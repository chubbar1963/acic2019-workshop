<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Ensemble Machine Learning | The tlverse Software Ecosystem for Causal Inference</title>
  <meta name="description" content="An open-source and fully-reproducible electronic set of teaching materials accompanying a full-day short-course on applying the Targeted Learning methodology in practice using the tlverse software ecosystem." />
  <meta name="generator" content="bookdown 0.10.2 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Ensemble Machine Learning | The tlverse Software Ecosystem for Causal Inference" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://tlverse.org/acic2019-workshop/" />
  
  <meta property="og:description" content="An open-source and fully-reproducible electronic set of teaching materials accompanying a full-day short-course on applying the Targeted Learning methodology in practice using the tlverse software ecosystem." />
  <meta name="github-repo" content="tlverse/acic2019-workshop" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Ensemble Machine Learning | The tlverse Software Ecosystem for Causal Inference" />
  
  <meta name="twitter:description" content="An open-source and fully-reproducible electronic set of teaching materials accompanying a full-day short-course on applying the Targeted Learning methodology in practice using the tlverse software ecosystem." />
  

<meta name="author" content="Mark van der Laan, Alan Hubbard, Jeremy Coyle, Nima Hejazi, Ivana Malenica, Rachael Phillips" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="img/logos/favicons/favicon.png" type="image/x-icon" />
<link rel="prev" href="tlverse.html">
<link rel="next" href="the-tmle-framework.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.3/htmlwidgets.js"></script>
<link href="libs/vis-4.20.1/vis.css" rel="stylesheet" />
<script src="libs/vis-4.20.1/vis.min.js"></script>
<script src="libs/visNetwork-binding-2.0.6/visNetwork.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">ACIC 2019 tlverse software workshop</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#important-links"><i class="fa fa-check"></i>Important links</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#about-this-workshop"><i class="fa fa-check"></i>About this workshop</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#outline"><i class="fa fa-check"></i>Outline</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#about-the-instructors"><i class="fa fa-check"></i>About the instructors</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#mark-van-der-laan"><i class="fa fa-check"></i>Mark van der Laan</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#alan-hubbard"><i class="fa fa-check"></i>Alan Hubbard</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#jeremy-coyle"><i class="fa fa-check"></i>Jeremy Coyle</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#nima-hejazi"><i class="fa fa-check"></i>Nima Hejazi</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#ivana-malenica"><i class="fa fa-check"></i>Ivana Malenica</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#rachael-phillips"><i class="fa fa-check"></i>Rachael Phillips</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="motivation.html"><a href="motivation.html"><i class="fa fa-check"></i>Motivation</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> The Targeted Learning Roadmap</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#the-statistical-model"><i class="fa fa-check"></i><b>1.1</b> The Statistical Model</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#the-causal-model"><i class="fa fa-check"></i><b>1.2</b> The Causal Model</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#the-parameter-of-interest"><i class="fa fa-check"></i><b>1.3</b> The Parameter of Interest</a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#identifiability"><i class="fa fa-check"></i><b>1.4</b> Identifiability</a></li>
<li class="chapter" data-level="1.5" data-path="intro.html"><a href="intro.html#estimators-superlearning-and-targeted-maximum-likelihood"><i class="fa fa-check"></i><b>1.5</b> Estimators: SuperLearning and Targeted Maximum Likelihood</a><ul>
<li class="chapter" data-level="1.5.1" data-path="intro.html"><a href="intro.html#superlearning"><i class="fa fa-check"></i><b>1.5.1</b> SuperLearning</a></li>
<li class="chapter" data-level="1.5.2" data-path="intro.html"><a href="intro.html#tmle"><i class="fa fa-check"></i><b>1.5.2</b> TMLE</a></li>
<li class="chapter" data-level="1.5.3" data-path="intro.html"><a href="intro.html#inference"><i class="fa fa-check"></i><b>1.5.3</b> Inference</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="intro.html"><a href="intro.html#the-wash-benefits-example-dataset"><i class="fa fa-check"></i><b>1.6</b> The WASH Benefits Example Dataset</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="tlverse.html"><a href="tlverse.html"><i class="fa fa-check"></i><b>2</b> Welcome to the <code>tlverse</code></a><ul>
<li class="chapter" data-level="2.1" data-path="tlverse.html"><a href="tlverse.html#learning-objectives"><i class="fa fa-check"></i><b>2.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="2.2" data-path="tlverse.html"><a href="tlverse.html#what-is-the-tlverse"><i class="fa fa-check"></i><b>2.2</b> What is the <code>tlverse</code>?</a></li>
<li class="chapter" data-level="2.3" data-path="tlverse.html"><a href="tlverse.html#tlverse-components"><i class="fa fa-check"></i><b>2.3</b> <code>tlverse</code> components</a></li>
<li class="chapter" data-level="2.4" data-path="tlverse.html"><a href="tlverse.html#installation"><i class="fa fa-check"></i><b>2.4</b> Installation</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="ensemble-machine-learning.html"><a href="ensemble-machine-learning.html"><i class="fa fa-check"></i><b>3</b> Ensemble Machine Learning</a><ul>
<li class="chapter" data-level="3.1" data-path="ensemble-machine-learning.html"><a href="ensemble-machine-learning.html#learning-objectives-1"><i class="fa fa-check"></i><b>3.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="3.2" data-path="ensemble-machine-learning.html"><a href="ensemble-machine-learning.html#introduction"><i class="fa fa-check"></i><b>3.2</b> Introduction</a></li>
<li class="chapter" data-level="3.3" data-path="ensemble-machine-learning.html"><a href="ensemble-machine-learning.html#basic-implementation"><i class="fa fa-check"></i><b>3.3</b> Basic Implementation</a><ul>
<li class="chapter" data-level="3.3.1" data-path="ensemble-machine-learning.html"><a href="ensemble-machine-learning.html#wash-benefits-study-example"><i class="fa fa-check"></i><b>3.3.1</b> WASH Benefits Study Example</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="ensemble-machine-learning.html"><a href="ensemble-machine-learning.html#extensions"><i class="fa fa-check"></i><b>3.4</b> Extensions</a><ul>
<li class="chapter" data-level="3.4.1" data-path="ensemble-machine-learning.html"><a href="ensemble-machine-learning.html#cross-validated-super-learner"><i class="fa fa-check"></i><b>3.4.1</b> Cross-validated Super Learner</a></li>
<li class="chapter" data-level="3.4.2" data-path="ensemble-machine-learning.html"><a href="ensemble-machine-learning.html#variable-importance-analysis-with-sl3"><i class="fa fa-check"></i><b>3.4.2</b> Variable Importance Analysis with <code>sl3</code></a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="ensemble-machine-learning.html"><a href="ensemble-machine-learning.html#exercise"><i class="fa fa-check"></i><b>3.5</b> Exercise</a><ul>
<li class="chapter" data-level="3.5.1" data-path="ensemble-machine-learning.html"><a href="ensemble-machine-learning.html#predicting-myocardial-infarction-with-sl3"><i class="fa fa-check"></i><b>3.5.1</b> Predicting Myocardial Infarction with <code>sl3</code></a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="ensemble-machine-learning.html"><a href="ensemble-machine-learning.html#concluding-remarks"><i class="fa fa-check"></i><b>3.6</b> Concluding Remarks</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html"><i class="fa fa-check"></i><b>4</b> The TMLE Framework</a><ul>
<li class="chapter" data-level="4.1" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#learning-objectives-2"><i class="fa fa-check"></i><b>4.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="4.2" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#example-tmle3-for-ate"><i class="fa fa-check"></i><b>4.2</b> Example: <code>tmle3</code> for ATE</a><ul>
<li class="chapter" data-level="4.2.1" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#load-the-data"><i class="fa fa-check"></i><b>4.2.1</b> Load the Data</a></li>
<li class="chapter" data-level="4.2.2" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#define-the-variable-roles"><i class="fa fa-check"></i><b>4.2.2</b> Define the variable roles</a></li>
<li class="chapter" data-level="4.2.3" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#handling-missingness"><i class="fa fa-check"></i><b>4.2.3</b> Handling Missingness</a></li>
<li class="chapter" data-level="4.2.4" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#create-a-spec-object"><i class="fa fa-check"></i><b>4.2.4</b> Create a “Spec” Object</a></li>
<li class="chapter" data-level="4.2.5" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#define-the-learners"><i class="fa fa-check"></i><b>4.2.5</b> Define the learners</a></li>
<li class="chapter" data-level="4.2.6" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#fit-the-tmle"><i class="fa fa-check"></i><b>4.2.6</b> Fit the TMLE</a></li>
<li class="chapter" data-level="4.2.7" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#evaluate-the-estimates"><i class="fa fa-check"></i><b>4.2.7</b> Evaluate the Estimates</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#tmle3-components"><i class="fa fa-check"></i><b>4.3</b> <code>tmle3</code> Components</a><ul>
<li class="chapter" data-level="4.3.1" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#tmle3_task"><i class="fa fa-check"></i><b>4.3.1</b> <code>tmle3_task</code></a></li>
<li class="chapter" data-level="4.3.2" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#initial-likelihood"><i class="fa fa-check"></i><b>4.3.2</b> Initial Likelihood</a></li>
<li class="chapter" data-level="4.3.3" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#targeted-likelihood-updater"><i class="fa fa-check"></i><b>4.3.3</b> Targeted Likelihood (updater)</a></li>
<li class="chapter" data-level="4.3.4" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#parameter-mapping"><i class="fa fa-check"></i><b>4.3.4</b> Parameter Mapping</a></li>
<li class="chapter" data-level="4.3.5" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#putting-it-all-together"><i class="fa fa-check"></i><b>4.3.5</b> Putting it all together</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#fitting-tmle3-with-multiple-parameters"><i class="fa fa-check"></i><b>4.4</b> Fitting <code>tmle3</code> with multiple parameters</a><ul>
<li class="chapter" data-level="4.4.1" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#delta-method"><i class="fa fa-check"></i><b>4.4.1</b> Delta Method</a></li>
<li class="chapter" data-level="4.4.2" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#fit"><i class="fa fa-check"></i><b>4.4.2</b> Fit</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#exercise-1"><i class="fa fa-check"></i><b>4.5</b> Exercise</a></li>
<li class="chapter" data-level="4.6" data-path="the-tmle-framework.html"><a href="the-tmle-framework.html#summary"><i class="fa fa-check"></i><b>4.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html"><i class="fa fa-check"></i><b>5</b> Optimal Individualized Treatment Regimes</a><ul>
<li class="chapter" data-level="5.1" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#learning-objectives-3"><i class="fa fa-check"></i><b>5.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="5.2" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#introduction-to-optimal-individualized-interventions"><i class="fa fa-check"></i><b>5.2</b> Introduction to Optimal Individualized Interventions</a></li>
<li class="chapter" data-level="5.3" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#data-structure-and-notation"><i class="fa fa-check"></i><b>5.3</b> Data Structure and Notation</a></li>
<li class="chapter" data-level="5.4" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#defining-the-causal-effect-of-an-optimal-individualized-intervention"><i class="fa fa-check"></i><b>5.4</b> Defining the Causal Effect of an Optimal Individualized Intervention</a><ul>
<li class="chapter" data-level="5.4.1" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#why-cv-tmle"><i class="fa fa-check"></i><b>5.4.1</b> Why CV-TMLE?</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#binary-treatment"><i class="fa fa-check"></i><b>5.5</b> Binary Treatment</a><ul>
<li class="chapter" data-level="5.5.1" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#evaluating-the-causal-effect-of-an-optimal-itr-with-binary-treatment"><i class="fa fa-check"></i><b>5.5.1</b> Evaluating the Causal Effect of an optimal ITR with Binary Treatment</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#categorical-treatment"><i class="fa fa-check"></i><b>5.6</b> Categorical Treatment</a><ul>
<li class="chapter" data-level="5.6.1" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#evaluating-the-causal-effect-of-an-optimal-itr-with-categorical-treatment"><i class="fa fa-check"></i><b>5.6.1</b> Evaluating the Causal Effect of an optimal ITR with Categorical Treatment</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#extensions-to-causal-effect-of-an-oit"><i class="fa fa-check"></i><b>5.7</b> Extensions to Causal Effect of an OIT</a><ul>
<li class="chapter" data-level="5.7.1" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#simpler-rules"><i class="fa fa-check"></i><b>5.7.1</b> Simpler Rules</a></li>
<li class="chapter" data-level="5.7.2" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#realistic-optimal-individual-regimes"><i class="fa fa-check"></i><b>5.7.2</b> Realistic Optimal Individual Regimes</a></li>
<li class="chapter" data-level="5.7.3" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#variable-importance-analysis"><i class="fa fa-check"></i><b>5.7.3</b> Variable Importance Analysis</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#exercise-2"><i class="fa fa-check"></i><b>5.8</b> Exercise</a><ul>
<li class="chapter" data-level="5.8.1" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#real-world-data-and-tmle3mopttx"><i class="fa fa-check"></i><b>5.8.1</b> Real World Data and <code>tmle3mopttx</code></a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#summary-1"><i class="fa fa-check"></i><b>5.9</b> Summary</a><ul>
<li class="chapter" data-level="5.9.1" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#solutions"><i class="fa fa-check"></i><b>5.9.1</b> Solutions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html"><i class="fa fa-check"></i><b>6</b> Stochastic Treatment Regimes</a><ul>
<li class="chapter" data-level="6.1" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#learning-objectives-4"><i class="fa fa-check"></i><b>6.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="6.2" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#introduction-1"><i class="fa fa-check"></i><b>6.2</b> Introduction</a></li>
<li class="chapter" data-level="6.3" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#stochastic-interventions"><i class="fa fa-check"></i><b>6.3</b> Stochastic Interventions</a><ul>
<li class="chapter" data-level="6.3.1" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#identifying-the-causal-effect-of-a-stochastic-intervention"><i class="fa fa-check"></i><b>6.3.1</b> Identifying the Causal Effect of a Stochastic Intervention</a></li>
<li class="chapter" data-level="6.3.2" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#interpreting-the-causal-effect-of-a-stochastic-intervention"><i class="fa fa-check"></i><b>6.3.2</b> Interpreting the Causal Effect of a Stochastic Intervention</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#estimating-the-causal-effect-of-a-stochastic-intervention-with-tmle3shift"><i class="fa fa-check"></i><b>6.4</b> Estimating the Causal Effect of a Stochastic Intervention with <code>tmle3shift</code></a><ul>
<li class="chapter" data-level="6.4.1" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#simulate-data-1"><i class="fa fa-check"></i><b>6.4.1</b> Simulate Data</a></li>
<li class="chapter" data-level="6.4.2" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#targeted-estimation-of-stochastic-interventions-effects"><i class="fa fa-check"></i><b>6.4.2</b> Targeted Estimation of Stochastic Interventions Effects</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#stochastic-interventions-over-a-grid-of-counterfactual-shifts"><i class="fa fa-check"></i><b>6.5</b> Stochastic Interventions over a Grid of Counterfactual Shifts</a><ul>
<li class="chapter" data-level="6.5.1" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#initializing-vimshift-through-its-tmle3_spec"><i class="fa fa-check"></i><b>6.5.1</b> Initializing <code>vimshift</code> through its <code>tmle3_Spec</code></a></li>
<li class="chapter" data-level="6.5.2" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#targeted-estimation-of-stochastic-intervention-effects"><i class="fa fa-check"></i><b>6.5.2</b> Targeted Estimation of Stochastic Intervention Effects</a></li>
<li class="chapter" data-level="6.5.3" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#inference-with-marginal-structural-models"><i class="fa fa-check"></i><b>6.5.3</b> Inference with Marginal Structural Models</a></li>
<li class="chapter" data-level="6.5.4" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#directly-targeting-the-msm-parameter-beta"><i class="fa fa-check"></i><b>6.5.4</b> Directly Targeting the MSM Parameter <span class="math inline">\(\beta\)</span></a></li>
<li class="chapter" data-level="6.5.5" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#example-with-the-wash-benefits-data"><i class="fa fa-check"></i><b>6.5.5</b> Example with the WASH Benefits Data</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#exercises"><i class="fa fa-check"></i><b>6.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="r6.html"><a href="r6.html"><i class="fa fa-check"></i><b>7</b> A Primer on the <code>R6</code> Class System</a><ul>
<li class="chapter" data-level="7.1" data-path="r6.html"><a href="r6.html#classes-fields-and-methods"><i class="fa fa-check"></i><b>7.1</b> Classes, Fields, and Methods</a></li>
<li class="chapter" data-level="7.2" data-path="r6.html"><a href="r6.html#object-oriented-programming-python-and-r"><i class="fa fa-check"></i><b>7.2</b> Object Oriented Programming: <code>Python</code> and <code>R</code></a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">The <code>tlverse</code> Software Ecosystem for Causal Inference</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ensemble-machine-learning" class="section level1">
<h1><span class="header-section-number">Chapter 3</span> Ensemble Machine Learning</h1>
<p><em>Rachael Phillips</em></p>
<p>Based on the <a href="https://github.com/tlverse/sl3"><code>sl3</code> <code>R</code> package</a> by <em>Jeremy
Coyle, Nima Hejazi, Ivana Malenica, and Oleg Sofrygin</em>.</p>
<p>Updated: 2019-05-15</p>
<div id="learning-objectives-1" class="section level2">
<h2><span class="header-section-number">3.1</span> Learning Objectives</h2>
<p>By the end of this lesson you will be able to:</p>
<ol style="list-style-type: decimal">
<li>Assemble an ensemble of learners based on the properties that identify what
features they support.</li>
<li>Customize learner hyperparameters to incorporate a diversity of different
settings.</li>
<li>Select a subset of available covariates and pass only those variables to the
modeling algorithm.</li>
<li>Fit an ensemble with nested cross-validation to obtain an estimate of the
performance of the ensemble itself.</li>
<li>Calculate <code>sl3</code> variable importance metrics.</li>
<li>Interpret the discrete and continuous super learner fits.</li>
<li>Rationalize the need to remove bias from the super learner to make an optimal
bias-variance tradeoff for the parameter of interest.</li>
</ol>
</div>
<div id="introduction" class="section level2">
<h2><span class="header-section-number">3.2</span> Introduction</h2>
<p>Now that we have defined the statistical estimation problem, we are ready
construct the TMLE; an asymptotically efficient substitution estimator of this
target quantity. The first step in this estimation procedure is an initial
estimate of the data-generating distribution, or the relevant part of this
distribution that is needed to evaluate the target parameter. For this initial
estimation, we use the super learner <span class="citation">(Van der Laan, Polley, and Hubbard <a href="#ref-van2007super">2007</a>)</span>, an important step in
creating a robust estimator.</p>
<div id="super-learner" class="section level4 unnumbered">
<h4>Super Learner</h4>
<ul>
<li><p>Loss-function-based tool that uses V-fold cross-validation to obtain the best
prediction of the relevant part of the likelihood that’s needed to evaluate
target parameter.</p></li>
<li><p>Requires expressing the estimand as the minimizer of an expected loss, and
proposing a library of algorithms (“learners” in <code>sl3</code> nomenclature) that we
think might be consistent with the true data-generating distribution.</p></li>
<li><p>Proven to be asymptotically as accurate as the best possible prediction
algorithm that is tested <span class="citation">(van der Laan and Dudoit <a href="#ref-vdl2003unified">2003</a>; Van der Vaart, Dudoit, and Laan <a href="#ref-van2006oracle">2006</a>)</span>.</p></li>
<li><p>The <em>discrete super learner</em>, or cross-validated selector, is the algorithm in
the library that minimizes the V-fold cross-validated empirical risk.</p></li>
<li><p>The <em>continuous super learner</em> is a weighted average of the library of
algorithms, where the weights are chosen to minimize the V-fold
cross-validated empirical risk of the library. Restricting the weights
(“metalearner” in <code>sl3</code> nomenclature) to be positive and sum to one (convex
combination) has been shown to improve upon the discrete super learner
<span class="citation">(Polley and Van Der Laan <a href="#ref-polley2010super">2010</a>; Van der Laan, Polley, and Hubbard <a href="#ref-van2007super">2007</a>)</span>.</p></li>
<li><p>This background material is described in greater detail in the accompanying
<a href="https://tlverse.org/tlverse-handbook/ensemble-machine-learning.html"><code>sl3</code> chapter</a>
of the <code>tlverse</code> handbook.</p></li>
</ul>
</div>
</div>
<div id="basic-implementation" class="section level2">
<h2><span class="header-section-number">3.3</span> Basic Implementation</h2>
<p>We begin by illustrating the basic functionality of the super learner
algorithm as implemented in <code>sl3</code>. The <code>sl3</code> implementation consists of the
following steps:</p>
<ol start="0" style="list-style-type: decimal">
<li>Load the necessary libraries and data</li>
<li>Define the machine learning task</li>
<li>Make a super learner by creating library of base learners and a metalearner</li>
<li>Train the super learner on the machine learning task</li>
<li>Obtain predicted values</li>
</ol>
<div id="wash-benefits-study-example" class="section level3">
<h3><span class="header-section-number">3.3.1</span> WASH Benefits Study Example</h3>
<p>Using the WASH data, we are interested in predicting weight-for-height z-score
<code>whz</code> using the available covariate data. Let’s begin!</p>
<p><strong>0. Load the necessary libraries and data</strong></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(kableExtra)
<span class="kw">library</span>(knitr)
<span class="kw">library</span>(skimr)
<span class="kw">library</span>(here)
<span class="kw">library</span>(tidyverse)
<span class="kw">library</span>(data.table)
<span class="kw">library</span>(sl3)
<span class="kw">library</span>(SuperLearner)
<span class="kw">library</span>(origami)

<span class="kw">set.seed</span>(<span class="dv">7194</span>)

<span class="co"># load data set and take a peek</span>
washb_data &lt;-<span class="st"> </span><span class="kw">fread</span>(<span class="kw">here</span>(<span class="st">&quot;data&quot;</span>, <span class="st">&quot;washb_data.csv&quot;</span>), <span class="dt">stringsAsFactors =</span> <span class="ot">TRUE</span>)
<span class="kw">head</span>(washb_data) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">kable</span>(<span class="dt">digits =</span> <span class="dv">4</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">kable_styling</span>(<span class="dt">fixed_thead =</span> T) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">scroll_box</span>(<span class="dt">width =</span> <span class="st">&quot;100%&quot;</span>, <span class="dt">height =</span> <span class="st">&quot;300px&quot;</span>)</code></pre>
<div style="border: 1px solid #ddd; padding: 0px; overflow-y: scroll; height:300px; overflow-x: scroll; width:100%; ">
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
whz
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
tr
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
fracode
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
month
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
aged
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
sex
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
momage
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
momedu
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
momheight
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
hfiacat
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
Nlt18
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
Ncomp
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
watmin
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
elec
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
floor
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
walls
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
roof
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_wardrobe
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_table
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_chair
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_khat
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_chouki
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_tv
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_refrig
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_bike
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_moto
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_sewmach
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
asset_mobile
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:left;">
Control
</td>
<td style="text-align:left;">
N05265
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
268
</td>
<td style="text-align:left;">
male
</td>
<td style="text-align:right;">
30
</td>
<td style="text-align:left;">
Primary (1-5y)
</td>
<td style="text-align:right;">
146.40
</td>
<td style="text-align:left;">
Food Secure
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
11
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
-1.16
</td>
<td style="text-align:left;">
Control
</td>
<td style="text-align:left;">
N05265
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
286
</td>
<td style="text-align:left;">
male
</td>
<td style="text-align:right;">
25
</td>
<td style="text-align:left;">
Primary (1-5y)
</td>
<td style="text-align:right;">
148.75
</td>
<td style="text-align:left;">
Moderately Food Insecure
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
-1.05
</td>
<td style="text-align:left;">
Control
</td>
<td style="text-align:left;">
N08002
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
264
</td>
<td style="text-align:left;">
male
</td>
<td style="text-align:right;">
25
</td>
<td style="text-align:left;">
Primary (1-5y)
</td>
<td style="text-align:right;">
152.15
</td>
<td style="text-align:left;">
Food Secure
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
10
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
-1.26
</td>
<td style="text-align:left;">
Control
</td>
<td style="text-align:left;">
N08002
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
252
</td>
<td style="text-align:left;">
female
</td>
<td style="text-align:right;">
28
</td>
<td style="text-align:left;">
Primary (1-5y)
</td>
<td style="text-align:right;">
140.25
</td>
<td style="text-align:left;">
Food Secure
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
-0.59
</td>
<td style="text-align:left;">
Control
</td>
<td style="text-align:left;">
N06531
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
336
</td>
<td style="text-align:left;">
female
</td>
<td style="text-align:right;">
19
</td>
<td style="text-align:left;">
Secondary (&gt;5y)
</td>
<td style="text-align:right;">
150.95
</td>
<td style="text-align:left;">
Food Secure
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
7
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:right;">
-0.51
</td>
<td style="text-align:left;">
Control
</td>
<td style="text-align:left;">
N06531
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
304
</td>
<td style="text-align:left;">
male
</td>
<td style="text-align:right;">
20
</td>
<td style="text-align:left;">
Secondary (&gt;5y)
</td>
<td style="text-align:right;">
154.20
</td>
<td style="text-align:left;">
Severely Food Insecure
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
</tr>
</tbody>
</table>
</div>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">skim</span>(washb_data)  </code></pre>
<pre><code>Skim summary statistics
 n obs: 4695 
 n variables: 28 

── Variable type:factor ────────────────────────────────────────────────────────
 variable missing complete    n n_unique
  fracode       0     4695 4695       20
  hfiacat       0     4695 4695        4
   momedu       0     4695 4695        3
      sex       0     4695 4695        2
       tr       0     4695 4695        7
                              top_counts ordered
  N08: 367, N06: 338, N06: 331, N06: 325   FALSE
 Foo: 3249, Mod: 879, Mil: 410, Sev: 157   FALSE
   Sec: 2513, Pri: 1448, No : 734, NA: 0   FALSE
             fem: 2352, mal: 2343, NA: 0   FALSE
 Con: 1178, Nut: 598, Han: 590, San: 590   FALSE

── Variable type:integer ───────────────────────────────────────────────────────
       variable missing complete    n    mean    sd p0 p25 p50 p75 p100
           aged       0     4695 4695 266.32  52.17 42 230 266 303  460
     asset_bike       0     4695 4695   0.32   0.47  0   0   0   1    1
    asset_chair       0     4695 4695   0.73   0.44  0   0   1   1    1
   asset_chouki       0     4695 4695   0.78   0.41  0   1   1   1    1
     asset_khat       0     4695 4695   0.61   0.49  0   0   1   1    1
   asset_mobile       0     4695 4695   0.86   0.35  0   1   1   1    1
     asset_moto       0     4695 4695   0.066  0.25  0   0   0   0    1
   asset_refrig       0     4695 4695   0.079  0.27  0   0   0   0    1
  asset_sewmach       0     4695 4695   0.065  0.25  0   0   0   0    1
    asset_table       0     4695 4695   0.73   0.44  0   0   1   1    1
       asset_tv       0     4695 4695   0.3    0.46  0   0   0   1    1
 asset_wardrobe       0     4695 4695   0.17   0.37  0   0   0   0    1
           elec       0     4695 4695   0.6    0.49  0   0   1   1    1
          floor       0     4695 4695   0.11   0.31  0   0   0   0    1
         momage      18     4677 4695  23.91   5.24 14  20  23  27   60
          month       0     4695 4695   6.45   3.33  1   4   6   9   12
          Ncomp       0     4695 4695  11.04   6.35  2   6  10  14   52
          Nlt18       0     4695 4695   1.6    1.25  0   1   1   2   10
           roof       0     4695 4695   0.99   0.12  0   1   1   1    1
          walls       0     4695 4695   0.72   0.45  0   0   1   1    1
         watmin       0     4695 4695   0.95   9.48  0   0   0   1  600
     hist
 ▁▁▂▇▇▅▁▁
 ▇▁▁▁▁▁▁▃
 ▃▁▁▁▁▁▁▇
 ▂▁▁▁▁▁▁▇
 ▅▁▁▁▁▁▁▇
 ▁▁▁▁▁▁▁▇
 ▇▁▁▁▁▁▁▁
 ▇▁▁▁▁▁▁▁
 ▇▁▁▁▁▁▁▁
 ▃▁▁▁▁▁▁▇
 ▇▁▁▁▁▁▁▃
 ▇▁▁▁▁▁▁▂
 ▆▁▁▁▁▁▁▇
 ▇▁▁▁▁▁▁▁
 ▅▇▅▂▁▁▁▁
 ▅▃▇▃▂▇▃▅
 ▇▇▃▁▁▁▁▁
 ▇▃▂▁▁▁▁▁
 ▁▁▁▁▁▁▁▇
 ▃▁▁▁▁▁▁▇
 ▇▁▁▁▁▁▁▁

── Variable type:numeric ───────────────────────────────────────────────────────
  variable missing complete    n   mean   sd     p0    p25   p50    p75   p100
 momheight      31     4664 4695 150.5  5.23 120.65 147.05 150.6 154.06 168   
       whz       0     4695 4695  -0.59 1.03  -4.67  -1.28  -0.6   0.08   4.97
     hist
 ▁▁▁▂▇▇▂▁
 ▁▁▅▇▃▁▁▁</code></pre>
<p><strong>1. Define the machine learning task</strong></p>
<p>To define the machine learning <strong>“task”</strong> (predict weight-for-height z-score
<code>whz</code> using the available covariate data), we need to create an <code>sl3_Task</code>
object. The <code>sl3_Task</code> keeps track of the roles the variables play in the
machine learning problem, the data, and any metadata (e.g., observational-level
weights, id, offset).</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># specify the outcome and covariates</span>
outcome &lt;-<span class="st"> &quot;whz&quot;</span>
covars &lt;-<span class="st"> </span><span class="kw">colnames</span>(washb_data)[<span class="op">-</span><span class="kw">which</span>(<span class="kw">names</span>(washb_data) <span class="op">==</span><span class="st"> </span>outcome)]

<span class="co"># create the sl3 task</span>
washb_task &lt;-<span class="st"> </span><span class="kw">make_sl3_Task</span>(
  <span class="dt">data =</span> washb_data,
  <span class="dt">covariates =</span> covars,
  <span class="dt">outcome =</span> outcome
)</code></pre>
<pre><code>Warning in .subset2(public_bind_env, &quot;initialize&quot;)(...): Missing Covariate Data
Found. Imputing covariates using sl3_process_missing</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># examine it</span>
washb_task</code></pre>
<pre><code>A sl3 Task with 4695 obs and these nodes:
$covariates
 [1] &quot;tr&quot;              &quot;fracode&quot;         &quot;month&quot;           &quot;aged&quot;           
 [5] &quot;sex&quot;             &quot;momage&quot;          &quot;momedu&quot;          &quot;momheight&quot;      
 [9] &quot;hfiacat&quot;         &quot;Nlt18&quot;           &quot;Ncomp&quot;           &quot;watmin&quot;         
[13] &quot;elec&quot;            &quot;floor&quot;           &quot;walls&quot;           &quot;roof&quot;           
[17] &quot;asset_wardrobe&quot;  &quot;asset_table&quot;     &quot;asset_chair&quot;     &quot;asset_khat&quot;     
[21] &quot;asset_chouki&quot;    &quot;asset_tv&quot;        &quot;asset_refrig&quot;    &quot;asset_bike&quot;     
[25] &quot;asset_moto&quot;      &quot;asset_sewmach&quot;   &quot;asset_mobile&quot;    &quot;delta_momage&quot;   
[29] &quot;delta_momheight&quot;

$outcome
[1] &quot;whz&quot;

$id
NULL

$weights
NULL

$offset
NULL</code></pre>
<p><strong>2. Make a super learner</strong></p>
<p>Now that we have defined our machine learning problem with the task, we are
ready to <strong>“make”</strong> the super learner. This requires specification of</p>
<ul>
<li>A library of base learning algorithms that we think might be consistent with
the true data-generating distribution.</li>
<li>A metalearner, to ensemble the base learners.</li>
</ul>
<p>We might also incorporate</p>
<ul>
<li>Feature selection, to pass only a subset of the predictors to the algorithm.</li>
<li>Hyperparameter specification, to tune base learners.</li>
</ul>
<p>Learners have properties that indicate what features they support. We may use
<code>sl3_list_properties()</code> to get a list of all properties supported by at least
one learner.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sl3_list_properties</span>()</code></pre>
<pre><code> [1] &quot;binomial&quot;             &quot;categorical&quot;          &quot;continuous&quot;          
 [4] &quot;cv&quot;                   &quot;density&quot;              &quot;ids&quot;                 
 [7] &quot;multivariate_outcome&quot; &quot;offset&quot;               &quot;preprocessing&quot;       
[10] &quot;timeseries&quot;           &quot;weights&quot;              &quot;wrapper&quot;             </code></pre>
<p>Since we have a continuous outcome, we may identify the learners that support
this outcome type with <code>sl3_list_learners()</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sl3_list_learners</span>(<span class="kw">c</span>(<span class="st">&quot;continuous&quot;</span>))</code></pre>
<pre><code> [1] &quot;Lrnr_arima&quot;                     &quot;Lrnr_bartMachine&quot;              
 [3] &quot;Lrnr_bilstm&quot;                    &quot;Lrnr_condensier&quot;               
 [5] &quot;Lrnr_dbarts&quot;                    &quot;Lrnr_expSmooth&quot;                
 [7] &quot;Lrnr_glm&quot;                       &quot;Lrnr_glm_fast&quot;                 
 [9] &quot;Lrnr_glmnet&quot;                    &quot;Lrnr_grf&quot;                      
[11] &quot;Lrnr_h2o_glm&quot;                   &quot;Lrnr_h2o_grid&quot;                 
[13] &quot;Lrnr_hal9001&quot;                   &quot;Lrnr_HarmonicReg&quot;              
[15] &quot;Lrnr_lstm&quot;                      &quot;Lrnr_mean&quot;                     
[17] &quot;Lrnr_nnls&quot;                      &quot;Lrnr_optim&quot;                    
[19] &quot;Lrnr_pkg_SuperLearner&quot;          &quot;Lrnr_pkg_SuperLearner_method&quot;  
[21] &quot;Lrnr_pkg_SuperLearner_screener&quot; &quot;Lrnr_randomForest&quot;             
[23] &quot;Lrnr_ranger&quot;                    &quot;Lrnr_rpart&quot;                    
[25] &quot;Lrnr_rugarch&quot;                   &quot;Lrnr_solnp&quot;                    
[27] &quot;Lrnr_stratified&quot;                &quot;Lrnr_svm&quot;                      
[29] &quot;Lrnr_tsDyn&quot;                     &quot;Lrnr_xgboost&quot;                  </code></pre>
<p>Now that we have an idea of some learners, we can construct them using the
<code>make_learner</code> function.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># choose base learners</span>
lrnr_glm &lt;-<span class="st"> </span><span class="kw">make_learner</span>(Lrnr_glm)
lrnr_mean &lt;-<span class="st"> </span><span class="kw">make_learner</span>(Lrnr_mean)
lrnr_glmnet &lt;-<span class="st"> </span><span class="kw">make_learner</span>(Lrnr_glmnet)</code></pre>
<p>We can customize learner hyperparameters to incorporate a diversity of different
settings. Documentation for the learners and their hyperparameters can be found
in the <a href="https://tlverse.org/sl3/reference/index.html#section-sl-learners"><code>sl3 Learners Reference</code></a>.
We can also include learners from the <code>SuperLearner</code> <code>R</code> package.</p>
<pre class="sourceCode r"><code class="sourceCode r">lrnr_ranger100 &lt;-<span class="st"> </span><span class="kw">make_learner</span>(Lrnr_ranger, <span class="dt">num.trees =</span> <span class="dv">100</span>)
lrnr_hal_simple &lt;-<span class="st"> </span><span class="kw">make_learner</span>(Lrnr_hal9001, <span class="dt">degrees =</span> <span class="dv">1</span>, <span class="dt">n_folds =</span> <span class="dv">2</span>)
lrnr_gam &lt;-<span class="st"> </span>Lrnr_pkg_SuperLearner<span class="op">$</span><span class="kw">new</span>(<span class="st">&quot;SL.gam&quot;</span>)
lrnr_bayesglm &lt;-<span class="st"> </span>Lrnr_pkg_SuperLearner<span class="op">$</span><span class="kw">new</span>(<span class="st">&quot;SL.bayesglm&quot;</span>)</code></pre>
<p>In order to assemble the library of learners, we need to <strong>“stack”</strong> them
together. A <code>Stack</code> is a special learner and it has the same interface as all
other learners. What makes a stack special is that it combines multiple learners
by training them simultaneously, so that their predictions can be either
combined or compared.</p>
<pre class="sourceCode r"><code class="sourceCode r">stack &lt;-<span class="st"> </span><span class="kw">make_learner</span>(
  Stack,
  lrnr_glm, lrnr_mean, lrnr_ranger100, lrnr_glmnet,
  lrnr_gam, lrnr_bayesglm
)</code></pre>
<p>We will fit a non-negative least squares metalearner using <code>Lrnr_nnls</code>. Note
that any learner can be used as a metalearner.</p>
<pre class="sourceCode r"><code class="sourceCode r">metalearner &lt;-<span class="st"> </span><span class="kw">make_learner</span>(Lrnr_nnls)</code></pre>
<p>We can optionally select a subset of available covariates and pass only
those variables to the modeling algorithm. Let’s consider screening covariates
based on their correlation with our outcome of interest (<code>cor.test</code> p-value
<span class="math inline">\(\leq 0.1\)</span>).</p>
<pre class="sourceCode r"><code class="sourceCode r">screen_cor &lt;-<span class="st"> </span>Lrnr_pkg_SuperLearner_screener<span class="op">$</span><span class="kw">new</span>(<span class="st">&quot;screen.corP&quot;</span>)
screen_cor<span class="op">$</span><span class="kw">train</span>(washb_task)</code></pre>
<pre><code>[1] &quot;Lrnr_pkg_SuperLearner_screener_screen.corP&quot;
$selected
 [1] &quot;tr&quot;             &quot;fracode&quot;        &quot;aged&quot;           &quot;momage&quot;        
 [5] &quot;momedu&quot;         &quot;momheight&quot;      &quot;hfiacat&quot;        &quot;Nlt18&quot;         
 [9] &quot;elec&quot;           &quot;floor&quot;          &quot;walls&quot;          &quot;asset_wardrobe&quot;
[13] &quot;asset_table&quot;    &quot;asset_chair&quot;    &quot;asset_khat&quot;     &quot;asset_chouki&quot;  
[17] &quot;asset_tv&quot;       &quot;asset_refrig&quot;   &quot;asset_moto&quot;     &quot;asset_sewmach&quot; 
[21] &quot;asset_mobile&quot;  </code></pre>
<p>To <strong>“pipe”</strong> only the selected covariates to the modeling algorithm, we need to
make a <code>Pipeline</code>, which is a just set of learners to be fit sequentially, where
the fit from one learner is used to define the task for the next learner.</p>
<pre class="sourceCode r"><code class="sourceCode r">cor_pipeline &lt;-<span class="st"> </span><span class="kw">make_learner</span>(Pipeline, screen_cor, stack)</code></pre>
<p>Now, our learners will be preceded by a screening step. We also consider the
original <code>stack</code>, just to compare how the feature selection methods perform in
comparison to the methods without feature selection.</p>
<p>Analogous to what we have seen before, we have to stack the pipeline and
original <code>stack</code> together, so we may use them as base learners in our super
learner.</p>
<pre class="sourceCode r"><code class="sourceCode r">fancy_stack &lt;-<span class="st"> </span><span class="kw">make_learner</span>(Stack, cor_pipeline, stack)
<span class="co"># we can visualize the stack</span>
dt_stack &lt;-<span class="st"> </span><span class="kw">delayed_learner_train</span>(fancy_stack, washb_task)
<span class="kw">plot</span>(dt_stack, <span class="dt">color =</span> <span class="ot">FALSE</span>, <span class="dt">height =</span> <span class="st">&quot;400px&quot;</span>, <span class="dt">width =</span> <span class="st">&quot;100%&quot;</span>)</code></pre>
<div id="htmlwidget-cdd97510cf75335e3aa4" style="width:100%;height:400px;" class="visNetwork html-widget"></div>
<script type="application/json" data-for="htmlwidget-cdd97510cf75335e3aa4">{"x":{"nodes":{"id":["cbc77362-773e-11e9-8bef-42010a14001a","cbc75ac6-773e-11e9-8bef-42010a14001a","cbc66b66-773e-11e9-8bef-42010a14001a","cbc64f0a-773e-11e9-8bef-42010a14001a","cbc4fe7a-773e-11e9-8bef-42010a14001a","cbc61be8-773e-11e9-8bef-42010a14001a","cbc53408-773e-11e9-8bef-42010a14001a","cbc60072-773e-11e9-8bef-42010a14001a","cbc55528-773e-11e9-8bef-42010a14001a","cbc5722e-773e-11e9-8bef-42010a14001a","cbc58d22-773e-11e9-8bef-42010a14001a","cbc5a8fc-773e-11e9-8bef-42010a14001a","cbc5c60c-773e-11e9-8bef-42010a14001a","cbc5e164-773e-11e9-8bef-42010a14001a","cbc7407c-773e-11e9-8bef-42010a14001a","cbc72506-773e-11e9-8bef-42010a14001a","cbc689e8-773e-11e9-8bef-42010a14001a","cbc6a41e-773e-11e9-8bef-42010a14001a","cbc6bd3c-773e-11e9-8bef-42010a14001a","cbc6d650-773e-11e9-8bef-42010a14001a","cbc6ef8c-773e-11e9-8bef-42010a14001a","cbc70be8-773e-11e9-8bef-42010a14001a"],"label":["Stack","bundle","Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP->Stack)","bundle","Lrnr_pkg_SuperLearner_screener_screen.corP","Stack","chain","bundle","Lrnr_glm_TRUE","Lrnr_mean","Lrnr_ranger_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_pkg_SuperLearner_SL.gam","Lrnr_pkg_SuperLearner_SL.bayesglm","Stack","bundle","Lrnr_glm_TRUE","Lrnr_mean","Lrnr_ranger_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_pkg_SuperLearner_SL.gam","Lrnr_pkg_SuperLearner_SL.bayesglm"],"level":[1,2,3,4,9,5,8,6,7,7,7,7,7,7,3,4,5,5,5,5,5,5],"sequential":[true,true,true,true,false,true,true,true,false,false,false,false,false,false,true,true,false,false,false,false,false,false],"state":["waiting","waiting","waiting","waiting","ready","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","ready","ready","ready","ready","ready","ready"],"group":["none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none"]},"edges":{"from":["cbc4fe7a-773e-11e9-8bef-42010a14001a","cbc4fe7a-773e-11e9-8bef-42010a14001a","cbc53408-773e-11e9-8bef-42010a14001a","cbc53408-773e-11e9-8bef-42010a14001a","cbc55528-773e-11e9-8bef-42010a14001a","cbc53408-773e-11e9-8bef-42010a14001a","cbc5722e-773e-11e9-8bef-42010a14001a","cbc53408-773e-11e9-8bef-42010a14001a","cbc58d22-773e-11e9-8bef-42010a14001a","cbc53408-773e-11e9-8bef-42010a14001a","cbc5a8fc-773e-11e9-8bef-42010a14001a","cbc53408-773e-11e9-8bef-42010a14001a","cbc5c60c-773e-11e9-8bef-42010a14001a","cbc53408-773e-11e9-8bef-42010a14001a","cbc5e164-773e-11e9-8bef-42010a14001a","cbc60072-773e-11e9-8bef-42010a14001a","cbc61be8-773e-11e9-8bef-42010a14001a","cbc64f0a-773e-11e9-8bef-42010a14001a","cbc66b66-773e-11e9-8bef-42010a14001a","cbc689e8-773e-11e9-8bef-42010a14001a","cbc6a41e-773e-11e9-8bef-42010a14001a","cbc6bd3c-773e-11e9-8bef-42010a14001a","cbc6d650-773e-11e9-8bef-42010a14001a","cbc6ef8c-773e-11e9-8bef-42010a14001a","cbc70be8-773e-11e9-8bef-42010a14001a","cbc72506-773e-11e9-8bef-42010a14001a","cbc7407c-773e-11e9-8bef-42010a14001a","cbc75ac6-773e-11e9-8bef-42010a14001a"],"to":["cbc64f0a-773e-11e9-8bef-42010a14001a","cbc53408-773e-11e9-8bef-42010a14001a","cbc61be8-773e-11e9-8bef-42010a14001a","cbc55528-773e-11e9-8bef-42010a14001a","cbc60072-773e-11e9-8bef-42010a14001a","cbc5722e-773e-11e9-8bef-42010a14001a","cbc60072-773e-11e9-8bef-42010a14001a","cbc58d22-773e-11e9-8bef-42010a14001a","cbc60072-773e-11e9-8bef-42010a14001a","cbc5a8fc-773e-11e9-8bef-42010a14001a","cbc60072-773e-11e9-8bef-42010a14001a","cbc5c60c-773e-11e9-8bef-42010a14001a","cbc60072-773e-11e9-8bef-42010a14001a","cbc5e164-773e-11e9-8bef-42010a14001a","cbc60072-773e-11e9-8bef-42010a14001a","cbc61be8-773e-11e9-8bef-42010a14001a","cbc64f0a-773e-11e9-8bef-42010a14001a","cbc66b66-773e-11e9-8bef-42010a14001a","cbc75ac6-773e-11e9-8bef-42010a14001a","cbc72506-773e-11e9-8bef-42010a14001a","cbc72506-773e-11e9-8bef-42010a14001a","cbc72506-773e-11e9-8bef-42010a14001a","cbc72506-773e-11e9-8bef-42010a14001a","cbc72506-773e-11e9-8bef-42010a14001a","cbc72506-773e-11e9-8bef-42010a14001a","cbc7407c-773e-11e9-8bef-42010a14001a","cbc75ac6-773e-11e9-8bef-42010a14001a","cbc77362-773e-11e9-8bef-42010a14001a"],"label":["","","","","","","","","","","","","","","","","","","","","","","","","","","",""]},"nodesToDataframe":true,"edgesToDataframe":true,"options":{"width":"100%","height":"100%","nodes":{"shape":"dot"},"manipulation":{"enabled":false},"edges":{"arrows":"to"},"layout":{"hierarchical":{"enabled":true,"levelSeparation":500,"nodeSpacing":200,"direction":"RL"}},"groups":{"useDefaultGroups":true,"none":{"color":{"border":"black","background":"white"}}}},"groups":["none"],"width":"100%","height":"400px","idselection":{"enabled":false},"byselection":{"enabled":false},"main":null,"submain":null,"footer":null,"background":"rgba(0, 0, 0, 0)"},"evals":[],"jsHooks":[]}</script>
<p>Now that we have made a library/stack of base learners and a metalearner, we
are ready to make the super learner. The super learner algorithm fits a
metalearner on the validation-set predictions.</p>
<pre class="sourceCode r"><code class="sourceCode r">sl &lt;-<span class="st"> </span><span class="kw">make_learner</span>(Lrnr_sl,
  <span class="dt">learners =</span> fancy_stack,
  <span class="dt">metalearner =</span> metalearner
)
<span class="co"># we can visualize the super learner</span>
dt_sl &lt;-<span class="st"> </span><span class="kw">delayed_learner_train</span>(sl, washb_task)
<span class="kw">plot</span>(dt_sl, <span class="dt">color =</span> <span class="ot">FALSE</span>, <span class="dt">height =</span> <span class="st">&quot;400px&quot;</span>, <span class="dt">width =</span> <span class="st">&quot;100%&quot;</span>)</code></pre>
<div id="htmlwidget-fd0b82f657870377d67e" style="width:100%;height:400px;" class="visNetwork html-widget"></div>
<script type="application/json" data-for="htmlwidget-fd0b82f657870377d67e">{"x":{"nodes":{"id":["cc022ac0-773e-11e9-8bef-42010a14001a","cc020ffe-773e-11e9-8bef-42010a14001a","cc01bf90-773e-11e9-8bef-42010a14001a","cc01a5be-773e-11e9-8bef-42010a14001a","cbd622d6-773e-11e9-8bef-42010a14001a","cbd609d6-773e-11e9-8bef-42010a14001a","cbd51d46-773e-11e9-8bef-42010a14001a","cbd5039c-773e-11e9-8bef-42010a14001a","cbd3d0b2-773e-11e9-8bef-42010a14001a","cbd4cce2-773e-11e9-8bef-42010a14001a","cbd3edb8-773e-11e9-8bef-42010a14001a","cbd4b1c6-773e-11e9-8bef-42010a14001a","cbd40a14-773e-11e9-8bef-42010a14001a","cbd4260c-773e-11e9-8bef-42010a14001a","cbd44088-773e-11e9-8bef-42010a14001a","cbd45ae6-773e-11e9-8bef-42010a14001a","cbd478d2-773e-11e9-8bef-42010a14001a","cbd49416-773e-11e9-8bef-42010a14001a","cbd5f054-773e-11e9-8bef-42010a14001a","cbd5d60a-773e-11e9-8bef-42010a14001a","cbd53d1c-773e-11e9-8bef-42010a14001a","cbd556bc-773e-11e9-8bef-42010a14001a","cbd57034-773e-11e9-8bef-42010a14001a","cbd58920-773e-11e9-8bef-42010a14001a","cbd5a2f2-773e-11e9-8bef-42010a14001a","cbd5bc4c-773e-11e9-8bef-42010a14001a","cc018890-773e-11e9-8bef-42010a14001a","cbea8c3a-773e-11e9-8bef-42010a14001a","cbea72ae-773e-11e9-8bef-42010a14001a","cbe9839e-773e-11e9-8bef-42010a14001a","cbe969c2-773e-11e9-8bef-42010a14001a","cbe8380e-773e-11e9-8bef-42010a14001a","cbe93452-773e-11e9-8bef-42010a14001a","cbe853fc-773e-11e9-8bef-42010a14001a","cbe917c4-773e-11e9-8bef-42010a14001a","cbe870e4-773e-11e9-8bef-42010a14001a","cbe88e12-773e-11e9-8bef-42010a14001a","cbe8a938-773e-11e9-8bef-42010a14001a","cbe8c3d2-773e-11e9-8bef-42010a14001a","cbe8de62-773e-11e9-8bef-42010a14001a","cbe8fd0c-773e-11e9-8bef-42010a14001a","cbea576a-773e-11e9-8bef-42010a14001a","cbea3c80-773e-11e9-8bef-42010a14001a","cbe9a2d4-773e-11e9-8bef-42010a14001a","cbe9bc4c-773e-11e9-8bef-42010a14001a","cbe9d6d2-773e-11e9-8bef-42010a14001a","cbe9f090-773e-11e9-8bef-42010a14001a","cbea0a1c-773e-11e9-8bef-42010a14001a","cbea23bc-773e-11e9-8bef-42010a14001a","cbed230a-773e-11e9-8bef-42010a14001a","cbecfc7c-773e-11e9-8bef-42010a14001a","cbec072c-773e-11e9-8bef-42010a14001a","cbebedc8-773e-11e9-8bef-42010a14001a","cbeac59c-773e-11e9-8bef-42010a14001a","cbebb98e-773e-11e9-8bef-42010a14001a","cbeadffa-773e-11e9-8bef-42010a14001a","cbeb9f1c-773e-11e9-8bef-42010a14001a","cbeafc9c-773e-11e9-8bef-42010a14001a","cbeb18da-773e-11e9-8bef-42010a14001a","cbeb33e2-773e-11e9-8bef-42010a14001a","cbeb4ef4-773e-11e9-8bef-42010a14001a","cbeb697a-773e-11e9-8bef-42010a14001a","cbeb83d8-773e-11e9-8bef-42010a14001a","cbece21e-773e-11e9-8bef-42010a14001a","cbecc536-773e-11e9-8bef-42010a14001a","cbec264e-773e-11e9-8bef-42010a14001a","cbec416a-773e-11e9-8bef-42010a14001a","cbec5ac4-773e-11e9-8bef-42010a14001a","cbec748c-773e-11e9-8bef-42010a14001a","cbec8f94-773e-11e9-8bef-42010a14001a","cbeca9fc-773e-11e9-8bef-42010a14001a","cbefa4ea-773e-11e9-8bef-42010a14001a","cbef8bae-773e-11e9-8bef-42010a14001a","cbee9d3e-773e-11e9-8bef-42010a14001a","cbee83f8-773e-11e9-8bef-42010a14001a","cbed5eb0-773e-11e9-8bef-42010a14001a","cbee505e-773e-11e9-8bef-42010a14001a","cbed792c-773e-11e9-8bef-42010a14001a","cbee35ce-773e-11e9-8bef-42010a14001a","cbed943e-773e-11e9-8bef-42010a14001a","cbedaf8c-773e-11e9-8bef-42010a14001a","cbedca3a-773e-11e9-8bef-42010a14001a","cbede538-773e-11e9-8bef-42010a14001a","cbedffe6-773e-11e9-8bef-42010a14001a","cbee1b98-773e-11e9-8bef-42010a14001a","cbef729a-773e-11e9-8bef-42010a14001a","cbef57d8-773e-11e9-8bef-42010a14001a","cbeebdd2-773e-11e9-8bef-42010a14001a","cbeed7b8-773e-11e9-8bef-42010a14001a","cbeef0fe-773e-11e9-8bef-42010a14001a","cbef0a80-773e-11e9-8bef-42010a14001a","cbef2416-773e-11e9-8bef-42010a14001a","cbef3e6a-773e-11e9-8bef-42010a14001a","cbf22f80-773e-11e9-8bef-42010a14001a","cbf21554-773e-11e9-8bef-42010a14001a","cbf122a2-773e-11e9-8bef-42010a14001a","cbf1079a-773e-11e9-8bef-42010a14001a","cbefe018-773e-11e9-8bef-42010a14001a","cbf0d3ec-773e-11e9-8bef-42010a14001a","cbeff90e-773e-11e9-8bef-42010a14001a","cbf0b858-773e-11e9-8bef-42010a14001a","cbf0147a-773e-11e9-8bef-42010a14001a","cbf03072-773e-11e9-8bef-42010a14001a","cbf04b3e-773e-11e9-8bef-42010a14001a","cbf06600-773e-11e9-8bef-42010a14001a","cbf08388-773e-11e9-8bef-42010a14001a","cbf09dfa-773e-11e9-8bef-42010a14001a","cbf1fb28-773e-11e9-8bef-42010a14001a","cbf1e048-773e-11e9-8bef-42010a14001a","cbf1434a-773e-11e9-8bef-42010a14001a","cbf15d80-773e-11e9-8bef-42010a14001a","cbf176a8-773e-11e9-8bef-42010a14001a","cbf192aa-773e-11e9-8bef-42010a14001a","cbf1ac86-773e-11e9-8bef-42010a14001a","cbf1c6d0-773e-11e9-8bef-42010a14001a","cbf4b0e8-773e-11e9-8bef-42010a14001a","cbf4977a-773e-11e9-8bef-42010a14001a","cbf3a7f2-773e-11e9-8bef-42010a14001a","cbf38ea2-773e-11e9-8bef-42010a14001a","cbf26afe-773e-11e9-8bef-42010a14001a","cbf359c8-773e-11e9-8bef-42010a14001a","cbf28340-773e-11e9-8bef-42010a14001a","cbf33f9c-773e-11e9-8bef-42010a14001a","cbf29e98-773e-11e9-8bef-42010a14001a","cbf2b90a-773e-11e9-8bef-42010a14001a","cbf2d390-773e-11e9-8bef-42010a14001a","cbf2efb0-773e-11e9-8bef-42010a14001a","cbf30a90-773e-11e9-8bef-42010a14001a","cbf32552-773e-11e9-8bef-42010a14001a","cbf47c68-773e-11e9-8bef-42010a14001a","cbf46192-773e-11e9-8bef-42010a14001a","cbf3c836-773e-11e9-8bef-42010a14001a","cbf3e1e0-773e-11e9-8bef-42010a14001a","cbf3fb3a-773e-11e9-8bef-42010a14001a","cbf4148a-773e-11e9-8bef-42010a14001a","cbf42f6a-773e-11e9-8bef-42010a14001a","cbf44856-773e-11e9-8bef-42010a14001a","cbf7415a-773e-11e9-8bef-42010a14001a","cbf72760-773e-11e9-8bef-42010a14001a","cbf62b8a-773e-11e9-8bef-42010a14001a","cbf611ea-773e-11e9-8bef-42010a14001a","cbf4ecf2-773e-11e9-8bef-42010a14001a","cbf5dcb6-773e-11e9-8bef-42010a14001a","cbf504da-773e-11e9-8bef-42010a14001a","cbf5bf7e-773e-11e9-8bef-42010a14001a","cbf51fe2-773e-11e9-8bef-42010a14001a","cbf53b08-773e-11e9-8bef-42010a14001a","cbf55548-773e-11e9-8bef-42010a14001a","cbf57122-773e-11e9-8bef-42010a14001a","cbf58b8a-773e-11e9-8bef-42010a14001a","cbf5a57a-773e-11e9-8bef-42010a14001a","cbf70d3e-773e-11e9-8bef-42010a14001a","cbf6e4c6-773e-11e9-8bef-42010a14001a","cbf64afc-773e-11e9-8bef-42010a14001a","cbf6647e-773e-11e9-8bef-42010a14001a","cbf67d92-773e-11e9-8bef-42010a14001a","cbf698cc-773e-11e9-8bef-42010a14001a","cbf6b26c-773e-11e9-8bef-42010a14001a","cbf6cba8-773e-11e9-8bef-42010a14001a","cbf9c290-773e-11e9-8bef-42010a14001a","cbf9a936-773e-11e9-8bef-42010a14001a","cbf8b602-773e-11e9-8bef-42010a14001a","cbf89ce4-773e-11e9-8bef-42010a14001a","cbf7794a-773e-11e9-8bef-42010a14001a","cbf86918-773e-11e9-8bef-42010a14001a","cbf791c8-773e-11e9-8bef-42010a14001a","cbf84d66-773e-11e9-8bef-42010a14001a","cbf7ad02-773e-11e9-8bef-42010a14001a","cbf7c756-773e-11e9-8bef-42010a14001a","cbf7e358-773e-11e9-8bef-42010a14001a","cbf7fde8-773e-11e9-8bef-42010a14001a","cbf8186e-773e-11e9-8bef-42010a14001a","cbf83344-773e-11e9-8bef-42010a14001a","cbf98d48-773e-11e9-8bef-42010a14001a","cbf97218-773e-11e9-8bef-42010a14001a","cbf8d5ba-773e-11e9-8bef-42010a14001a","cbf8efa0-773e-11e9-8bef-42010a14001a","cbf90aa8-773e-11e9-8bef-42010a14001a","cbf924a2-773e-11e9-8bef-42010a14001a","cbf93ec4-773e-11e9-8bef-42010a14001a","cbf958fa-773e-11e9-8bef-42010a14001a","cbfc5ec4-773e-11e9-8bef-42010a14001a","cbfc461e-773e-11e9-8bef-42010a14001a","cbfb5416-773e-11e9-8bef-42010a14001a","cbfb2c98-773e-11e9-8bef-42010a14001a","cbf9fcce-773e-11e9-8bef-42010a14001a","cbfaf62e-773e-11e9-8bef-42010a14001a","cbfa16dc-773e-11e9-8bef-42010a14001a","cbfada9a-773e-11e9-8bef-42010a14001a","cbfa3252-773e-11e9-8bef-42010a14001a","cbfa512e-773e-11e9-8bef-42010a14001a","cbfa6d62-773e-11e9-8bef-42010a14001a","cbfa8824-773e-11e9-8bef-42010a14001a","cbfaa3b8-773e-11e9-8bef-42010a14001a","cbfabec0-773e-11e9-8bef-42010a14001a","cbfc2c1a-773e-11e9-8bef-42010a14001a","cbfc10f4-773e-11e9-8bef-42010a14001a","cbfb75a4-773e-11e9-8bef-42010a14001a","cbfb9066-773e-11e9-8bef-42010a14001a","cbfbaa42-773e-11e9-8bef-42010a14001a","cbfbc446-773e-11e9-8bef-42010a14001a","cbfbddb4-773e-11e9-8bef-42010a14001a","cbfbf72c-773e-11e9-8bef-42010a14001a","cbfee8a6-773e-11e9-8bef-42010a14001a","cbfecd3a-773e-11e9-8bef-42010a14001a","cbfdd92a-773e-11e9-8bef-42010a14001a","cbfdbfe4-773e-11e9-8bef-42010a14001a","cbfc9c04-773e-11e9-8bef-42010a14001a","cbfd8c36-773e-11e9-8bef-42010a14001a","cbfcb61c-773e-11e9-8bef-42010a14001a","cbfd71d8-773e-11e9-8bef-42010a14001a","cbfcd0f2-773e-11e9-8bef-42010a14001a","cbfceba0-773e-11e9-8bef-42010a14001a","cbfd06d0-773e-11e9-8bef-42010a14001a","cbfd20fc-773e-11e9-8bef-42010a14001a","cbfd3b82-773e-11e9-8bef-42010a14001a","cbfd57a2-773e-11e9-8bef-42010a14001a","cbfeb340-773e-11e9-8bef-42010a14001a","cbfe9798-773e-11e9-8bef-42010a14001a","cbfdfa0e-773e-11e9-8bef-42010a14001a","cbfe1426-773e-11e9-8bef-42010a14001a","cbfe2d62-773e-11e9-8bef-42010a14001a","cbfe477a-773e-11e9-8bef-42010a14001a","cbfe62aa-773e-11e9-8bef-42010a14001a","cbfe7bf0-773e-11e9-8bef-42010a14001a","cc016e78-773e-11e9-8bef-42010a14001a","cc015546-773e-11e9-8bef-42010a14001a","cc00667c-773e-11e9-8bef-42010a14001a","cc004c14-773e-11e9-8bef-42010a14001a","cbff23e8-773e-11e9-8bef-42010a14001a","cc00185c-773e-11e9-8bef-42010a14001a","cbff3dba-773e-11e9-8bef-42010a14001a","cbfffd04-773e-11e9-8bef-42010a14001a","cbff59c6-773e-11e9-8bef-42010a14001a","cbff753c-773e-11e9-8bef-42010a14001a","cbff8fe0-773e-11e9-8bef-42010a14001a","cbffaa98-773e-11e9-8bef-42010a14001a","cbffc6b8-773e-11e9-8bef-42010a14001a","cbffe102-773e-11e9-8bef-42010a14001a","cc013b9c-773e-11e9-8bef-42010a14001a","cc0120e4-773e-11e9-8bef-42010a14001a","cc0085ee-773e-11e9-8bef-42010a14001a","cc009f34-773e-11e9-8bef-42010a14001a","cc00b8c0-773e-11e9-8bef-42010a14001a","cc00d2c4-773e-11e9-8bef-42010a14001a","cc00ec64-773e-11e9-8bef-42010a14001a","cc010744-773e-11e9-8bef-42010a14001a","cc01dade-773e-11e9-8bef-42010a14001a","cc01f4e2-773e-11e9-8bef-42010a14001a"],"label":["CV_","bundle","CV_Stack","bundle","Stack","bundle","Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP->Stack)","bundle","Lrnr_pkg_SuperLearner_screener_screen.corP","Stack","chain","bundle","Lrnr_glm_TRUE","Lrnr_mean","Lrnr_ranger_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_pkg_SuperLearner_SL.gam","Lrnr_pkg_SuperLearner_SL.bayesglm","Stack","bundle","Lrnr_glm_TRUE","Lrnr_mean","Lrnr_ranger_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_pkg_SuperLearner_SL.gam","Lrnr_pkg_SuperLearner_SL.bayesglm","bundle","Stack","bundle","Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP->Stack)","bundle","Lrnr_pkg_SuperLearner_screener_screen.corP","Stack","chain","bundle","Lrnr_glm_TRUE","Lrnr_mean","Lrnr_ranger_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_pkg_SuperLearner_SL.gam","Lrnr_pkg_SuperLearner_SL.bayesglm","Stack","bundle","Lrnr_glm_TRUE","Lrnr_mean","Lrnr_ranger_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_pkg_SuperLearner_SL.gam","Lrnr_pkg_SuperLearner_SL.bayesglm","Stack","bundle","Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP->Stack)","bundle","Lrnr_pkg_SuperLearner_screener_screen.corP","Stack","chain","bundle","Lrnr_glm_TRUE","Lrnr_mean","Lrnr_ranger_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_pkg_SuperLearner_SL.gam","Lrnr_pkg_SuperLearner_SL.bayesglm","Stack","bundle","Lrnr_glm_TRUE","Lrnr_mean","Lrnr_ranger_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_pkg_SuperLearner_SL.gam","Lrnr_pkg_SuperLearner_SL.bayesglm","Stack","bundle","Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP->Stack)","bundle","Lrnr_pkg_SuperLearner_screener_screen.corP","Stack","chain","bundle","Lrnr_glm_TRUE","Lrnr_mean","Lrnr_ranger_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_pkg_SuperLearner_SL.gam","Lrnr_pkg_SuperLearner_SL.bayesglm","Stack","bundle","Lrnr_glm_TRUE","Lrnr_mean","Lrnr_ranger_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_pkg_SuperLearner_SL.gam","Lrnr_pkg_SuperLearner_SL.bayesglm","Stack","bundle","Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP->Stack)","bundle","Lrnr_pkg_SuperLearner_screener_screen.corP","Stack","chain","bundle","Lrnr_glm_TRUE","Lrnr_mean","Lrnr_ranger_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_pkg_SuperLearner_SL.gam","Lrnr_pkg_SuperLearner_SL.bayesglm","Stack","bundle","Lrnr_glm_TRUE","Lrnr_mean","Lrnr_ranger_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_pkg_SuperLearner_SL.gam","Lrnr_pkg_SuperLearner_SL.bayesglm","Stack","bundle","Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP->Stack)","bundle","Lrnr_pkg_SuperLearner_screener_screen.corP","Stack","chain","bundle","Lrnr_glm_TRUE","Lrnr_mean","Lrnr_ranger_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_pkg_SuperLearner_SL.gam","Lrnr_pkg_SuperLearner_SL.bayesglm","Stack","bundle","Lrnr_glm_TRUE","Lrnr_mean","Lrnr_ranger_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_pkg_SuperLearner_SL.gam","Lrnr_pkg_SuperLearner_SL.bayesglm","Stack","bundle","Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP->Stack)","bundle","Lrnr_pkg_SuperLearner_screener_screen.corP","Stack","chain","bundle","Lrnr_glm_TRUE","Lrnr_mean","Lrnr_ranger_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_pkg_SuperLearner_SL.gam","Lrnr_pkg_SuperLearner_SL.bayesglm","Stack","bundle","Lrnr_glm_TRUE","Lrnr_mean","Lrnr_ranger_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_pkg_SuperLearner_SL.gam","Lrnr_pkg_SuperLearner_SL.bayesglm","Stack","bundle","Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP->Stack)","bundle","Lrnr_pkg_SuperLearner_screener_screen.corP","Stack","chain","bundle","Lrnr_glm_TRUE","Lrnr_mean","Lrnr_ranger_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_pkg_SuperLearner_SL.gam","Lrnr_pkg_SuperLearner_SL.bayesglm","Stack","bundle","Lrnr_glm_TRUE","Lrnr_mean","Lrnr_ranger_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_pkg_SuperLearner_SL.gam","Lrnr_pkg_SuperLearner_SL.bayesglm","Stack","bundle","Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP->Stack)","bundle","Lrnr_pkg_SuperLearner_screener_screen.corP","Stack","chain","bundle","Lrnr_glm_TRUE","Lrnr_mean","Lrnr_ranger_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_pkg_SuperLearner_SL.gam","Lrnr_pkg_SuperLearner_SL.bayesglm","Stack","bundle","Lrnr_glm_TRUE","Lrnr_mean","Lrnr_ranger_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_pkg_SuperLearner_SL.gam","Lrnr_pkg_SuperLearner_SL.bayesglm","Stack","bundle","Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP->Stack)","bundle","Lrnr_pkg_SuperLearner_screener_screen.corP","Stack","chain","bundle","Lrnr_glm_TRUE","Lrnr_mean","Lrnr_ranger_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_pkg_SuperLearner_SL.gam","Lrnr_pkg_SuperLearner_SL.bayesglm","Stack","bundle","Lrnr_glm_TRUE","Lrnr_mean","Lrnr_ranger_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_pkg_SuperLearner_SL.gam","Lrnr_pkg_SuperLearner_SL.bayesglm","Stack","bundle","Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP->Stack)","bundle","Lrnr_pkg_SuperLearner_screener_screen.corP","Stack","chain","bundle","Lrnr_glm_TRUE","Lrnr_mean","Lrnr_ranger_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_pkg_SuperLearner_SL.gam","Lrnr_pkg_SuperLearner_SL.bayesglm","Stack","bundle","Lrnr_glm_TRUE","Lrnr_mean","Lrnr_ranger_100_TRUE","Lrnr_glmnet_NULL_deviance_10_1_100_TRUE","Lrnr_pkg_SuperLearner_SL.gam","Lrnr_pkg_SuperLearner_SL.bayesglm","chain","Lrnr_nnls"],"level":[1,2,5,6,7,8,9,10,15,11,14,12,13,13,13,13,13,13,9,10,11,11,11,11,11,11,7,8,9,10,11,16,12,15,13,14,14,14,14,14,14,10,11,12,12,12,12,12,12,8,9,10,11,16,12,15,13,14,14,14,14,14,14,10,11,12,12,12,12,12,12,8,9,10,11,16,12,15,13,14,14,14,14,14,14,10,11,12,12,12,12,12,12,8,9,10,11,16,12,15,13,14,14,14,14,14,14,10,11,12,12,12,12,12,12,8,9,10,11,16,12,15,13,14,14,14,14,14,14,10,11,12,12,12,12,12,12,8,9,10,11,16,12,15,13,14,14,14,14,14,14,10,11,12,12,12,12,12,12,8,9,10,11,16,12,15,13,14,14,14,14,14,14,10,11,12,12,12,12,12,12,8,9,10,11,16,12,15,13,14,14,14,14,14,14,10,11,12,12,12,12,12,12,8,9,10,11,16,12,15,13,14,14,14,14,14,14,10,11,12,12,12,12,12,12,8,9,10,11,16,12,15,13,14,14,14,14,14,14,10,11,12,12,12,12,12,12,4,3],"sequential":[true,true,true,true,true,true,true,true,false,true,true,true,false,false,false,false,false,false,true,true,false,false,false,false,false,false,true,true,true,true,true,false,true,true,true,false,false,false,false,false,false,true,true,false,false,false,false,false,false,true,true,true,true,false,true,true,true,false,false,false,false,false,false,true,true,false,false,false,false,false,false,true,true,true,true,false,true,true,true,false,false,false,false,false,false,true,true,false,false,false,false,false,false,true,true,true,true,false,true,true,true,false,false,false,false,false,false,true,true,false,false,false,false,false,false,true,true,true,true,false,true,true,true,false,false,false,false,false,false,true,true,false,false,false,false,false,false,true,true,true,true,false,true,true,true,false,false,false,false,false,false,true,true,false,false,false,false,false,false,true,true,true,true,false,true,true,true,false,false,false,false,false,false,true,true,false,false,false,false,false,false,true,true,true,true,false,true,true,true,false,false,false,false,false,false,true,true,false,false,false,false,false,false,true,true,true,true,false,true,true,true,false,false,false,false,false,false,true,true,false,false,false,false,false,false,true,true,true,true,false,true,true,true,false,false,false,false,false,false,true,true,false,false,false,false,false,false,true,false],"state":["waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","ready","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","ready","ready","ready","ready","ready","ready","waiting","waiting","waiting","waiting","waiting","ready","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","ready","ready","ready","ready","ready","ready","waiting","waiting","waiting","waiting","ready","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","ready","ready","ready","ready","ready","ready","waiting","waiting","waiting","waiting","ready","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","ready","ready","ready","ready","ready","ready","waiting","waiting","waiting","waiting","ready","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","ready","ready","ready","ready","ready","ready","waiting","waiting","waiting","waiting","ready","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","ready","ready","ready","ready","ready","ready","waiting","waiting","waiting","waiting","ready","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","ready","ready","ready","ready","ready","ready","waiting","waiting","waiting","waiting","ready","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","ready","ready","ready","ready","ready","ready","waiting","waiting","waiting","waiting","ready","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","ready","ready","ready","ready","ready","ready","waiting","waiting","waiting","waiting","ready","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","ready","ready","ready","ready","ready","ready","waiting","waiting","waiting","waiting","ready","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","waiting","ready","ready","ready","ready","ready","ready","waiting","waiting"],"group":["none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none","none"]},"edges":{"from":["cbd3d0b2-773e-11e9-8bef-42010a14001a","cbd3d0b2-773e-11e9-8bef-42010a14001a","cbd3edb8-773e-11e9-8bef-42010a14001a","cbd3edb8-773e-11e9-8bef-42010a14001a","cbd40a14-773e-11e9-8bef-42010a14001a","cbd3edb8-773e-11e9-8bef-42010a14001a","cbd4260c-773e-11e9-8bef-42010a14001a","cbd3edb8-773e-11e9-8bef-42010a14001a","cbd44088-773e-11e9-8bef-42010a14001a","cbd3edb8-773e-11e9-8bef-42010a14001a","cbd45ae6-773e-11e9-8bef-42010a14001a","cbd3edb8-773e-11e9-8bef-42010a14001a","cbd478d2-773e-11e9-8bef-42010a14001a","cbd3edb8-773e-11e9-8bef-42010a14001a","cbd49416-773e-11e9-8bef-42010a14001a","cbd4b1c6-773e-11e9-8bef-42010a14001a","cbd4cce2-773e-11e9-8bef-42010a14001a","cbd5039c-773e-11e9-8bef-42010a14001a","cbd51d46-773e-11e9-8bef-42010a14001a","cbd53d1c-773e-11e9-8bef-42010a14001a","cbd556bc-773e-11e9-8bef-42010a14001a","cbd57034-773e-11e9-8bef-42010a14001a","cbd58920-773e-11e9-8bef-42010a14001a","cbd5a2f2-773e-11e9-8bef-42010a14001a","cbd5bc4c-773e-11e9-8bef-42010a14001a","cbd5d60a-773e-11e9-8bef-42010a14001a","cbd5f054-773e-11e9-8bef-42010a14001a","cbd609d6-773e-11e9-8bef-42010a14001a","cbd622d6-773e-11e9-8bef-42010a14001a","cbe8380e-773e-11e9-8bef-42010a14001a","cbe8380e-773e-11e9-8bef-42010a14001a","cbe853fc-773e-11e9-8bef-42010a14001a","cbe853fc-773e-11e9-8bef-42010a14001a","cbe870e4-773e-11e9-8bef-42010a14001a","cbe853fc-773e-11e9-8bef-42010a14001a","cbe88e12-773e-11e9-8bef-42010a14001a","cbe853fc-773e-11e9-8bef-42010a14001a","cbe8a938-773e-11e9-8bef-42010a14001a","cbe853fc-773e-11e9-8bef-42010a14001a","cbe8c3d2-773e-11e9-8bef-42010a14001a","cbe853fc-773e-11e9-8bef-42010a14001a","cbe8de62-773e-11e9-8bef-42010a14001a","cbe853fc-773e-11e9-8bef-42010a14001a","cbe8fd0c-773e-11e9-8bef-42010a14001a","cbe917c4-773e-11e9-8bef-42010a14001a","cbe93452-773e-11e9-8bef-42010a14001a","cbe969c2-773e-11e9-8bef-42010a14001a","cbe9839e-773e-11e9-8bef-42010a14001a","cbe9a2d4-773e-11e9-8bef-42010a14001a","cbe9bc4c-773e-11e9-8bef-42010a14001a","cbe9d6d2-773e-11e9-8bef-42010a14001a","cbe9f090-773e-11e9-8bef-42010a14001a","cbea0a1c-773e-11e9-8bef-42010a14001a","cbea23bc-773e-11e9-8bef-42010a14001a","cbea3c80-773e-11e9-8bef-42010a14001a","cbea576a-773e-11e9-8bef-42010a14001a","cbea72ae-773e-11e9-8bef-42010a14001a","cbea8c3a-773e-11e9-8bef-42010a14001a","cbeac59c-773e-11e9-8bef-42010a14001a","cbeac59c-773e-11e9-8bef-42010a14001a","cbeadffa-773e-11e9-8bef-42010a14001a","cbeadffa-773e-11e9-8bef-42010a14001a","cbeafc9c-773e-11e9-8bef-42010a14001a","cbeadffa-773e-11e9-8bef-42010a14001a","cbeb18da-773e-11e9-8bef-42010a14001a","cbeadffa-773e-11e9-8bef-42010a14001a","cbeb33e2-773e-11e9-8bef-42010a14001a","cbeadffa-773e-11e9-8bef-42010a14001a","cbeb4ef4-773e-11e9-8bef-42010a14001a","cbeadffa-773e-11e9-8bef-42010a14001a","cbeb697a-773e-11e9-8bef-42010a14001a","cbeadffa-773e-11e9-8bef-42010a14001a","cbeb83d8-773e-11e9-8bef-42010a14001a","cbeb9f1c-773e-11e9-8bef-42010a14001a","cbebb98e-773e-11e9-8bef-42010a14001a","cbebedc8-773e-11e9-8bef-42010a14001a","cbec072c-773e-11e9-8bef-42010a14001a","cbec264e-773e-11e9-8bef-42010a14001a","cbec416a-773e-11e9-8bef-42010a14001a","cbec5ac4-773e-11e9-8bef-42010a14001a","cbec748c-773e-11e9-8bef-42010a14001a","cbec8f94-773e-11e9-8bef-42010a14001a","cbeca9fc-773e-11e9-8bef-42010a14001a","cbecc536-773e-11e9-8bef-42010a14001a","cbece21e-773e-11e9-8bef-42010a14001a","cbecfc7c-773e-11e9-8bef-42010a14001a","cbed230a-773e-11e9-8bef-42010a14001a","cbed5eb0-773e-11e9-8bef-42010a14001a","cbed5eb0-773e-11e9-8bef-42010a14001a","cbed792c-773e-11e9-8bef-42010a14001a","cbed792c-773e-11e9-8bef-42010a14001a","cbed943e-773e-11e9-8bef-42010a14001a","cbed792c-773e-11e9-8bef-42010a14001a","cbedaf8c-773e-11e9-8bef-42010a14001a","cbed792c-773e-11e9-8bef-42010a14001a","cbedca3a-773e-11e9-8bef-42010a14001a","cbed792c-773e-11e9-8bef-42010a14001a","cbede538-773e-11e9-8bef-42010a14001a","cbed792c-773e-11e9-8bef-42010a14001a","cbedffe6-773e-11e9-8bef-42010a14001a","cbed792c-773e-11e9-8bef-42010a14001a","cbee1b98-773e-11e9-8bef-42010a14001a","cbee35ce-773e-11e9-8bef-42010a14001a","cbee505e-773e-11e9-8bef-42010a14001a","cbee83f8-773e-11e9-8bef-42010a14001a","cbee9d3e-773e-11e9-8bef-42010a14001a","cbeebdd2-773e-11e9-8bef-42010a14001a","cbeed7b8-773e-11e9-8bef-42010a14001a","cbeef0fe-773e-11e9-8bef-42010a14001a","cbef0a80-773e-11e9-8bef-42010a14001a","cbef2416-773e-11e9-8bef-42010a14001a","cbef3e6a-773e-11e9-8bef-42010a14001a","cbef57d8-773e-11e9-8bef-42010a14001a","cbef729a-773e-11e9-8bef-42010a14001a","cbef8bae-773e-11e9-8bef-42010a14001a","cbefa4ea-773e-11e9-8bef-42010a14001a","cbefe018-773e-11e9-8bef-42010a14001a","cbefe018-773e-11e9-8bef-42010a14001a","cbeff90e-773e-11e9-8bef-42010a14001a","cbeff90e-773e-11e9-8bef-42010a14001a","cbf0147a-773e-11e9-8bef-42010a14001a","cbeff90e-773e-11e9-8bef-42010a14001a","cbf03072-773e-11e9-8bef-42010a14001a","cbeff90e-773e-11e9-8bef-42010a14001a","cbf04b3e-773e-11e9-8bef-42010a14001a","cbeff90e-773e-11e9-8bef-42010a14001a","cbf06600-773e-11e9-8bef-42010a14001a","cbeff90e-773e-11e9-8bef-42010a14001a","cbf08388-773e-11e9-8bef-42010a14001a","cbeff90e-773e-11e9-8bef-42010a14001a","cbf09dfa-773e-11e9-8bef-42010a14001a","cbf0b858-773e-11e9-8bef-42010a14001a","cbf0d3ec-773e-11e9-8bef-42010a14001a","cbf1079a-773e-11e9-8bef-42010a14001a","cbf122a2-773e-11e9-8bef-42010a14001a","cbf1434a-773e-11e9-8bef-42010a14001a","cbf15d80-773e-11e9-8bef-42010a14001a","cbf176a8-773e-11e9-8bef-42010a14001a","cbf192aa-773e-11e9-8bef-42010a14001a","cbf1ac86-773e-11e9-8bef-42010a14001a","cbf1c6d0-773e-11e9-8bef-42010a14001a","cbf1e048-773e-11e9-8bef-42010a14001a","cbf1fb28-773e-11e9-8bef-42010a14001a","cbf21554-773e-11e9-8bef-42010a14001a","cbf22f80-773e-11e9-8bef-42010a14001a","cbf26afe-773e-11e9-8bef-42010a14001a","cbf26afe-773e-11e9-8bef-42010a14001a","cbf28340-773e-11e9-8bef-42010a14001a","cbf28340-773e-11e9-8bef-42010a14001a","cbf29e98-773e-11e9-8bef-42010a14001a","cbf28340-773e-11e9-8bef-42010a14001a","cbf2b90a-773e-11e9-8bef-42010a14001a","cbf28340-773e-11e9-8bef-42010a14001a","cbf2d390-773e-11e9-8bef-42010a14001a","cbf28340-773e-11e9-8bef-42010a14001a","cbf2efb0-773e-11e9-8bef-42010a14001a","cbf28340-773e-11e9-8bef-42010a14001a","cbf30a90-773e-11e9-8bef-42010a14001a","cbf28340-773e-11e9-8bef-42010a14001a","cbf32552-773e-11e9-8bef-42010a14001a","cbf33f9c-773e-11e9-8bef-42010a14001a","cbf359c8-773e-11e9-8bef-42010a14001a","cbf38ea2-773e-11e9-8bef-42010a14001a","cbf3a7f2-773e-11e9-8bef-42010a14001a","cbf3c836-773e-11e9-8bef-42010a14001a","cbf3e1e0-773e-11e9-8bef-42010a14001a","cbf3fb3a-773e-11e9-8bef-42010a14001a","cbf4148a-773e-11e9-8bef-42010a14001a","cbf42f6a-773e-11e9-8bef-42010a14001a","cbf44856-773e-11e9-8bef-42010a14001a","cbf46192-773e-11e9-8bef-42010a14001a","cbf47c68-773e-11e9-8bef-42010a14001a","cbf4977a-773e-11e9-8bef-42010a14001a","cbf4b0e8-773e-11e9-8bef-42010a14001a","cbf4ecf2-773e-11e9-8bef-42010a14001a","cbf4ecf2-773e-11e9-8bef-42010a14001a","cbf504da-773e-11e9-8bef-42010a14001a","cbf504da-773e-11e9-8bef-42010a14001a","cbf51fe2-773e-11e9-8bef-42010a14001a","cbf504da-773e-11e9-8bef-42010a14001a","cbf53b08-773e-11e9-8bef-42010a14001a","cbf504da-773e-11e9-8bef-42010a14001a","cbf55548-773e-11e9-8bef-42010a14001a","cbf504da-773e-11e9-8bef-42010a14001a","cbf57122-773e-11e9-8bef-42010a14001a","cbf504da-773e-11e9-8bef-42010a14001a","cbf58b8a-773e-11e9-8bef-42010a14001a","cbf504da-773e-11e9-8bef-42010a14001a","cbf5a57a-773e-11e9-8bef-42010a14001a","cbf5bf7e-773e-11e9-8bef-42010a14001a","cbf5dcb6-773e-11e9-8bef-42010a14001a","cbf611ea-773e-11e9-8bef-42010a14001a","cbf62b8a-773e-11e9-8bef-42010a14001a","cbf64afc-773e-11e9-8bef-42010a14001a","cbf6647e-773e-11e9-8bef-42010a14001a","cbf67d92-773e-11e9-8bef-42010a14001a","cbf698cc-773e-11e9-8bef-42010a14001a","cbf6b26c-773e-11e9-8bef-42010a14001a","cbf6cba8-773e-11e9-8bef-42010a14001a","cbf6e4c6-773e-11e9-8bef-42010a14001a","cbf70d3e-773e-11e9-8bef-42010a14001a","cbf72760-773e-11e9-8bef-42010a14001a","cbf7415a-773e-11e9-8bef-42010a14001a","cbf7794a-773e-11e9-8bef-42010a14001a","cbf7794a-773e-11e9-8bef-42010a14001a","cbf791c8-773e-11e9-8bef-42010a14001a","cbf791c8-773e-11e9-8bef-42010a14001a","cbf7ad02-773e-11e9-8bef-42010a14001a","cbf791c8-773e-11e9-8bef-42010a14001a","cbf7c756-773e-11e9-8bef-42010a14001a","cbf791c8-773e-11e9-8bef-42010a14001a","cbf7e358-773e-11e9-8bef-42010a14001a","cbf791c8-773e-11e9-8bef-42010a14001a","cbf7fde8-773e-11e9-8bef-42010a14001a","cbf791c8-773e-11e9-8bef-42010a14001a","cbf8186e-773e-11e9-8bef-42010a14001a","cbf791c8-773e-11e9-8bef-42010a14001a","cbf83344-773e-11e9-8bef-42010a14001a","cbf84d66-773e-11e9-8bef-42010a14001a","cbf86918-773e-11e9-8bef-42010a14001a","cbf89ce4-773e-11e9-8bef-42010a14001a","cbf8b602-773e-11e9-8bef-42010a14001a","cbf8d5ba-773e-11e9-8bef-42010a14001a","cbf8efa0-773e-11e9-8bef-42010a14001a","cbf90aa8-773e-11e9-8bef-42010a14001a","cbf924a2-773e-11e9-8bef-42010a14001a","cbf93ec4-773e-11e9-8bef-42010a14001a","cbf958fa-773e-11e9-8bef-42010a14001a","cbf97218-773e-11e9-8bef-42010a14001a","cbf98d48-773e-11e9-8bef-42010a14001a","cbf9a936-773e-11e9-8bef-42010a14001a","cbf9c290-773e-11e9-8bef-42010a14001a","cbf9fcce-773e-11e9-8bef-42010a14001a","cbf9fcce-773e-11e9-8bef-42010a14001a","cbfa16dc-773e-11e9-8bef-42010a14001a","cbfa16dc-773e-11e9-8bef-42010a14001a","cbfa3252-773e-11e9-8bef-42010a14001a","cbfa16dc-773e-11e9-8bef-42010a14001a","cbfa512e-773e-11e9-8bef-42010a14001a","cbfa16dc-773e-11e9-8bef-42010a14001a","cbfa6d62-773e-11e9-8bef-42010a14001a","cbfa16dc-773e-11e9-8bef-42010a14001a","cbfa8824-773e-11e9-8bef-42010a14001a","cbfa16dc-773e-11e9-8bef-42010a14001a","cbfaa3b8-773e-11e9-8bef-42010a14001a","cbfa16dc-773e-11e9-8bef-42010a14001a","cbfabec0-773e-11e9-8bef-42010a14001a","cbfada9a-773e-11e9-8bef-42010a14001a","cbfaf62e-773e-11e9-8bef-42010a14001a","cbfb2c98-773e-11e9-8bef-42010a14001a","cbfb5416-773e-11e9-8bef-42010a14001a","cbfb75a4-773e-11e9-8bef-42010a14001a","cbfb9066-773e-11e9-8bef-42010a14001a","cbfbaa42-773e-11e9-8bef-42010a14001a","cbfbc446-773e-11e9-8bef-42010a14001a","cbfbddb4-773e-11e9-8bef-42010a14001a","cbfbf72c-773e-11e9-8bef-42010a14001a","cbfc10f4-773e-11e9-8bef-42010a14001a","cbfc2c1a-773e-11e9-8bef-42010a14001a","cbfc461e-773e-11e9-8bef-42010a14001a","cbfc5ec4-773e-11e9-8bef-42010a14001a","cbfc9c04-773e-11e9-8bef-42010a14001a","cbfc9c04-773e-11e9-8bef-42010a14001a","cbfcb61c-773e-11e9-8bef-42010a14001a","cbfcb61c-773e-11e9-8bef-42010a14001a","cbfcd0f2-773e-11e9-8bef-42010a14001a","cbfcb61c-773e-11e9-8bef-42010a14001a","cbfceba0-773e-11e9-8bef-42010a14001a","cbfcb61c-773e-11e9-8bef-42010a14001a","cbfd06d0-773e-11e9-8bef-42010a14001a","cbfcb61c-773e-11e9-8bef-42010a14001a","cbfd20fc-773e-11e9-8bef-42010a14001a","cbfcb61c-773e-11e9-8bef-42010a14001a","cbfd3b82-773e-11e9-8bef-42010a14001a","cbfcb61c-773e-11e9-8bef-42010a14001a","cbfd57a2-773e-11e9-8bef-42010a14001a","cbfd71d8-773e-11e9-8bef-42010a14001a","cbfd8c36-773e-11e9-8bef-42010a14001a","cbfdbfe4-773e-11e9-8bef-42010a14001a","cbfdd92a-773e-11e9-8bef-42010a14001a","cbfdfa0e-773e-11e9-8bef-42010a14001a","cbfe1426-773e-11e9-8bef-42010a14001a","cbfe2d62-773e-11e9-8bef-42010a14001a","cbfe477a-773e-11e9-8bef-42010a14001a","cbfe62aa-773e-11e9-8bef-42010a14001a","cbfe7bf0-773e-11e9-8bef-42010a14001a","cbfe9798-773e-11e9-8bef-42010a14001a","cbfeb340-773e-11e9-8bef-42010a14001a","cbfecd3a-773e-11e9-8bef-42010a14001a","cbfee8a6-773e-11e9-8bef-42010a14001a","cbff23e8-773e-11e9-8bef-42010a14001a","cbff23e8-773e-11e9-8bef-42010a14001a","cbff3dba-773e-11e9-8bef-42010a14001a","cbff3dba-773e-11e9-8bef-42010a14001a","cbff59c6-773e-11e9-8bef-42010a14001a","cbff3dba-773e-11e9-8bef-42010a14001a","cbff753c-773e-11e9-8bef-42010a14001a","cbff3dba-773e-11e9-8bef-42010a14001a","cbff8fe0-773e-11e9-8bef-42010a14001a","cbff3dba-773e-11e9-8bef-42010a14001a","cbffaa98-773e-11e9-8bef-42010a14001a","cbff3dba-773e-11e9-8bef-42010a14001a","cbffc6b8-773e-11e9-8bef-42010a14001a","cbff3dba-773e-11e9-8bef-42010a14001a","cbffe102-773e-11e9-8bef-42010a14001a","cbfffd04-773e-11e9-8bef-42010a14001a","cc00185c-773e-11e9-8bef-42010a14001a","cc004c14-773e-11e9-8bef-42010a14001a","cc00667c-773e-11e9-8bef-42010a14001a","cc0085ee-773e-11e9-8bef-42010a14001a","cc009f34-773e-11e9-8bef-42010a14001a","cc00b8c0-773e-11e9-8bef-42010a14001a","cc00d2c4-773e-11e9-8bef-42010a14001a","cc00ec64-773e-11e9-8bef-42010a14001a","cc010744-773e-11e9-8bef-42010a14001a","cc0120e4-773e-11e9-8bef-42010a14001a","cc013b9c-773e-11e9-8bef-42010a14001a","cc015546-773e-11e9-8bef-42010a14001a","cc016e78-773e-11e9-8bef-42010a14001a","cc018890-773e-11e9-8bef-42010a14001a","cc01a5be-773e-11e9-8bef-42010a14001a","cc01bf90-773e-11e9-8bef-42010a14001a","cc01bf90-773e-11e9-8bef-42010a14001a","cc01dade-773e-11e9-8bef-42010a14001a","cc01dade-773e-11e9-8bef-42010a14001a","cc01f4e2-773e-11e9-8bef-42010a14001a","cc020ffe-773e-11e9-8bef-42010a14001a"],"to":["cbd5039c-773e-11e9-8bef-42010a14001a","cbd3edb8-773e-11e9-8bef-42010a14001a","cbd4cce2-773e-11e9-8bef-42010a14001a","cbd40a14-773e-11e9-8bef-42010a14001a","cbd4b1c6-773e-11e9-8bef-42010a14001a","cbd4260c-773e-11e9-8bef-42010a14001a","cbd4b1c6-773e-11e9-8bef-42010a14001a","cbd44088-773e-11e9-8bef-42010a14001a","cbd4b1c6-773e-11e9-8bef-42010a14001a","cbd45ae6-773e-11e9-8bef-42010a14001a","cbd4b1c6-773e-11e9-8bef-42010a14001a","cbd478d2-773e-11e9-8bef-42010a14001a","cbd4b1c6-773e-11e9-8bef-42010a14001a","cbd49416-773e-11e9-8bef-42010a14001a","cbd4b1c6-773e-11e9-8bef-42010a14001a","cbd4cce2-773e-11e9-8bef-42010a14001a","cbd5039c-773e-11e9-8bef-42010a14001a","cbd51d46-773e-11e9-8bef-42010a14001a","cbd609d6-773e-11e9-8bef-42010a14001a","cbd5d60a-773e-11e9-8bef-42010a14001a","cbd5d60a-773e-11e9-8bef-42010a14001a","cbd5d60a-773e-11e9-8bef-42010a14001a","cbd5d60a-773e-11e9-8bef-42010a14001a","cbd5d60a-773e-11e9-8bef-42010a14001a","cbd5d60a-773e-11e9-8bef-42010a14001a","cbd5f054-773e-11e9-8bef-42010a14001a","cbd609d6-773e-11e9-8bef-42010a14001a","cbd622d6-773e-11e9-8bef-42010a14001a","cc01a5be-773e-11e9-8bef-42010a14001a","cbe969c2-773e-11e9-8bef-42010a14001a","cbe853fc-773e-11e9-8bef-42010a14001a","cbe93452-773e-11e9-8bef-42010a14001a","cbe870e4-773e-11e9-8bef-42010a14001a","cbe917c4-773e-11e9-8bef-42010a14001a","cbe88e12-773e-11e9-8bef-42010a14001a","cbe917c4-773e-11e9-8bef-42010a14001a","cbe8a938-773e-11e9-8bef-42010a14001a","cbe917c4-773e-11e9-8bef-42010a14001a","cbe8c3d2-773e-11e9-8bef-42010a14001a","cbe917c4-773e-11e9-8bef-42010a14001a","cbe8de62-773e-11e9-8bef-42010a14001a","cbe917c4-773e-11e9-8bef-42010a14001a","cbe8fd0c-773e-11e9-8bef-42010a14001a","cbe917c4-773e-11e9-8bef-42010a14001a","cbe93452-773e-11e9-8bef-42010a14001a","cbe969c2-773e-11e9-8bef-42010a14001a","cbe9839e-773e-11e9-8bef-42010a14001a","cbea72ae-773e-11e9-8bef-42010a14001a","cbea3c80-773e-11e9-8bef-42010a14001a","cbea3c80-773e-11e9-8bef-42010a14001a","cbea3c80-773e-11e9-8bef-42010a14001a","cbea3c80-773e-11e9-8bef-42010a14001a","cbea3c80-773e-11e9-8bef-42010a14001a","cbea3c80-773e-11e9-8bef-42010a14001a","cbea576a-773e-11e9-8bef-42010a14001a","cbea72ae-773e-11e9-8bef-42010a14001a","cbea8c3a-773e-11e9-8bef-42010a14001a","cc018890-773e-11e9-8bef-42010a14001a","cbebedc8-773e-11e9-8bef-42010a14001a","cbeadffa-773e-11e9-8bef-42010a14001a","cbebb98e-773e-11e9-8bef-42010a14001a","cbeafc9c-773e-11e9-8bef-42010a14001a","cbeb9f1c-773e-11e9-8bef-42010a14001a","cbeb18da-773e-11e9-8bef-42010a14001a","cbeb9f1c-773e-11e9-8bef-42010a14001a","cbeb33e2-773e-11e9-8bef-42010a14001a","cbeb9f1c-773e-11e9-8bef-42010a14001a","cbeb4ef4-773e-11e9-8bef-42010a14001a","cbeb9f1c-773e-11e9-8bef-42010a14001a","cbeb697a-773e-11e9-8bef-42010a14001a","cbeb9f1c-773e-11e9-8bef-42010a14001a","cbeb83d8-773e-11e9-8bef-42010a14001a","cbeb9f1c-773e-11e9-8bef-42010a14001a","cbebb98e-773e-11e9-8bef-42010a14001a","cbebedc8-773e-11e9-8bef-42010a14001a","cbec072c-773e-11e9-8bef-42010a14001a","cbecfc7c-773e-11e9-8bef-42010a14001a","cbecc536-773e-11e9-8bef-42010a14001a","cbecc536-773e-11e9-8bef-42010a14001a","cbecc536-773e-11e9-8bef-42010a14001a","cbecc536-773e-11e9-8bef-42010a14001a","cbecc536-773e-11e9-8bef-42010a14001a","cbecc536-773e-11e9-8bef-42010a14001a","cbece21e-773e-11e9-8bef-42010a14001a","cbecfc7c-773e-11e9-8bef-42010a14001a","cbed230a-773e-11e9-8bef-42010a14001a","cc018890-773e-11e9-8bef-42010a14001a","cbee83f8-773e-11e9-8bef-42010a14001a","cbed792c-773e-11e9-8bef-42010a14001a","cbee505e-773e-11e9-8bef-42010a14001a","cbed943e-773e-11e9-8bef-42010a14001a","cbee35ce-773e-11e9-8bef-42010a14001a","cbedaf8c-773e-11e9-8bef-42010a14001a","cbee35ce-773e-11e9-8bef-42010a14001a","cbedca3a-773e-11e9-8bef-42010a14001a","cbee35ce-773e-11e9-8bef-42010a14001a","cbede538-773e-11e9-8bef-42010a14001a","cbee35ce-773e-11e9-8bef-42010a14001a","cbedffe6-773e-11e9-8bef-42010a14001a","cbee35ce-773e-11e9-8bef-42010a14001a","cbee1b98-773e-11e9-8bef-42010a14001a","cbee35ce-773e-11e9-8bef-42010a14001a","cbee505e-773e-11e9-8bef-42010a14001a","cbee83f8-773e-11e9-8bef-42010a14001a","cbee9d3e-773e-11e9-8bef-42010a14001a","cbef8bae-773e-11e9-8bef-42010a14001a","cbef57d8-773e-11e9-8bef-42010a14001a","cbef57d8-773e-11e9-8bef-42010a14001a","cbef57d8-773e-11e9-8bef-42010a14001a","cbef57d8-773e-11e9-8bef-42010a14001a","cbef57d8-773e-11e9-8bef-42010a14001a","cbef57d8-773e-11e9-8bef-42010a14001a","cbef729a-773e-11e9-8bef-42010a14001a","cbef8bae-773e-11e9-8bef-42010a14001a","cbefa4ea-773e-11e9-8bef-42010a14001a","cc018890-773e-11e9-8bef-42010a14001a","cbf1079a-773e-11e9-8bef-42010a14001a","cbeff90e-773e-11e9-8bef-42010a14001a","cbf0d3ec-773e-11e9-8bef-42010a14001a","cbf0147a-773e-11e9-8bef-42010a14001a","cbf0b858-773e-11e9-8bef-42010a14001a","cbf03072-773e-11e9-8bef-42010a14001a","cbf0b858-773e-11e9-8bef-42010a14001a","cbf04b3e-773e-11e9-8bef-42010a14001a","cbf0b858-773e-11e9-8bef-42010a14001a","cbf06600-773e-11e9-8bef-42010a14001a","cbf0b858-773e-11e9-8bef-42010a14001a","cbf08388-773e-11e9-8bef-42010a14001a","cbf0b858-773e-11e9-8bef-42010a14001a","cbf09dfa-773e-11e9-8bef-42010a14001a","cbf0b858-773e-11e9-8bef-42010a14001a","cbf0d3ec-773e-11e9-8bef-42010a14001a","cbf1079a-773e-11e9-8bef-42010a14001a","cbf122a2-773e-11e9-8bef-42010a14001a","cbf21554-773e-11e9-8bef-42010a14001a","cbf1e048-773e-11e9-8bef-42010a14001a","cbf1e048-773e-11e9-8bef-42010a14001a","cbf1e048-773e-11e9-8bef-42010a14001a","cbf1e048-773e-11e9-8bef-42010a14001a","cbf1e048-773e-11e9-8bef-42010a14001a","cbf1e048-773e-11e9-8bef-42010a14001a","cbf1fb28-773e-11e9-8bef-42010a14001a","cbf21554-773e-11e9-8bef-42010a14001a","cbf22f80-773e-11e9-8bef-42010a14001a","cc018890-773e-11e9-8bef-42010a14001a","cbf38ea2-773e-11e9-8bef-42010a14001a","cbf28340-773e-11e9-8bef-42010a14001a","cbf359c8-773e-11e9-8bef-42010a14001a","cbf29e98-773e-11e9-8bef-42010a14001a","cbf33f9c-773e-11e9-8bef-42010a14001a","cbf2b90a-773e-11e9-8bef-42010a14001a","cbf33f9c-773e-11e9-8bef-42010a14001a","cbf2d390-773e-11e9-8bef-42010a14001a","cbf33f9c-773e-11e9-8bef-42010a14001a","cbf2efb0-773e-11e9-8bef-42010a14001a","cbf33f9c-773e-11e9-8bef-42010a14001a","cbf30a90-773e-11e9-8bef-42010a14001a","cbf33f9c-773e-11e9-8bef-42010a14001a","cbf32552-773e-11e9-8bef-42010a14001a","cbf33f9c-773e-11e9-8bef-42010a14001a","cbf359c8-773e-11e9-8bef-42010a14001a","cbf38ea2-773e-11e9-8bef-42010a14001a","cbf3a7f2-773e-11e9-8bef-42010a14001a","cbf4977a-773e-11e9-8bef-42010a14001a","cbf46192-773e-11e9-8bef-42010a14001a","cbf46192-773e-11e9-8bef-42010a14001a","cbf46192-773e-11e9-8bef-42010a14001a","cbf46192-773e-11e9-8bef-42010a14001a","cbf46192-773e-11e9-8bef-42010a14001a","cbf46192-773e-11e9-8bef-42010a14001a","cbf47c68-773e-11e9-8bef-42010a14001a","cbf4977a-773e-11e9-8bef-42010a14001a","cbf4b0e8-773e-11e9-8bef-42010a14001a","cc018890-773e-11e9-8bef-42010a14001a","cbf611ea-773e-11e9-8bef-42010a14001a","cbf504da-773e-11e9-8bef-42010a14001a","cbf5dcb6-773e-11e9-8bef-42010a14001a","cbf51fe2-773e-11e9-8bef-42010a14001a","cbf5bf7e-773e-11e9-8bef-42010a14001a","cbf53b08-773e-11e9-8bef-42010a14001a","cbf5bf7e-773e-11e9-8bef-42010a14001a","cbf55548-773e-11e9-8bef-42010a14001a","cbf5bf7e-773e-11e9-8bef-42010a14001a","cbf57122-773e-11e9-8bef-42010a14001a","cbf5bf7e-773e-11e9-8bef-42010a14001a","cbf58b8a-773e-11e9-8bef-42010a14001a","cbf5bf7e-773e-11e9-8bef-42010a14001a","cbf5a57a-773e-11e9-8bef-42010a14001a","cbf5bf7e-773e-11e9-8bef-42010a14001a","cbf5dcb6-773e-11e9-8bef-42010a14001a","cbf611ea-773e-11e9-8bef-42010a14001a","cbf62b8a-773e-11e9-8bef-42010a14001a","cbf72760-773e-11e9-8bef-42010a14001a","cbf6e4c6-773e-11e9-8bef-42010a14001a","cbf6e4c6-773e-11e9-8bef-42010a14001a","cbf6e4c6-773e-11e9-8bef-42010a14001a","cbf6e4c6-773e-11e9-8bef-42010a14001a","cbf6e4c6-773e-11e9-8bef-42010a14001a","cbf6e4c6-773e-11e9-8bef-42010a14001a","cbf70d3e-773e-11e9-8bef-42010a14001a","cbf72760-773e-11e9-8bef-42010a14001a","cbf7415a-773e-11e9-8bef-42010a14001a","cc018890-773e-11e9-8bef-42010a14001a","cbf89ce4-773e-11e9-8bef-42010a14001a","cbf791c8-773e-11e9-8bef-42010a14001a","cbf86918-773e-11e9-8bef-42010a14001a","cbf7ad02-773e-11e9-8bef-42010a14001a","cbf84d66-773e-11e9-8bef-42010a14001a","cbf7c756-773e-11e9-8bef-42010a14001a","cbf84d66-773e-11e9-8bef-42010a14001a","cbf7e358-773e-11e9-8bef-42010a14001a","cbf84d66-773e-11e9-8bef-42010a14001a","cbf7fde8-773e-11e9-8bef-42010a14001a","cbf84d66-773e-11e9-8bef-42010a14001a","cbf8186e-773e-11e9-8bef-42010a14001a","cbf84d66-773e-11e9-8bef-42010a14001a","cbf83344-773e-11e9-8bef-42010a14001a","cbf84d66-773e-11e9-8bef-42010a14001a","cbf86918-773e-11e9-8bef-42010a14001a","cbf89ce4-773e-11e9-8bef-42010a14001a","cbf8b602-773e-11e9-8bef-42010a14001a","cbf9a936-773e-11e9-8bef-42010a14001a","cbf97218-773e-11e9-8bef-42010a14001a","cbf97218-773e-11e9-8bef-42010a14001a","cbf97218-773e-11e9-8bef-42010a14001a","cbf97218-773e-11e9-8bef-42010a14001a","cbf97218-773e-11e9-8bef-42010a14001a","cbf97218-773e-11e9-8bef-42010a14001a","cbf98d48-773e-11e9-8bef-42010a14001a","cbf9a936-773e-11e9-8bef-42010a14001a","cbf9c290-773e-11e9-8bef-42010a14001a","cc018890-773e-11e9-8bef-42010a14001a","cbfb2c98-773e-11e9-8bef-42010a14001a","cbfa16dc-773e-11e9-8bef-42010a14001a","cbfaf62e-773e-11e9-8bef-42010a14001a","cbfa3252-773e-11e9-8bef-42010a14001a","cbfada9a-773e-11e9-8bef-42010a14001a","cbfa512e-773e-11e9-8bef-42010a14001a","cbfada9a-773e-11e9-8bef-42010a14001a","cbfa6d62-773e-11e9-8bef-42010a14001a","cbfada9a-773e-11e9-8bef-42010a14001a","cbfa8824-773e-11e9-8bef-42010a14001a","cbfada9a-773e-11e9-8bef-42010a14001a","cbfaa3b8-773e-11e9-8bef-42010a14001a","cbfada9a-773e-11e9-8bef-42010a14001a","cbfabec0-773e-11e9-8bef-42010a14001a","cbfada9a-773e-11e9-8bef-42010a14001a","cbfaf62e-773e-11e9-8bef-42010a14001a","cbfb2c98-773e-11e9-8bef-42010a14001a","cbfb5416-773e-11e9-8bef-42010a14001a","cbfc461e-773e-11e9-8bef-42010a14001a","cbfc10f4-773e-11e9-8bef-42010a14001a","cbfc10f4-773e-11e9-8bef-42010a14001a","cbfc10f4-773e-11e9-8bef-42010a14001a","cbfc10f4-773e-11e9-8bef-42010a14001a","cbfc10f4-773e-11e9-8bef-42010a14001a","cbfc10f4-773e-11e9-8bef-42010a14001a","cbfc2c1a-773e-11e9-8bef-42010a14001a","cbfc461e-773e-11e9-8bef-42010a14001a","cbfc5ec4-773e-11e9-8bef-42010a14001a","cc018890-773e-11e9-8bef-42010a14001a","cbfdbfe4-773e-11e9-8bef-42010a14001a","cbfcb61c-773e-11e9-8bef-42010a14001a","cbfd8c36-773e-11e9-8bef-42010a14001a","cbfcd0f2-773e-11e9-8bef-42010a14001a","cbfd71d8-773e-11e9-8bef-42010a14001a","cbfceba0-773e-11e9-8bef-42010a14001a","cbfd71d8-773e-11e9-8bef-42010a14001a","cbfd06d0-773e-11e9-8bef-42010a14001a","cbfd71d8-773e-11e9-8bef-42010a14001a","cbfd20fc-773e-11e9-8bef-42010a14001a","cbfd71d8-773e-11e9-8bef-42010a14001a","cbfd3b82-773e-11e9-8bef-42010a14001a","cbfd71d8-773e-11e9-8bef-42010a14001a","cbfd57a2-773e-11e9-8bef-42010a14001a","cbfd71d8-773e-11e9-8bef-42010a14001a","cbfd8c36-773e-11e9-8bef-42010a14001a","cbfdbfe4-773e-11e9-8bef-42010a14001a","cbfdd92a-773e-11e9-8bef-42010a14001a","cbfecd3a-773e-11e9-8bef-42010a14001a","cbfe9798-773e-11e9-8bef-42010a14001a","cbfe9798-773e-11e9-8bef-42010a14001a","cbfe9798-773e-11e9-8bef-42010a14001a","cbfe9798-773e-11e9-8bef-42010a14001a","cbfe9798-773e-11e9-8bef-42010a14001a","cbfe9798-773e-11e9-8bef-42010a14001a","cbfeb340-773e-11e9-8bef-42010a14001a","cbfecd3a-773e-11e9-8bef-42010a14001a","cbfee8a6-773e-11e9-8bef-42010a14001a","cc018890-773e-11e9-8bef-42010a14001a","cc004c14-773e-11e9-8bef-42010a14001a","cbff3dba-773e-11e9-8bef-42010a14001a","cc00185c-773e-11e9-8bef-42010a14001a","cbff59c6-773e-11e9-8bef-42010a14001a","cbfffd04-773e-11e9-8bef-42010a14001a","cbff753c-773e-11e9-8bef-42010a14001a","cbfffd04-773e-11e9-8bef-42010a14001a","cbff8fe0-773e-11e9-8bef-42010a14001a","cbfffd04-773e-11e9-8bef-42010a14001a","cbffaa98-773e-11e9-8bef-42010a14001a","cbfffd04-773e-11e9-8bef-42010a14001a","cbffc6b8-773e-11e9-8bef-42010a14001a","cbfffd04-773e-11e9-8bef-42010a14001a","cbffe102-773e-11e9-8bef-42010a14001a","cbfffd04-773e-11e9-8bef-42010a14001a","cc00185c-773e-11e9-8bef-42010a14001a","cc004c14-773e-11e9-8bef-42010a14001a","cc00667c-773e-11e9-8bef-42010a14001a","cc015546-773e-11e9-8bef-42010a14001a","cc0120e4-773e-11e9-8bef-42010a14001a","cc0120e4-773e-11e9-8bef-42010a14001a","cc0120e4-773e-11e9-8bef-42010a14001a","cc0120e4-773e-11e9-8bef-42010a14001a","cc0120e4-773e-11e9-8bef-42010a14001a","cc0120e4-773e-11e9-8bef-42010a14001a","cc013b9c-773e-11e9-8bef-42010a14001a","cc015546-773e-11e9-8bef-42010a14001a","cc016e78-773e-11e9-8bef-42010a14001a","cc018890-773e-11e9-8bef-42010a14001a","cc01a5be-773e-11e9-8bef-42010a14001a","cc01bf90-773e-11e9-8bef-42010a14001a","cc020ffe-773e-11e9-8bef-42010a14001a","cc01dade-773e-11e9-8bef-42010a14001a","cc020ffe-773e-11e9-8bef-42010a14001a","cc01f4e2-773e-11e9-8bef-42010a14001a","cc020ffe-773e-11e9-8bef-42010a14001a","cc022ac0-773e-11e9-8bef-42010a14001a"],"label":["","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""]},"nodesToDataframe":true,"edgesToDataframe":true,"options":{"width":"100%","height":"100%","nodes":{"shape":"dot"},"manipulation":{"enabled":false},"edges":{"arrows":"to"},"layout":{"hierarchical":{"enabled":true,"levelSeparation":500,"nodeSpacing":200,"direction":"RL"}},"groups":{"useDefaultGroups":true,"none":{"color":{"border":"black","background":"white"}}}},"groups":["none"],"width":"100%","height":"400px","idselection":{"enabled":false},"byselection":{"enabled":false},"main":null,"submain":null,"footer":null,"background":"rgba(0, 0, 0, 0)"},"evals":[],"jsHooks":[]}</script>
<p><strong>3. Train the super learner on the machine learning task</strong></p>
<p>Now we are ready to <strong>“train”</strong> our super learner on our <code>sl3_task</code> object, <code>washb_task</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">sl_fit &lt;-<span class="st"> </span>sl<span class="op">$</span><span class="kw">train</span>(washb_task)</code></pre>
<p><strong>4. Obtain predicted values</strong></p>
<p>Now that we have fit the super learner, we are ready to obtain our predicted
values, and we can also obtain a summary of the results.</p>
<pre class="sourceCode r"><code class="sourceCode r">sl_preds &lt;-<span class="st"> </span>sl_fit<span class="op">$</span><span class="kw">predict</span>()
<span class="kw">head</span>(sl_preds)</code></pre>
<pre><code>[1] -0.5759581 -0.8972591 -0.6915767 -0.7653106 -0.6992900 -0.7528622</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">sl_fit<span class="op">$</span><span class="kw">print</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">kable</span>(<span class="dt">digits =</span> <span class="dv">4</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">kable_styling</span>(<span class="dt">fixed_thead =</span> T) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">scroll_box</span>(<span class="dt">width =</span> <span class="st">&quot;100%&quot;</span>, <span class="dt">height =</span> <span class="st">&quot;300px&quot;</span>)</code></pre>
<pre><code>[1] &quot;SuperLearner:&quot;
List of 2
 $ : chr &quot;Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)&quot;
 $ : chr &quot;Stack&quot;
[1] &quot;Lrnr_nnls&quot;
                                                                                                  lrnrs
 1:                           Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_glm_TRUE
 2:                               Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_mean
 3:                    Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_ranger_100_TRUE
 4: Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_glmnet_NULL_deviance_10_1_100_TRUE
 5:            Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_pkg_SuperLearner_SL.gam
 6:       Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_pkg_SuperLearner_SL.bayesglm
 7:                                                                                 Stack_Lrnr_glm_TRUE
 8:                                                                                     Stack_Lrnr_mean
 9:                                                                          Stack_Lrnr_ranger_100_TRUE
10:                                                       Stack_Lrnr_glmnet_NULL_deviance_10_1_100_TRUE
11:                                                                  Stack_Lrnr_pkg_SuperLearner_SL.gam
12:                                                             Stack_Lrnr_pkg_SuperLearner_SL.bayesglm
       weights
 1: 0.00000000
 2: 0.02397398
 3: 0.20383544
 4: 0.12345161
 5: 0.13219592
 6: 0.00000000
 7: 0.00000000
 8: 0.00000000
 9: 0.21739057
10: 0.00000000
11: 0.30132400
12: 0.00000000
[1] &quot;Cross-validated risk (MSE, squared error loss):&quot;
                                                                                                learner
 1:                           Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_glm_TRUE
 2:                               Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_mean
 3:                    Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_ranger_100_TRUE
 4: Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_glmnet_NULL_deviance_10_1_100_TRUE
 5:            Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_pkg_SuperLearner_SL.gam
 6:       Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_pkg_SuperLearner_SL.bayesglm
 7:                                                                                 Stack_Lrnr_glm_TRUE
 8:                                                                                     Stack_Lrnr_mean
 9:                                                                          Stack_Lrnr_ranger_100_TRUE
10:                                                       Stack_Lrnr_glmnet_NULL_deviance_10_1_100_TRUE
11:                                                                  Stack_Lrnr_pkg_SuperLearner_SL.gam
12:                                                             Stack_Lrnr_pkg_SuperLearner_SL.bayesglm
13:                                                                                        SuperLearner
    coefficients mean_risk    SE_risk    fold_SD fold_min_risk fold_max_risk
 1:           NA  1.015128 0.02363317 0.07629401     0.8927540      1.131594
 2:           NA  1.065282 0.02502664 0.09191791     0.9264292      1.196647
 3:           NA  1.020198 0.02353201 0.07956168     0.8788317      1.164011
 4:           NA  1.012042 0.02359063 0.07876676     0.8821712      1.130815
 5:           NA  1.011497 0.02357149 0.07449866     0.8919503      1.132290
 6:           NA  1.015119 0.02363328 0.07631510     0.8926608      1.131570
 7:           NA  1.018612 0.02380402 0.07799191     0.8956048      1.134940
 8:           NA  1.065282 0.02502664 0.09191791     0.9264292      1.196647
 9:           NA  1.017914 0.02355535 0.08529178     0.8819340      1.161558
10:           NA  1.012548 0.02359695 0.07921315     0.8826979      1.130114
11:           NA  1.012122 0.02358982 0.07486427     0.8981537      1.135950
12:           NA  1.018596 0.02380414 0.07801948     0.8954820      1.134909
13:           NA  1.005061 0.02340291 0.07907176     0.8766645      1.136870</code></pre>
<div style="border: 1px solid #ddd; padding: 0px; overflow-y: scroll; height:300px; overflow-x: scroll; width:100%; ">
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
learner
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
coefficients
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
mean_risk
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
SE_risk
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
fold_SD
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
fold_min_risk
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
fold_max_risk
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_glm_TRUE
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
1.0151
</td>
<td style="text-align:right;">
0.0236
</td>
<td style="text-align:right;">
0.0763
</td>
<td style="text-align:right;">
0.8928
</td>
<td style="text-align:right;">
1.1316
</td>
</tr>
<tr>
<td style="text-align:left;">
Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_mean
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
1.0653
</td>
<td style="text-align:right;">
0.0250
</td>
<td style="text-align:right;">
0.0919
</td>
<td style="text-align:right;">
0.9264
</td>
<td style="text-align:right;">
1.1966
</td>
</tr>
<tr>
<td style="text-align:left;">
Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_ranger_100_TRUE
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
1.0202
</td>
<td style="text-align:right;">
0.0235
</td>
<td style="text-align:right;">
0.0796
</td>
<td style="text-align:right;">
0.8788
</td>
<td style="text-align:right;">
1.1640
</td>
</tr>
<tr>
<td style="text-align:left;">
Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_glmnet_NULL_deviance_10_1_100_TRUE
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
1.0120
</td>
<td style="text-align:right;">
0.0236
</td>
<td style="text-align:right;">
0.0788
</td>
<td style="text-align:right;">
0.8822
</td>
<td style="text-align:right;">
1.1308
</td>
</tr>
<tr>
<td style="text-align:left;">
Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_pkg_SuperLearner_SL.gam
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
1.0115
</td>
<td style="text-align:right;">
0.0236
</td>
<td style="text-align:right;">
0.0745
</td>
<td style="text-align:right;">
0.8920
</td>
<td style="text-align:right;">
1.1323
</td>
</tr>
<tr>
<td style="text-align:left;">
Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_pkg_SuperLearner_SL.bayesglm
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
1.0151
</td>
<td style="text-align:right;">
0.0236
</td>
<td style="text-align:right;">
0.0763
</td>
<td style="text-align:right;">
0.8927
</td>
<td style="text-align:right;">
1.1316
</td>
</tr>
<tr>
<td style="text-align:left;">
Stack_Lrnr_glm_TRUE
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
1.0186
</td>
<td style="text-align:right;">
0.0238
</td>
<td style="text-align:right;">
0.0780
</td>
<td style="text-align:right;">
0.8956
</td>
<td style="text-align:right;">
1.1349
</td>
</tr>
<tr>
<td style="text-align:left;">
Stack_Lrnr_mean
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
1.0653
</td>
<td style="text-align:right;">
0.0250
</td>
<td style="text-align:right;">
0.0919
</td>
<td style="text-align:right;">
0.9264
</td>
<td style="text-align:right;">
1.1966
</td>
</tr>
<tr>
<td style="text-align:left;">
Stack_Lrnr_ranger_100_TRUE
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
1.0179
</td>
<td style="text-align:right;">
0.0236
</td>
<td style="text-align:right;">
0.0853
</td>
<td style="text-align:right;">
0.8819
</td>
<td style="text-align:right;">
1.1616
</td>
</tr>
<tr>
<td style="text-align:left;">
Stack_Lrnr_glmnet_NULL_deviance_10_1_100_TRUE
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
1.0125
</td>
<td style="text-align:right;">
0.0236
</td>
<td style="text-align:right;">
0.0792
</td>
<td style="text-align:right;">
0.8827
</td>
<td style="text-align:right;">
1.1301
</td>
</tr>
<tr>
<td style="text-align:left;">
Stack_Lrnr_pkg_SuperLearner_SL.gam
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
1.0121
</td>
<td style="text-align:right;">
0.0236
</td>
<td style="text-align:right;">
0.0749
</td>
<td style="text-align:right;">
0.8982
</td>
<td style="text-align:right;">
1.1359
</td>
</tr>
<tr>
<td style="text-align:left;">
Stack_Lrnr_pkg_SuperLearner_SL.bayesglm
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
1.0186
</td>
<td style="text-align:right;">
0.0238
</td>
<td style="text-align:right;">
0.0780
</td>
<td style="text-align:right;">
0.8955
</td>
<td style="text-align:right;">
1.1349
</td>
</tr>
<tr>
<td style="text-align:left;">
SuperLearner
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
1.0051
</td>
<td style="text-align:right;">
0.0234
</td>
<td style="text-align:right;">
0.0791
</td>
<td style="text-align:right;">
0.8767
</td>
<td style="text-align:right;">
1.1369
</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div id="extensions" class="section level2">
<h2><span class="header-section-number">3.4</span> Extensions</h2>
<div id="cross-validated-super-learner" class="section level3">
<h3><span class="header-section-number">3.4.1</span> Cross-validated Super Learner</h3>
<p>We can cross-validate the super learner to see how well the super learner
performs on unseen data. This requires an “external” layer of cross-validation,
also called nested cross-validation, which involves setting aside a separate
holdout sample that we don’t use to fit the super learner. This
external cross validation procedure may also incorporate 10 folds, which is the
default in <code>sl3</code>. However, we will incorporate 2 outer folds of
cross-validation for computational efficiency.</p>
<pre class="sourceCode r"><code class="sourceCode r">washb_task_new &lt;-<span class="st"> </span><span class="kw">make_sl3_Task</span>(
  <span class="dt">data =</span> washb_data,
  <span class="dt">covariates =</span> covars,
  <span class="dt">outcome =</span> outcome,
  <span class="dt">folds =</span> <span class="kw">make_folds</span>(washb_data, <span class="dt">fold_fun =</span> folds_vfold, <span class="dt">V =</span> <span class="dv">2</span>)
)</code></pre>
<pre><code>Warning in .subset2(public_bind_env, &quot;initialize&quot;)(...): Missing Covariate Data
Found. Imputing covariates using sl3_process_missing</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">CVsl &lt;-<span class="st"> </span><span class="kw">CV_lrnr_sl</span>(sl_fit, washb_task_new, loss_squared_error)
CVsl <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">kable</span>(<span class="dt">digits =</span> <span class="dv">4</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">kable_styling</span>(<span class="dt">fixed_thead =</span> T) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">scroll_box</span>(<span class="dt">width =</span> <span class="st">&quot;100%&quot;</span>, <span class="dt">height =</span> <span class="st">&quot;300px&quot;</span>)</code></pre>
<div style="border: 1px solid #ddd; padding: 0px; overflow-y: scroll; height:300px; overflow-x: scroll; width:100%; ">
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
learner
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
coefficients
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
mean_risk
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
SE_risk
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
fold_SD
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
fold_min_risk
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
fold_max_risk
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_glm_TRUE
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
1.0102
</td>
<td style="text-align:right;">
0.0235
</td>
<td style="text-align:right;">
0.0230
</td>
<td style="text-align:right;">
0.9939
</td>
<td style="text-align:right;">
1.0264
</td>
</tr>
<tr>
<td style="text-align:left;">
Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_mean
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
1.0652
</td>
<td style="text-align:right;">
0.0250
</td>
<td style="text-align:right;">
0.0306
</td>
<td style="text-align:right;">
1.0435
</td>
<td style="text-align:right;">
1.0868
</td>
</tr>
<tr>
<td style="text-align:left;">
Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_ranger_100_TRUE
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
1.0282
</td>
<td style="text-align:right;">
0.0237
</td>
<td style="text-align:right;">
0.0175
</td>
<td style="text-align:right;">
1.0158
</td>
<td style="text-align:right;">
1.0406
</td>
</tr>
<tr>
<td style="text-align:left;">
Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_glmnet_NULL_deviance_10_1_100_TRUE
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
1.0099
</td>
<td style="text-align:right;">
0.0235
</td>
<td style="text-align:right;">
0.0276
</td>
<td style="text-align:right;">
0.9904
</td>
<td style="text-align:right;">
1.0294
</td>
</tr>
<tr>
<td style="text-align:left;">
Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_pkg_SuperLearner_SL.gam
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
1.0105
</td>
<td style="text-align:right;">
0.0235
</td>
<td style="text-align:right;">
0.0220
</td>
<td style="text-align:right;">
0.9950
</td>
<td style="text-align:right;">
1.0261
</td>
</tr>
<tr>
<td style="text-align:left;">
Pipeline(Lrnr_pkg_SuperLearner_screener_screen.corP-&gt;Stack)_Lrnr_pkg_SuperLearner_SL.bayesglm
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
1.0101
</td>
<td style="text-align:right;">
0.0235
</td>
<td style="text-align:right;">
0.0230
</td>
<td style="text-align:right;">
0.9939
</td>
<td style="text-align:right;">
1.0264
</td>
</tr>
<tr>
<td style="text-align:left;">
Stack_Lrnr_glm_TRUE
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
1.0223
</td>
<td style="text-align:right;">
0.0246
</td>
<td style="text-align:right;">
0.0105
</td>
<td style="text-align:right;">
1.0149
</td>
<td style="text-align:right;">
1.0297
</td>
</tr>
<tr>
<td style="text-align:left;">
Stack_Lrnr_mean
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
1.0652
</td>
<td style="text-align:right;">
0.0250
</td>
<td style="text-align:right;">
0.0306
</td>
<td style="text-align:right;">
1.0435
</td>
<td style="text-align:right;">
1.0868
</td>
</tr>
<tr>
<td style="text-align:left;">
Stack_Lrnr_ranger_100_TRUE
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
1.0210
</td>
<td style="text-align:right;">
0.0236
</td>
<td style="text-align:right;">
0.0198
</td>
<td style="text-align:right;">
1.0071
</td>
<td style="text-align:right;">
1.0350
</td>
</tr>
<tr>
<td style="text-align:left;">
Stack_Lrnr_glmnet_NULL_deviance_10_1_100_TRUE
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
1.0101
</td>
<td style="text-align:right;">
0.0235
</td>
<td style="text-align:right;">
0.0272
</td>
<td style="text-align:right;">
0.9909
</td>
<td style="text-align:right;">
1.0294
</td>
</tr>
<tr>
<td style="text-align:left;">
Stack_Lrnr_pkg_SuperLearner_SL.gam
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
1.0339
</td>
<td style="text-align:right;">
0.0319
</td>
<td style="text-align:right;">
0.0121
</td>
<td style="text-align:right;">
1.0253
</td>
<td style="text-align:right;">
1.0424
</td>
</tr>
<tr>
<td style="text-align:left;">
Stack_Lrnr_pkg_SuperLearner_SL.bayesglm
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
1.0223
</td>
<td style="text-align:right;">
0.0246
</td>
<td style="text-align:right;">
0.0104
</td>
<td style="text-align:right;">
1.0149
</td>
<td style="text-align:right;">
1.0296
</td>
</tr>
<tr>
<td style="text-align:left;">
SuperLearner
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:right;">
1.0118
</td>
<td style="text-align:right;">
0.0235
</td>
<td style="text-align:right;">
0.0270
</td>
<td style="text-align:right;">
0.9927
</td>
<td style="text-align:right;">
1.0308
</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="variable-importance-analysis-with-sl3" class="section level3">
<h3><span class="header-section-number">3.4.2</span> Variable Importance Analysis with <code>sl3</code></h3>
<p>Variable importance can be interesting and informative. The <code>sl3</code> <code>varimp</code>
function returns a table with variables listed in decreasing order of
importance, in which the measure of importance is based on a risk difference
between the learner fit with a permuted covariate and the learner fit with the
true covariate, across all covariates.</p>
<p>In this manner, the larger the risk difference, the more important the variable
is in the prediction.</p>
<pre class="sourceCode r"><code class="sourceCode r">washb_varimp &lt;-<span class="st"> </span><span class="kw">varimp</span>(sl_fit, loss_squared_error)
washb_varimp <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">kable</span>(<span class="dt">digits =</span> <span class="dv">4</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">kable_styling</span>(<span class="dt">fixed_thead =</span> T) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">scroll_box</span>(<span class="dt">width =</span> <span class="st">&quot;100%&quot;</span>, <span class="dt">height =</span> <span class="st">&quot;300px&quot;</span>)</code></pre>
<div style="border: 1px solid #ddd; padding: 0px; overflow-y: scroll; height:300px; overflow-x: scroll; width:100%; ">
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
X
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
risk_diff
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
aged
</td>
<td style="text-align:right;">
0.0483
</td>
</tr>
<tr>
<td style="text-align:left;">
momedu
</td>
<td style="text-align:right;">
0.0088
</td>
</tr>
<tr>
<td style="text-align:left;">
tr
</td>
<td style="text-align:right;">
0.0059
</td>
</tr>
<tr>
<td style="text-align:left;">
month
</td>
<td style="text-align:right;">
0.0055
</td>
</tr>
<tr>
<td style="text-align:left;">
floor
</td>
<td style="text-align:right;">
0.0030
</td>
</tr>
<tr>
<td style="text-align:left;">
hfiacat
</td>
<td style="text-align:right;">
0.0028
</td>
</tr>
<tr>
<td style="text-align:left;">
asset_refrig
</td>
<td style="text-align:right;">
0.0027
</td>
</tr>
<tr>
<td style="text-align:left;">
asset_chair
</td>
<td style="text-align:right;">
0.0026
</td>
</tr>
<tr>
<td style="text-align:left;">
Nlt18
</td>
<td style="text-align:right;">
0.0024
</td>
</tr>
<tr>
<td style="text-align:left;">
momheight
</td>
<td style="text-align:right;">
0.0020
</td>
</tr>
<tr>
<td style="text-align:left;">
asset_chouki
</td>
<td style="text-align:right;">
0.0019
</td>
</tr>
<tr>
<td style="text-align:left;">
fracode
</td>
<td style="text-align:right;">
0.0017
</td>
</tr>
<tr>
<td style="text-align:left;">
momage
</td>
<td style="text-align:right;">
0.0016
</td>
</tr>
<tr>
<td style="text-align:left;">
elec
</td>
<td style="text-align:right;">
0.0013
</td>
</tr>
<tr>
<td style="text-align:left;">
asset_moto
</td>
<td style="text-align:right;">
0.0011
</td>
</tr>
<tr>
<td style="text-align:left;">
asset_table
</td>
<td style="text-align:right;">
0.0008
</td>
</tr>
<tr>
<td style="text-align:left;">
watmin
</td>
<td style="text-align:right;">
0.0007
</td>
</tr>
<tr>
<td style="text-align:left;">
asset_khat
</td>
<td style="text-align:right;">
0.0006
</td>
</tr>
<tr>
<td style="text-align:left;">
walls
</td>
<td style="text-align:right;">
0.0004
</td>
</tr>
<tr>
<td style="text-align:left;">
sex
</td>
<td style="text-align:right;">
0.0002
</td>
</tr>
<tr>
<td style="text-align:left;">
asset_wardrobe
</td>
<td style="text-align:right;">
0.0001
</td>
</tr>
<tr>
<td style="text-align:left;">
delta_momage
</td>
<td style="text-align:right;">
-0.0001
</td>
</tr>
<tr>
<td style="text-align:left;">
asset_tv
</td>
<td style="text-align:right;">
-0.0001
</td>
</tr>
<tr>
<td style="text-align:left;">
roof
</td>
<td style="text-align:right;">
-0.0002
</td>
</tr>
<tr>
<td style="text-align:left;">
delta_momheight
</td>
<td style="text-align:right;">
-0.0002
</td>
</tr>
<tr>
<td style="text-align:left;">
asset_sewmach
</td>
<td style="text-align:right;">
-0.0003
</td>
</tr>
<tr>
<td style="text-align:left;">
asset_bike
</td>
<td style="text-align:right;">
-0.0006
</td>
</tr>
<tr>
<td style="text-align:left;">
asset_mobile
</td>
<td style="text-align:right;">
-0.0009
</td>
</tr>
<tr>
<td style="text-align:left;">
Ncomp
</td>
<td style="text-align:right;">
-0.0015
</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div id="exercise" class="section level2">
<h2><span class="header-section-number">3.5</span> Exercise</h2>
<div id="predicting-myocardial-infarction-with-sl3" class="section level3">
<h3><span class="header-section-number">3.5.1</span> Predicting Myocardial Infarction with <code>sl3</code></h3>
<p>Follow the steps below to predict myocardial infarction (<code>mi</code>) using the
available covariate data. Thanks to Professor David Benkeser at Emory University
for making the this Cardiovascular Health Study (CHS) data accessible.</p>
<p>Work with a buddy/team. You have 20 minutes.</p>
<p>In the etherpad, submit your group’s answers to the following questions.</p>
<ol style="list-style-type: decimal">
<li>Which learner was the discrete super learner? What was the cross validated
mean risk of the discrete super learner?</li>
<li>What was the cross validated risk of the continuous super learner?</li>
<li>Did your group face any challenges?</li>
</ol>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># load the data set</span>
db_data &lt;-
<span class="st"> </span><span class="kw">url</span>(<span class="st">&quot;https://raw.githubusercontent.com/benkeser/sllecture/master/chspred.csv&quot;</span>)
chspred &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="dt">file =</span> db_data, <span class="dt">col_names =</span> <span class="ot">TRUE</span>)</code></pre>
<pre><code>Parsed with column specification:
cols(
  .default = col_double()
)</code></pre>
<pre><code>See spec(...) for full column specifications.</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># take a quick peek</span>
<span class="kw">head</span>(chspred) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">kable</span>(<span class="dt">digits =</span> <span class="dv">4</span>) <span class="op">%&gt;%</span>
<span class="st">  </span>kableExtra<span class="op">:::</span><span class="kw">kable_styling</span>(<span class="dt">fixed_thead =</span> T) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">scroll_box</span>(<span class="dt">width =</span> <span class="st">&quot;100%&quot;</span>, <span class="dt">height =</span> <span class="st">&quot;300px&quot;</span>)</code></pre>
<div style="border: 1px solid #ddd; padding: 0px; overflow-y: scroll; height:300px; overflow-x: scroll; width:100%; ">
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
waist
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
alcoh
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
hdl
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
beta
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
smoke
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
ace
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
ldl
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
bmi
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
aspirin
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
gend
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
age
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
estrgn
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
glu
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
ins
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
cysgfr
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
dm
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
fetuina
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
whr
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
hsed
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
race
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
logcystat
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
logtrig
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
logcrp
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
logcre
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
health
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
logkcal
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
sysbp
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;position: sticky; top:0; background-color: #FFFFFF;">
mi
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
110.1642
</td>
<td style="text-align:right;">
0.0000
</td>
<td style="text-align:right;">
66.4974
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
114.2162
</td>
<td style="text-align:right;">
27.9975
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
73.5179
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
159.9314
</td>
<td style="text-align:right;">
70.3343
</td>
<td style="text-align:right;">
75.0078
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0.1752
</td>
<td style="text-align:right;">
1.1690
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
-0.3420
</td>
<td style="text-align:right;">
5.4063
</td>
<td style="text-align:right;">
2.0126
</td>
<td style="text-align:right;">
-0.6739
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
4.3926
</td>
<td style="text-align:right;">
177.1345
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:right;">
89.9763
</td>
<td style="text-align:right;">
0.0000
</td>
<td style="text-align:right;">
50.0652
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
103.7766
</td>
<td style="text-align:right;">
20.8931
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
61.7723
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
153.3888
</td>
<td style="text-align:right;">
33.9695
</td>
<td style="text-align:right;">
82.7433
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0.5717
</td>
<td style="text-align:right;">
0.9011
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
-0.0847
</td>
<td style="text-align:right;">
4.8592
</td>
<td style="text-align:right;">
3.2933
</td>
<td style="text-align:right;">
-0.5551
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
6.2071
</td>
<td style="text-align:right;">
136.3742
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:right;">
106.1941
</td>
<td style="text-align:right;">
8.4174
</td>
<td style="text-align:right;">
40.5059
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
165.7158
</td>
<td style="text-align:right;">
28.4554
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
72.9312
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
121.7145
</td>
<td style="text-align:right;">
-17.3017
</td>
<td style="text-align:right;">
74.6989
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.3517
</td>
<td style="text-align:right;">
1.1797
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
-0.4451
</td>
<td style="text-align:right;">
4.5088
</td>
<td style="text-align:right;">
0.3013
</td>
<td style="text-align:right;">
-0.0115
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
6.7320
</td>
<td style="text-align:right;">
135.1993
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:right;">
90.0566
</td>
<td style="text-align:right;">
0.0000
</td>
<td style="text-align:right;">
36.1750
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
45.2035
</td>
<td style="text-align:right;">
23.9608
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
79.1191
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
53.9691
</td>
<td style="text-align:right;">
11.7315
</td>
<td style="text-align:right;">
95.7823
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.5439
</td>
<td style="text-align:right;">
1.1360
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
-0.4807
</td>
<td style="text-align:right;">
5.1832
</td>
<td style="text-align:right;">
3.0243
</td>
<td style="text-align:right;">
-0.5751
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
7.3972
</td>
<td style="text-align:right;">
139.0182
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:right;">
78.6143
</td>
<td style="text-align:right;">
2.9790
</td>
<td style="text-align:right;">
71.0642
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
131.3121
</td>
<td style="text-align:right;">
10.9656
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
69.0179
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
94.3153
</td>
<td style="text-align:right;">
9.7112
</td>
<td style="text-align:right;">
72.7109
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.4916
</td>
<td style="text-align:right;">
1.1028
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.3121
</td>
<td style="text-align:right;">
4.2190
</td>
<td style="text-align:right;">
-0.7057
</td>
<td style="text-align:right;">
0.0053
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
8.2779
</td>
<td style="text-align:right;">
88.0470
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:right;">
91.6593
</td>
<td style="text-align:right;">
0.0000
</td>
<td style="text-align:right;">
59.4963
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
171.1872
</td>
<td style="text-align:right;">
29.1317
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
81.8346
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
212.9066
</td>
<td style="text-align:right;">
-28.2269
</td>
<td style="text-align:right;">
69.2184
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0.4621
</td>
<td style="text-align:right;">
0.9529
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
-0.2872
</td>
<td style="text-align:right;">
5.1773
</td>
<td style="text-align:right;">
0.9705
</td>
<td style="text-align:right;">
0.2127
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
5.9942
</td>
<td style="text-align:right;">
69.5943
</td>
<td style="text-align:right;">
0
</td>
</tr>
</tbody>
</table>
</div>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">skim</span>(chspred)</code></pre>
<pre><code>Skim summary statistics
 n obs: 4590 
 n variables: 28 

── Variable type:numeric ───────────────────────────────────────────────────────
  variable missing complete    n    mean    sd      p0     p25     p50    p75
       ace       0     4590 4590   0.12   0.32    0      0       0       0   
       age       0     4590 4590  74.81   6.29   55.07  70.46   74.29   78.61
     alcoh       0     4590 4590   2.53   5.5     0      0       0       2.39
   aspirin       0     4590 4590   0.37   0.48    0      0       0       1   
      beta       0     4590 4590   0.12   0.33    0      0       0       0   
       bmi       0     4590 4590  26.79   6.55    7.94  22.36   26.4    30.81
    cysgfr       0     4590 4590  72.49  25.11  -32.71  55.98   72.02   89.05
        dm       0     4590 4590   0.26   0.44    0      0       0       1   
    estrgn       0     4590 4590   0.081  0.27    0      0       0       0   
   fetuina       0     4590 4590   0.47   0.13   -0.12   0.39    0.47    0.56
      gend       0     4590 4590   0.42   0.49    0      0       0       1   
       glu       0     4590 4590 108.37  48.42  -33.76  77.76  103.17  132.38
       hdl       0     4590 4590  52.97  19.14   -5     39.85   51.91   65.15
    health       0     4590 4590   0.79   0.41    0      1       1       1   
      hsed       0     4590 4590   0.45   0.5     0      0       0       1   
       ins       0     4590 4590  11.91  46    -149.49 -16.86   10.49   37.95
       ldl       0     4590 4590 119.9   53.16  -86.31  84.34  119.08  154.48
    logcre       0     4590 4590   0.028  0.4    -1.28  -0.25    0.018   0.29
    logcrp       0     4590 4590   1      1.35   -2.93   0.034   0.96    1.91
 logcystat       0     4590 4590   0.083  0.36   -1.1   -0.16    0.069   0.31
   logkcal       0     4590 4590   6.11   2.54    0      5.37    6.69    7.74
   logtrig       0     4590 4590   4.85   0.63    2.82   4.42    4.82    5.26
        mi       0     4590 4590   0.031  0.17    0      0       0       0   
      race       0     4590 4590   0.17   0.37    0      0       0       0   
     smoke       0     4590 4590   0.1    0.3     0      0       0       0   
     sysbp       0     4590 4590 136.55  27.39   39.55 117.46  135.03  154.22
     waist       0     4590 4590  97.46  16.57   35.46  86.01   97     108.3 
       whr       0     4590 4590   0.95   0.13    0.43   0.86    0.95    1.03
   p100     hist
   1    ▇▁▁▁▁▁▁▁
  99.85 ▁▂▆▇▅▂▁▁
  50.84 ▇▁▁▁▁▁▁▁
   1    ▇▁▁▁▁▁▁▅
   1    ▇▁▁▁▁▁▁▁
  59.44 ▁▃▇▆▂▁▁▁
 194.25 ▁▁▃▇▆▁▁▁
   1    ▇▁▁▁▁▁▁▃
   1    ▇▁▁▁▁▁▁▁
   0.96 ▁▁▁▆▇▃▁▁
   1    ▇▁▁▁▁▁▁▆
 452.4  ▁▅▇▂▁▁▁▁
 135.85 ▁▂▇▇▅▁▁▁
   1    ▂▁▁▁▁▁▁▇
   1    ▇▁▁▁▁▁▁▆
 457.35 ▁▆▇▁▁▁▁▁
 412.54 ▁▁▆▇▃▁▁▁
   2.18 ▁▂▇▇▂▁▁▁
   5.71 ▁▂▆▇▆▃▁▁
   1.86 ▁▂▇▇▃▁▁▁
  12.75 ▂▁▂▅▇▃▁▁
   7.71 ▁▂▆▇▅▁▁▁
   1    ▇▁▁▁▁▁▁▁
   1    ▇▁▁▁▁▁▁▂
   1    ▇▁▁▁▁▁▁▁
 262.7  ▁▁▆▇▅▁▁▁
 176.92 ▁▁▅▇▅▁▁▁
   1.74 ▁▁▆▇▂▁▁▁</code></pre>
<ol style="list-style-type: decimal">
<li>Create an <code>sl3</code> task, setting myocardial infarction <code>mi</code> as the outcome and
using all available covariate data.</li>
<li>Make a library of seven relatively fast base learning algorithms (i.e., do
not consider BART or HAL). Customize hyperparameters for one of your
learners. Feel free to use learners from <code>sl3</code> or <code>SuperLearner</code>. You may
use the same base learning library that is presented above.</li>
<li>Incorporate feature selection with the <code>SuperLearner</code> screener <code>screen.corP</code>.</li>
<li>Fit the metalearning step with non-negative least squares, <code>Lrnr_nnls</code>.</li>
<li>With the metalearner and base learners, make the super learner and train it
on the task.</li>
<li>Print your super learner fit by calling <code>print()</code> with <code>$</code>.</li>
<li>Cross-validate your super learner fit to see how well it performs on unseen
data. Specify <code>loss_squared_error</code> as the loss function to evaluate the
super learner.</li>
</ol>
</div>
</div>
<div id="concluding-remarks" class="section level2">
<h2><span class="header-section-number">3.6</span> Concluding Remarks</h2>
<ul>
<li><p>The general ensemble learning approach of super learner can be applied to a
diversity of estimation and prediction problems that can be defined by a loss
function.</p></li>
<li><p>Plug-in estimators of the estimand are desirable because a plug-in estimator
respects both the local and global constraints of the statistical model.</p></li>
<li><p>Asymptotically linear estimators are also advantageous, since they converge to
the estimand at <span class="math inline">\(1/\sqrt{n}\)</span> rate, and thereby permit formal statistical
inference.</p></li>
<li><p>If we plug in the estimator returned by super learner into the target
parameter mapping, then we would end up with an estimator that has the same
bias as what we plugged in. This estimator would not be asymptotically linear.</p></li>
<li><p>Targeted maximum likelihood estimation (TMLE) is a general strategy that
succeeds in constructing asymptotically linear plug-in estimators.</p></li>
<li><p>In the chapters that follow, we focus on the targeted maximum likelihood
estimator and the targeted minimum loss-based estimator, both referred to as
TMLE.</p></li>
</ul>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-polley2010super">
<p>Polley, Eric C, and Mark J Van Der Laan. 2010. “Super Learner in Prediction.” bepress.</p>
</div>
<div id="ref-vdl2003unified">
<p>van der Laan, Mark J, and Sandrine Dudoit. 2003. “Unified Cross-Validation Methodology for Selection Among Estimators and a General Cross-Validated Adaptive Epsilon-Net Estimator: Finite Sample Oracle Inequalities and Examples.” bepress.</p>
</div>
<div id="ref-van2007super">
<p>Van der Laan, Mark J, Eric C Polley, and Alan E Hubbard. 2007. “Super Learner.” <em>Statistical Applications in Genetics and Molecular Biology</em> 6 (1). De Gruyter.</p>
</div>
<div id="ref-van2006oracle">
<p>Van der Vaart, Aad W, Sandrine Dudoit, and Mark J van der Laan. 2006. “Oracle Inequalities for Multi-Fold Cross Validation.” <em>Statistics &amp; Decisions</em> 24 (3). Oldenbourg Wissenschaftsverlag: 351–71.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="tlverse.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="the-tmle-framework.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/tlverse/acic2019-workshop/edit/master/04-sl3.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["acic2019_workshop.pdf", "acic2019_workshop.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
