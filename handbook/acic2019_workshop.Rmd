---
title: "The `tlverse` Software Ecosystem for Causal Inference"
subtitle: "2019 Atlantic Causal Inference Conference"
author: "Mark van der Laan, Alan Hubbard, Jeremy Coyle, Nima Hejazi, Ivana
  Malenica, Rachael Phillips"
date: "updated: `r format(Sys.time(), '%B %d, %Y')`"
documentclass: book
output: bookdown::gitbook
site: bookdown::bookdown_site
bibliography: [book.bib, packages.bib]
biblio-style: apalike
fontsize: '12pt, krantz2'
monofont: "Source Code Pro"
monofontoptions: "Scale=0.7"
link-citations: yes
links-as-notes: true
colorlinks: yes
lot: yes
lof: yes
always_allow_html: yes
url: 'https\://tlverse.org/acic2019-workshop/'
github-repo: tlverse/acic2019-workshop
graphics: yes
description: "An open-source and fully-reproducible electronic set of teaching
  materials accompanying a full-day short-course on applying the Targeted
  Learning methodology in practice using the [`tlverse` software
  ecosystem](https://github.com/tlverse)."
#cover-image: "img/tlverse_book_cover.png"
#apple-touch-icon: "img/logos/favicons/apple-touch-icon.png"
favicon: "img/logos/favicons/favicon.png"
---


```{r set-options, include=FALSE}
# Set output options
if (knitr:::is_html_output()) {
  options(width = 80)
}
if (knitr:::is_latex_output()) {
  options(width = 65)
}
options(digits = 7, bookdown.clean_book = TRUE, knitr.kable.NA = "NA")
knitr::opts_chunk$set(
  tidy = FALSE,
  out.width = "\textwidth",
  fig.align = "center",
  comment = NA
)
```

```{r pkg-bib, include=FALSE}
# automatically create a bib database for R packages
knitr::write_bib(c(
  .packages(), "bookdown", "knitr", "rmarkdown"
), "packages.bib")
```
# Preface {-}

<img style="float: center; margin-right: 1%; margin-bottom: 0.01em"
     src="img/logos/tlverse-logo.svg" width="15%" height="15%">
<img style="float: center; margin-right: 1%; margin-bottom: 0.01em"
     src="img/logos/Rlogo.svg" width="15%" height="15%">
<img style="float: center; margin-right: 1%; margin-bottom: 0.01em"
     src="img/logos/vdl-logo-transparent.svg" width="15%" height="15%">
<p style="clear: both;">
<br>

This is an open source and fully-reproducible electronic vignette for a
full-day short-course on applying the targeted learning methodology in practice
using the [`tlverse` software ecosystem](https://github.com/tlverse), given at
the [2019 Atlantic Causal Inference
Conference](https://mcgill.ca/epi-biostat-occh/news-events/atlantic-causal-inference-conference-2019) in
Montréal, Québec, Canada on 22 May 2019. [*The Hitchhiker's Guide to the
`tlverse`, or a Targeted Learning Practitioner's
Handbook*](https://tlverse.org/tlverse-handbook/) accompanies this vignette and
covers the same topics presented in this vignette, but presents them in more
detail.

## Important links {-}

**Software installation**
Please install the relevant software before the workshop.

* [installation
script](https://github.com/tlverse/acic2019-workshop/blob/master/install.R)

You will probably exceed the GitHub API rate limit during this installation, and this
will throw an error. This issue and the solution are addressed
[here](#installtlverse).

**Workshop surveys**
These pre- and post-workshop surveys help us ensure the effectiveness of our
teaching methodology.

* [pre-workshop survey](https://forms.gle/u6iZHYjd81RBwQVv7)
* [post-workshop survey](https://forms.gle/ktcdUPP5faKVKCd98)


**Etherpad**
We will use the Etherpad for discussion, Q&A, and sharing URLs and bits
of code.

* [https://etherpad.net/p/acic2019-tlverse](https://etherpad.net/p/acic2019-tlverse)

**Code**
`R` script files for each section of the workshop are available via the GitHub
repository for the short course.  

* [https://github.com/tlverse/acic2019-workshop/tree/master/handbook/R](https://github.com/tlverse/acic2019-workshop/tree/master/handbook/R)

**RStudio Cloud**
Coming soon.

## About this workshop {-}

This full-day workshop will provide a comprehensive introduction to the field of
targeted learning for causal inference and the corresponding [`tlverse`
software ecosystem](https://github.com/tlverse). In particular, we will focus on
targeted minimum loss-based estimators of causal effects, including those of
static, dynamic, optimal dynamic, and stochastic interventions. These multiply
robust, efficient plug-in estimators use state-of-the-art, ensemble machine
learning tools to flexibly adjust for confounding while yielding valid
statistical inference. We will discuss the utility of this robust estimation
strategy in comparison to conventional techniques, which often rely on
restrictive statistical models and may therefore lead to severely biased
inference. In addition to discussion, this workshop will incorporate both
interactive activities and hands-on, guided `R` programming exercises, to allow
participants the opportunity to familiarize themselves with methodology and
tools that will translate to real-world causal inference analyses. It is highly
recommended for participants to have an understanding of basic statistical
concepts such as confounding, probability distributions, confidence intervals,
hypothesis tests, and regression. Advanced knowledge of mathematical statistics
may be useful but is not necessary. Familiarity with the `R` programming language
will be essential.

## Outline {-}

This is a full-day (6-hour) workshop, featuring modules that introduce distinct
causal questions, each motivated by a case study, alongside statistical
methodology and software for assessing the causal claim of interest. A sample
schedule may take the form:

* 08:30AM--09:00AM: Address software installation issues
* 09:00AM--09:10AM: Introductions
* 09:10AM--09:30AM: Introduction to the [`tlverse` software
    ecosystem](https://tlverse.org)
* 09:30AM--10:00AM: The Roadmap of Targeted Learning, and the [WASH
    Benefits](http://www.washbenefits.net/) data
* 10:00AM--10:20AM: Morning coffee break
* 10:20AM--10:50AM: [Why we need a statistical
    revolution](https://senseaboutscienceusa.org/super-learning-and-the-revolution-in-knowledge/)
* 10:50AM--11:50AM: Ensemble machine learning with the
    [`sl3`](https://github.com/tlverse/sl3) `R` package
* 11:50AM--12:10PM: Targeted learning for causal inference with the
    [`tmle3`](https://github.com/tlverse/tmle3) `R` package
* 12:10PM--01:00PM: Lunch break
* 01:00PM--01:30PM: Targeted learning for causal inference with the
    [`tmle3`](https://github.com/tlverse/tmle3) `R` package
* 01:30PM--02:00PM: Optimal treatment regimes and the
    [`tmle3mopttx`](https://github.com/tlverse/tmle3mopttx) `R` package
* 02:00PM--02:20PM: Afternoon coffee break
* 02:20PM--02:50PM: Optimal treatment regimes and the
    [`tmle3mopttx`](https://github.com/tlverse/tmle3mopttx) `R` package
* 02:50PM--04:00PM: Stochastic treatment regimes and the
    [`tmle3shift`](https://github.com/tlverse/tmle3shift) `R` package

## About the instructors {-}

### Mark van der Laan {-}

Mark van der Laan, Ph.D., is Professor of Biostatistics and Statistics at UC
Berkeley. His research interests include statistical methods in computational
biology, survival analysis, censored data, adaptive designs, targeted maximum
likelihood estimation, causal inference, data-adaptive loss-based learning, and
multiple testing. His research group developed loss-based super learning in
semiparametric models, based on cross-validation, as a generic optimal tool for
the estimation of infinite-dimensional parameters, such as nonparametric density
estimation and prediction with both censored and uncensored data. Building on
this work, his research group developed targeted maximum likelihood estimation
for a target parameter of the data-generating distribution in arbitrary
semiparametric and nonparametric models, as a generic optimal methodology for
statistical and causal inference. Most recently, Mark's group has focused in
part on the development of a centralized, principled set of software tools for
targeted learning, the `tlverse`. For more information, see
https://vanderlaan-lab.org.

### Alan Hubbard {-}

Alan Hubbard, Ph.D., is Professor of Biostatistics, former head of the Division
of Biostatistics at UC Berkeley, and head of data analytics core at UC
Berkeley's SuperFund research program. His current research interests include
causal inference, variable importance analysis, statistical machine learning,
estimation of and inference for data-adaptive statistical target parameters, and
targeted minimum loss-based estimation. Research in his group is generally
motivated by applications to problems in computational biology, epidemiology,
and precision medicine.

### Jeremy Coyle {-}

Jeremy Coyle, Ph.D., is a consulting data scientist and statistical programmer,
currently leading the software development effort that has produced the
`tlverse` ecosystem of R packages and related software tools. Jeremy earned his
Ph.D. in Biostatistics from UC Berkeley in 2016, primarily under the supervision
of Alan Hubbard.

### Nima Hejazi {-}

Nima is a Ph.D. candidate in biostatistics with a designated emphasis in
computational and genomic biology, working jointly with Mark van der Laan and
Alan Hubbard. Nima is affiliated with UC Berkeley's Center for Computational
Biology and NIH Biomedical Big Data training program. His research interests
span causal inference, nonparametric inference and machine learning, targeted
loss-based estimation, survival analysis, statistical computing, reproducible
research, and high-dimensional biology. He is also passionate about software
development for applied statistics, including software design, automated
testing, and reproducible coding practices. For more information, see
https://nimahejazi.org.

### Ivana Malenica {-}

Ivana is a Ph.D. student in biostatistics advised by Mark van der Laan. Ivana is
currently a fellow at the Berkeley Institute for Data Science, after serving as
a NIH Biomedical Big Data and Freeport-McMoRan Genomic Engine fellow. She earned
her Master's in Biostatistics and Bachelor's in Mathematics, and spent some time
at the Translational Genomics Research Institute. Very broadly, her research
interests span non/semi-parametric theory, probability theory, machine learning,
causal inference and high-dimensional statistics. Most of her current work
involves complex dependent settings (dependence through time and network) and
adaptive sequential designs.

### Rachael Phillips {-}

Rachael is a Ph.D. student in biostatistics, advised by Alan Hubbard and Mark
van der Laan. She has an M.A. in Biostatistics, B.S. in Biology with a Chemistry
minor and a B.A. in Mathematics with a Spanish minor. Her research is applied,
and specific to human health. Motivated by issues arising in healthcare, Rachael
leverages strategies rooted in causal inference and nonparametric estimation to
build clinician-tailored, machine-driven solutions. Her accompanying statistical
interests include high-dimensional statistics and experimental design. She is
also passionate about free, online-mediated education. She is affiliated with
the UC Berkeley Center for Computational Biology, NIH Biomedical Big Data
Training Program, and Superfund Research Program.

<!--chapter:end:index.Rmd-->

# Motivation {-}

> "One enemy of robust science is our humanity — our appetite for
> being right, and our tendency to find patterns in noise, to see supporting
> evidence for what we already believe is true, and to ignore the facts that do
> not fit."
>
> --- @naturenews_2015

Scientific research is at a unique point in history. The need to improve rigor
and reproducibility in our field is greater than ever; corroboration moves
science forward, yet there is a growing alarm about results that cannot be
reproduced and that report false discoveries [@baker2016there]. Consequences of
not meeting this need will result in further decline in the rate of scientific
progression, the reputation of the sciences, and the public’s trust in its
findings [@munafo2017manifesto; @naturenews2_2015].

> "The key question we want to answer when seeing the results of any scientific
> study is whether we can trust the data analysis."
>
> --- @peng2015reproducibility

Unfortunately, at its current state the culture of data analysis and statistics
actually enables human bias through improper model selection. All hypothesis
tests and estimators are derived from statistical models, so to obtain valid
estimates and inference it is critical that the statistical model contains the
process that generated the data. Perhaps treatment was randomized or only
depended on a small number of baseline covariates; this knowledge should and
can be incorporated in the model. Alternatively, maybe the data is
observational, and there is no knowledge about the data-generating process (DGP).
If this is the case, then the statistical model should contain *all* data
distributions. In practice; however, models are not selected based on knowledge
of the DGP, instead models are often selected based on (1) the p-values they
yield, (2) their convenience of implementation, and/or (3) an analysts loyalty
to a particular model. This practice of "cargo-cult statistics --- the
ritualistic miming of statistics rather than conscientious practice,"
[@stark2018cargo] is characterized by arbitrary modeling choices, even though
these choices often result in different answers to the same research question.
That is, "increasingly often, [statistics] is used instead to aid and
abet weak science, a role it can perform well when used mechanically or
ritually," as opposed to its original purpose of safeguarding against weak
science [@stark2018cargo]. This presents a fundamental drive behind the epidemic
of false findings that scientific research is suffering from [@van2014entering].

> "We suggest that the weak statistical understanding is probably due to
> inadequate "statistics lite" education. This approach does not build up
> appropriate mathematical fundamentals and does not provide scientifically
> rigorous introduction into statistics. Hence, students' knowledge may remain
> imprecise, patchy, and prone to serious misunderstandings. What this approach
> achieves, however, is providing students with false confidence of being able
> to use inferential tools whereas they usually only interpret the p-value
> provided by black box statistical software. While this educational problem
> remains unaddressed, poor statistical practices will prevail regardless of
> what procedures and measures may be favored and/or banned by editorials."
>
> --- @szucs2017null


Our team at The University of California, Berkeley, is uniquely positioned to
provide such an education. Spearheaded by Professor Mark van der Laan, and
spreading rapidly by many of his students and colleagues who have greatly
enriched the field, the aptly named "Targeted Learning" methodology targets the
scientific question at hand and is counter to the current culture of
"convenience statistics" which opens the door to biased estimation, misleading
results, and false discoveries. Targeted Learning restores the fundamentals that
formalized the field of statistics, such as the that facts that a statistical
model represents real knowledge about the experiment that generated the data,
and a target parameter represents what we are seeking to learn from the data as
a feature of the distribution that generated it [@vdl2014entering]. In this way,
Targeted Learning defines a truth and establishes a principled standard for
estimation, thereby inhibiting these all-too-human biases (e.g., hindsight bias,
confirmation bias, and outcome bias) from infiltrating analysis.

> "The key for effective classical [statistical] inference is to have
> well-defined questions and an analysis plan that tests those questions."
>
> --- @nosek2018preregistration

Our objective is to provide training to students, researchers, industry professionals, faculty in science, public health, statistics, and other
fields to empower them with the necessary knowledge and skills to utilize the
sound methodology of Targeted Learning --- a technique that provides tailored
pre-specified machines for answering queries, so that each data analysis is
completely reproducible, and estimators are efficient, minimally biased, and
provide formal statistical inference.

Just as the conscientious use of modern statistical methodology is necessary to
ensure that scientific practice thrives, it remains critical to acknowledge the
role that robust software plays in allowing practitioners direct access to
published results. We recall that "an article...in a scientific publication is
not the scholarship itself, it is merely advertising of the scholarship. The
actual scholarship is the complete software development environment and the
complete set of instructions which generated the figures," thus making the
availability and adoption of robust statistical software key to enhancing the
transparency that is an inherent aspect of science [@buckheit1995wavelab].

For a statistical methodology to be readily accessible in practice, it is
crucial that it is accompanied by robust user-friendly software
[@pullenayegum2016knowledge; @stromberg2004write]. The `tlverse` software
ecosystem was developed to fulfill this need for the Targeted Learning
methodology. Not only does this software facilitate computationally reproducible
and efficient analyses, it is also a tool for Targeted Learning education since
its workflow mirrors that of the methodology. In particular, the `tlverse`
paradigm does not focus on implementing a specific estimator or a small set of
related estimators. Instead, the focus is on exposing the statistical framework
of Targeted Learning itself --- all `R` packages in the `tlverse` ecosystem
directly model the key objects defined in the mathematical and theoretical
framework of Targeted Learning. What's more, the `tlverse` `R` packages share a
core set of design principles centered on extensibility, allowing for them to be
used in conjunction with each other and built upon one other in a cohesive
fashion.

In this workshop, the reader will embark on a journey through the `tlverse`
ecosystem. Guided by `R` programming exercises, case studies, and
intuitive explanation readers will build a toolbox for applying the Targeted
Learning statistical methodology, which will translate to real-world causal
inference analyses. Participants need not be a fully trained statistician to
begin understanding and applying these methods. However, it is highly
recommended for participants to have an understanding of basic statistical
concepts such as confounding, probability distributions, confidence intervals,
hypothesis tests, and regression. Advanced knowledge of mathematical statistics
may be useful but is not necessary. Familiarity with the `R` programming
language will be essential. We also recommend an understanding of introductory
causal inference.

For introductory materials for learning the `R` programming language we recommend the following free resources:

* [Software Carpentry's _Programming with
   `R`_](http://swcarpentry.github.io/r-novice-inflammation/)
* [Software Carpentry's _`R` for Reproducible Scientific
    Analysis_](http://swcarpentry.github.io/r-novice-gapminder/)
* [Grolemund and Wickham's _`R` for Data
    Science_](https://r4ds.had.co.nz)

For causal inference learning materials we recommend the following resources:

* [Hernán MA, Robins JM (2019). _Causal
Inference_.](https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/)
* [Jason A. Roy's coursera Course _A Crash Course in Causality: Inferring
Causal Effects from Observational Data_](https://www.coursera.org/learn/crash-course-in-causality)

<!--chapter:end:01-motivation.Rmd-->

# Welcome to the `tlverse` {#tlverse}

## Learning Objectives

1. Understand the `tlverse` ecosystem conceptually
2. Identify the core components of the `tlverse`
3. Install `tlverse` `R` packages
4. Understand the Targeted Learning roadmap
5. Learn about the WASH Benefits example data

## What is the `tlverse`?

The `tlverse` is a new framework for doing Targeted Learning in R, inspired by
the [`tidyverse` ecosystem](https://tidyverse.org) of R packages.

By analogy to the [`tidyverse`](https://tidyverse.org/):

> The `tidyverse` is an opinionated collection of R packages designed for data
> science. All packages share an underlying design philosophy, grammar, and data
> structures.

So, the [`tlverse`](https://tlverse.org) is

* an opinionated collection of R packages for Targeted Learning
* sharing an underlying philosophy, grammar, and set of data structures

## `tlverse` components

These are the main packages that represent the **core** of the `tlverse`:

* [`sl3`](https://github.com/tlverse/sl3): Modern Super Learning with Pipelines
  * _What?_ A modern object-oriented re-implementation of the Super Learner
    algorithm, employing recently developed paradigms for `R` programming.
  * _Why?_ A design that leverages modern tools for fast computation, is
    forward-looking, and can form one of the cornerstones of the `tlverse`.

* [`tmle3`](https://github.com/tlverse/tmle3): An Engine for Targeted Learning
  * _What?_ A generalized framework that simplifies Targeted Learning by
    identifying and implementing a series of common statistical estimation
    procedures.
  * _Why?_ A common interface and engine that accommodates current algorithmic
    approaches to Targeted Learning and is still flexible enough to remain the
    engine even as new techniques are developed.

In addition to the engines that drive development in the `tlverse`, there are
some supporting packages -- in particular, we have two...

* [`origami`](https://github.com/tlverse/origami): A Generalized Framework for
   Cross-Validation
  * _What?_ A generalized framework for flexible cross-validation
  * _Why?_ Cross-validation is a key part of ensuring error estimates are honest
    and preventing overfitting. It is an essential part of the both the Super
    Learner algorithm and Targeted Learning.

* [`delayed`](https://github.com/tlverse/delayed): Parallelization Framework for
   Dependent Tasks
  * _What?_ A framework for delayed computations (futures) based on task
    dependencies.
  * _Why?_ Efficient allocation of compute resources is essential when deploying
    large-scale, computationally intensive algorithms.

A key principle of the `tlverse` is extensibility. That is, we want to support
new Targeted Learning estimators as they are developed. The model for this is
new estimators are implemented in additional packages using the core packages
above. There are currently two featured examples of this:

* [`tmle3mopttx`](https://github.com/tlverse/tmle3mopttx): Optimal Treatments
  in `tlverse`
  * _What?_ Learn an optimal rule and estimate the mean outcome under the rule
  * _Why?_ Optimal Treatment is a powerful tool in precision healthcare and
    other settings where a one-size-fits-all treatment approach is not
    appropriate.

* [`tmle3shift`](https://github.com/tlverse/tmle3shift): Shift Interventions in
  `tlverse`
  * _What?_ Shift interventions for continuous treatments
  * _Why?_ Not all treatment variables are discrete. Being able to estimate the
    effects of continuous treatment represents a powerful extension of the
    Targeted Learning approach.

## Installation {#installtlverse}

The `tlverse` ecosystem of packages are currently hosted at
https://github.com/tlverse, not yet on [CRAN](http://cran.r-project.org/). You
can use the `devtools` package to install them:

```{r installation, eval=FALSE}
install.packages("devtools")
devtools::install_github("tlverse/tlverse")
```

The `tlverse` depends on a large number of other packages that are also hosted
on GitHub. Because of this, you may see the following error:

```
Error: HTTP error 403.
  API rate limit exceeded for 71.204.135.82. (But here's the good news:
  Authenticated requests get a higher rate limit. Check out the documentation
  for more details.)

  Rate limit remaining: 0/60
  Rate limit reset at: 2019-03-04 19:39:05 UTC

  To increase your GitHub API rate limit
  - Use `usethis::browse_github_pat()` to create a Personal Access Token.
  - Use `usethis::edit_r_environ()` and add the token as `GITHUB_PAT`.
```

This just means that R tried to install too many packages from GitHub in too
short of a window. To fix this, you need to tell R how to use GitHub as your
user (you'll need a GitHub user account). Follow these two steps:

1. Type `usethis::browse_github_pat()` in your R console, which will direct
   you to GitHub's page to create a New Personal Access Token.
2. Create a Personal Access Token simply by clicking "Generate token" at the
   bottom of the page.
3. Copy your Personal Access Token, a long string of lowercase letters and
   numbers.
4. Type `usethis::edit_r_environ()` in your R console, which will open your
   '.Renviron' file in the source window of RStudio.
5. In your '.Renviron' file, type "GITHUB_PAT=" and then paste your Personal
   Access Token after the equals symbol with no space.
6. In your '.Renviron' file, press the enter key to ensure that your '.Renviron'
   ends with a newline.
7. Save your '.Renviron' file.
8. Restart R for changes to take effect. You can restart R via the drop-down
   menu on the "Session" tab. The "Session" tab is at the top of the RStudio
   interface.

After following these steps, you should be able to successfully install the
package which threw the error above. 

<!--chapter:end:02-intro-tlverse.Rmd-->

---
output: html_document
editor_options: 
  chunk_output_type: console
---

# The Targeted Learning Roadmap {#intro}

A central goal of the Targeted Learning statistical paradigm is to estimate
scientifically relevant parameters in realistic (usually nonparametric) models and to do so with finite-sample robustness and consistent inference.

## The Statistical Model

Assume we have an i.i.d. sample of confounders, a binary intervention of
interest, and an outcome, or are observed data is  
\[ O = (W, A, Y).\]
The
distribution of the observed data may be factorized as follows: 
\[P(O) = P(W, A,
Y) = P(W)P (A \mid W) P(Y \mid A, W).\]
To estimate a parameter of interest, a
researcher need not necessarily be able to specify these whole or conditional
distributions. Rather, each estimator only requires that certain parts of the
distribution be known; for example, some may require estimates of $\mathbb{E}(Y
\mid A, W)$, the mean of $Y$ within subgroups $(A, W)$, or the regression of the
outcome on the exposure and confounders.

At this stage in the roadmap, the researcher must specify a choice of
statistical model to be used in estimating $\mathbb{E}(Y \mid A, W)$ or other
elements of the probability distribution needed to estimate the parameter of
interest. Here, _statistical model_ means any constraints on the model form that
may be imposed by knowledge about the data-generating process -- that is, known
aspects of how the data were generated. Typically, the _true model_ is a very
large model, placing few constraints, if any, on the data-generating
distribution, or a semi-parametric model. With few constraints on the
data-generating distribution, and a potentially large number of covariates,
data-adaptive, machine-learning approaches remain the only practical option for
estimating components of the likelihood. The remainder of this course concerns
how to do this as efficiently and robustly as possible, depending on the goal of
the analysis.

## The Causal Model

The next step in the roadmap is to use a causal framework to formalize the
experiment and thereby define the parameter of interest. Causal graphs are one
useful tool to express what we know about the causal relations among variables
that are relevant to the question under study [@pearl2009causality]. 

Ignoring error terms, we will assume the following ordering of the variables in $O$.

```{r, echo=F, eval=T}
library(visNetwork)
nodes <- data.frame(id=c("W","A","Y"))
nodes$label <- nodes$id
edges <- data.frame(from=c("W","W","A"),to=c("A","Y","Y"))
network <- visNetwork(nodes,edges, height="300px",width="200px") %>%
  visEdges(arrows=list(to=TRUE))  %>%
  visLayout(randomSeed=25)
network
```

While
directed acyclic graphs (DAGs - like above) provide a convenient means by which to visualize
causal relations between variables, the  causal relations among variables
can be represented via a set of structural equations:
\begin{align*}
  W &= f_W(U_W) \\
  A &= f_A(W, U_A) \\
  Y &= f_Y(W, A, U_Y),
\end{align*}
where $U_W$, $U_A$, and $U_Y$ represent the unmeasured exogenous background
characteristics that influence the value of each variable. In the NPSEM, $f_W$,
$f_A$ and $f_Y$ denote that each variable (for $W$, $A$ and $Y$, respectively)
is a function of its parents and unmeasured background characteristics, but one
typically has little information about  particular functional constraints (e.g.,
linear, logit-linear, only one interaction, etc.). For this reason, they are
called non-parametric structural equation models (NPSEMs). The DAG and set of
nonparametric structural equations represent exactly the same information and so
may be used interchangeably.

## The Parameter of Interest

The first hypothetical experiment we will consider is assigning exposure to the
whole population and observing the outcome, and then assigning no exposure to
the whole population and observing the outcome. On the nonparametric structural
equations, this corresponds to a comparison of the outcome distribution in the
population under two interventions:

1. $A$ is set to $1$ for all individuals, and
2. $A$ is set to $0$ for all individuals.

These interventions imply two new nonparametric structural equation models. For
the case $A = 1$, we have
\begin{align*}
  W &= f_W(U_W) \\
  A &= 1 \\
  Y(1) &= f_Y(W, 1, U_Y),
\end{align*}
and for the case $A=0$,
\begin{align*}
  W &= f_W(U_W) \\
  A &= 0 \\
  Y(1) &= f_Y(W, 0, U_Y).
\end{align*}

In these equations, $A$ is no longer a function of $W$ because we have
intervened on the system, setting $A$ deterministically to either of the values
$1$ or $0$. The new symbols $Y(1)$ and $Y(0)$ indicate the outcome variable in
our population if it were generated by the respective NPSEMs above; these are
often called _counterfactuals_. The difference between the means of the outcome
under these two interventions defines a parameter that is often called the
"average treatment effect" (ATE), denoted
\begin{equation}\label{eqn:ate}
  ATE = \mathbb{E}_X(Y(1)-Y(0)),
\end{equation}
where $\mathbb{E}_X$ is the mean under the theoretical (unobserved) full data
$X = (W, Y(1), Y(0))$.

Note, we can define much more complicated interventions on 
NPSEM's, such as interventions based upon rules (themselves based upon covariates), stochastic rules, etc. and each results in a different targeted parameter and entails different identifiability assumptions discussed below. 

## Identifiability

Because we can never observe both $Y(0)$ (the counterfactual outcome when $A=0$)
and $Y(1)$, we cannot estimate \ref{eqn:ate} directly. Instead, we have to make
assumptions under which this quantity may be estimated from the observed data
$O \sim P_0$ under the data-generating distribution $P_0$. Fortunately, given
the causal model specified in the NPSEM above, we can, with a handful of
untestable assumptions, estimate the ATE, even from observational data. These
assumptions may be summarized as follows

1. The causal graph implies $Y(a) \perp A$ for all $a \in \mathcal{A}$, which
   is the _randomization_ assumption. In the case of observational data, the
   analogous assumption is _strong ignorability_ or _no unmeasured confounding_
   $Y(a) \perp A \mid W$ for all $a \in \mathcal{A}$;
2. Although not represented in the causal graph, also required is the assumption
   of no interference between units, that is, the outcome for unit $i$ $Y_i$ is
   not affected by exposure for unit $j$ $A_j$ unless $i=j$;
3. _Consistency_ of the treatment mechanism is also required, i.e., the outcome
   for unit $i$ is $Y_i(a)$ whenever $A_i = a$, an assumption also known as "no
   other versions of treatment";
4. It is also necessary that all observed units, across strata defined by $W$,
   have a bounded (non-deterministic) probability of receiving treatment --
   that is, $0 < P_0(A = a \mid W) < 1$ for all $a$ and $W$). This assumption is
   referred to as _positivity_.

_Remark_: Together, (2) and (3), the assumptions of no interference and
consistency, respectively, are jointly referred to as the *stable unit
treatment value assumption* (SUTVA).

Given these assumptions, the ATE may be re-written as a function of $P_0$,
specifically
\begin{equation}\label{eqn:estimand}
  ATE = \mathbb{E}_0(Y(1) - Y(0)) = \mathbb{E}_0
    \left(\mathbb{E}_0[Y \mid A = 1, W] - \mathbb{E}_0[Y \mid A = 0, W]\right),
\end{equation}
or the difference in the predicted outcome values for each subject, under the
contrast of treatment conditions ($A = 0$ vs. $A = 1$), in the population,
averaged over all observations. Thus, a parameter of a theoretical "full" data
distribution can be represented as an estimand of the observed data
distribution. Significantly, there is nothing about the representation in
\ref{eqn:estimand} that requires parameteric assumptions; thus, the regressions
on the right hand side may be estimated freely with machine learning. With
different parameters, there will be potentially different identifiability
assumptions and the resulting estimands can be functions of different components
of $P_0$. We discuss several more complex estimands in later sections of this
workshop.

## Estimators: SuperLearning and Targeted Maximum Likelihood


Although we will discuss more in later sections, the goals of the estimators we
desire should be that, among sensible (asymptotically consistent, regular)
estimators,

1. the estimator be asymptotically efficient in the statistical model of
   interest, and
2. the estimator can be constructed for finite-sample performance improvements,
   relative to other estimators in the same class.

These priniciples guide our approach to estimation: Super Learning for
prediction (more generally density estimation) and TMLE for estimation of our
intervention parameters of interest.

```{r nature_slides, fig.show="hold"}
knitr::include_graphics("img/misc/NatureSlides.pdf")
```

### SuperLearning

- There is no universally optimal machine learning algorithm for density estimation or prediction
- This is true empirically, when we have test different algorithms on actual
  data and looked at the performance (e.g., MSE of prediction)
- For some data, one needs learners that can model a complex function.
- For others, typically the result of noise or insufficient sample size, a simple,
  parametric model might fit the best.
- SuperLearner, an ensemble learner, solves this issue, by allowing a convex
  combination of learners from the simplest (intercept-only) to most complex
  (neural nets, random forests, SVM, etc).
- It works by using cross-validation in a manner which guarantees that the
  resulting fit will be as good as possible, given the learners provided (note,
  even a convex combination of poor learners can sometimes result in good fit,
  though better to have good candidates).

```{r cv_fig, fig.show="hold"}
knitr::include_graphics("img/misc/vs.pdf")
```

The figure above shows an example of 10-fold cross-validation.

The schematic below is a visualization of the following algorithm:
\begin{itemize}

\item Break up the sample evenly into V-folds (say V=10).
\item For each of these 10 folds, remove that portion of the sample (kept out as validation sample) and the remaining will be used to fit learners (training sample).
\item Fit each learner on the training sample (note, some learners will have their own internal cross-validation procedure or other methods to select tuning parameters).
\item For each observation in the corresponding training sample, predict the outcome using each of the learners, so if there are $p$ learners, then where would be $p$ predictions on each of the observations in validation sample).
\item Take out another validation sample and repeat until each of the V-sets of data are removed.
\item Compare the cross-validated fit of the learners across all observations based on specified loss function (e.g., squared error, negative log-likelihood, ...) by calculating the corresponding average loss (risk).
\item Either:
\begin{itemize}
\item[$\square$] choose the learner with smallest risk and apply that learner to entire data set (resulting SL fit)
\item[$\square$] do a weighted average of the learners to minimize the 
\item[$\square$] cross-validated risk (construct an ensemble of learners), by
\begin{itemize}
\item[$\bigstar$] re-fitting the learners on the original data set, and
\item[$\bigstar$] use the weights above to get the file SL fit.
\end{itemize}
\end{itemize}
\end{itemize}

Note, this entire procedure can be itself cross-validated to get a consistent estimate of the future performance of the SL fit.

```{r cv_fig2, fig.show="hold"}
knitr::include_graphics("img/misc/SLKaiserNew.pdf")
```

For prediction, one can use the cross-validated risk to empirically determine the relative performance of SL and competing methods.  Below shows the results of such a study, comparing the fits of several different learners, including the SL algorithms.

```{r cv_fig3, fig.show="hold"}
knitr::include_graphics("img/misc/ericSL.pdf")
```

### Substitution Estimators
- Beyond a fit of the prediction function, one might also want to estimate more targeted parameters specific to certain scientific questions.  
- The approach is to plug into the estimand of interest estimates of the relevant distributions.
- Sometimes, we can use simple empirical distributions, but averaging some function over the observations (e.g., giving weight $1/n$ for all observations).
- Other parts of the distribution, like conditional means or probabilities, the estimate will require some sort of smoothing due to the curse of dimensionality.

We give one example using an example of the average treatment effect (see above): 

- $\Psi(P_0) = \Psi(Q_0) \mathbb{E}_0
    \left(\mathbb{E}_0[Y \mid A = 1, W] - \mathbb{E}_0[Y \mid A = 0, W]\right).$
where $Q_0$ represents both the distribution of $Y \mid W,A$ and distribution of $W$.
- Let $\bar{Q}_0(A,W) \equiv E_0(Y \mid A,W)$ and $Q_{0,W}(w) = P_0 (W=w)$, then
\[
\Psi(Q_0) = \sum_w \{ \bar{Q}_0(1,w)-\bar{Q}_0(0,w)\} Q_{0,W}(w)
\]
- The **Substitution Estimator** plugs in the empirical distribution (weight $1/n$ for each observation) for $Q_{0,W}(W_i)$, and some estimate of the regression of $Y$ on $(W,A)$  (say SL fit):
 \[
 \Psi(Q_n) = \frac{1}{n} \sum_{i=1}^n  \{ \bar{Q}_n(1,W_i)-\bar{Q}_n(0,W_i)\}
 \]
 - Thus, it becomes the average of the differences in predictions from the fit keeping the observed $W$, but first replacing $A=1$ and then the same but all $A=0$.

### TMLE
- Though using SL over an arbitrary parametric regression is an improvement, it's not sufficient to have the properties of an estimator one needs for rigorous inference.
- Because the variance-bias trade-off in the SL is focused on the prediction model, it can, for instance, underfit portions of the distributions that are critical for estimating the parameter of interest ($\Psi(P_0)$).
- TMLE keeps the benefits of substitution estimators (it is one), but augments the original estimates to correct for this issue and also results in an asymptotically linear (and thus normally-distributed) estimator with consisent Wald-style confidence intervals. 
- Produces a well-defined, unbiased, efficient substitution estimator of target parameters of a data-generating distribution.
- Updates an initial (super learner) estimate  of the relevant part of the data-generating distribution possibly using an estimate of a nuisance parameter (like the model of intervention given covariates).
- Removes asymptotic residual bias of initial estimator for the target parameter, if it uses a consistent estimator of $g_0$.
- If initial estimator was consistent for the target parameter, the additional fitting of the data in the targeting step may remove finite sample bias, and preserves consistency property of the initial estimator.
- If the initial estimator and the estimator of $g_0$ are both consistent, then it is also asymptotically  efficient according to semi-parametric statistical model efficiency theory.
- Thus, every effort is made to achieve minimal bias and the asymptotic semi-parametric efficiency bound for the variance.



```{r cv_fig4, fig.show="hold"}
knitr::include_graphics("img/misc/TMLEimage.pdf")
```

- There are different types of TMLE, sometimes for the same set of parameters, but below is an example of the algorithm for estimating the ATE.
- In this case, one can present the estimator as:

\[
 \Psi(Q^*_n) = \frac{1}{n} \sum_{i=1}^n  \{ \bar{Q}^*_n(1,W_i)-\bar{Q}^*_n(0,W_i)\}
 \]
where $\bar{Q}^*_n(A,W)$ is the TMLE augmented estimate.
$f(\bar{Q}^*_n(A,W)) = f(\bar{Q}_n(A,W)) + \epsilon_n * h_n(A,W)$, where $f(\cdot)$ is the appropriate link function (e.g., logit), $\epsilon_n$ is an estimated coefficient and $h_n(A,W)$ is a "clever covariate".
- In this case, $h_n(A,W) = A/g_n(W)-(1-A)/(1-g_n(W))$, with $g_n(W) = P_n(A=1 \mid W)$ being the estimated (also by SL) propensity score, so the estimator depends both on initial SL fit of the outcome regression ($\bar{Q}_0$) and an SL fit of the propensity score ($g_n$).

- There are further robust agumentations that are used in tlverse, such as an added layer of cross-validation to avoid over-fitting bias (CV-TMLE), and so called methods that can more robustly estimated several parameters simultaneously (e.g., the points on a survival curve). 

### Inference

- The estimators we discuss are **asymptotically linear**, meaning that the difference
in the estimate $\Psi(P_n)$ and the true parameter ($\Psi(P_0)$) can be represented in first order by a i.i.d. sum:
\begin{equation}\label{eqn:IC}
  \Psi(P_n) - \Psi(P_0) = \frac{1}{n} IC(O_i; \nu) + op(1/\sqrt{n})
\end{equation}

where $IC(O_i; \nu)$ (the influence curve or function) is a function of the data and possibly other nuisance parameters
$\nu$. Importantly, such estimators have mean-zero Gaussian limiting
distributions; thus, in the univariate case, one has that
\begin{equation}\label{eqn:limit_dist}
  \sqrt{n}(\Psi(P_n) - \Psi(P_0)) = N(0, (IC(O_i; \nu))^2),
\end{equation}
so that inference for the estimator of interest may be obtained in terms of
the influence function. For this simple case, a 95\% confidence interval may be
derived as:
\begin{equation}\label{eqn:CI}
  \Psi(P^{\star}_n) \pm 1.96 \sqrt{\frac{\hat{\sigma}^2}{n}},
\end{equation}
where $SE=\sqrt{\frac{\hat{\sigma}^2}{n}}$ and $\hat{\sigma}^2$ is the sample
variance of the estimated IC's: $IC(O; \hat{\nu})$. One can use the functional
delta method to derive the influence curve if a parameter of interest may be
written as a function of other asymptotically linear estimators.
- Thus, we can derive robust inference for parameters that are estimated by fitting complex, machine learning algorithms and these methods are computationally quick (do not rely on re-sampling based methods like the bootstrap).

## The WASH Benefits Example Dataset

The data come from a study of the effect of water quality, sanitation, hand
washing, and nutritional interventions on child development in rural Bangladesh
(WASH Benefits Bangladesh): a cluster-randomised controlled trial
[@luby2018effects]. The study enrolled pregnant women in their first or second
trimester from the rural villages of Gazipur, Kishoreganj, Mymensingh, and
Tangail districts of central Bangladesh, with an average of eight women per
cluster. Groups of eight geographically adjacent clusters were block-randomised,
using a random number generator, into six intervention groups (all of which
received weekly visits from a community health promoter for the first 6 months
and every 2 weeks for the next 18 months) and a double-sized control group (no
intervention or health promoter visit). The six intervention groups were:

1. chlorinated drinking water;
2. improved sanitation;
3. handwashing with soap;
4. combined water, sanitation, and hand washing;
5. improved nutrition through counseling and provision of lipid-based nutrient
   supplements; and
6. combined water, sanitation, handwashing, and nutrition.

In the workshop, we concentrate on child growth (size for age) as the outcome of
interest. For reference, this trial was registered with ClinicalTrials.gov as
NCT01590095.

```{r load_washb_data_intro, message=FALSE, warning=FALSE}
library(tidyverse)

# read in data
dat <- read_csv("https://raw.githubusercontent.com/tlverse/tlverse-data/master/wash-benefits/washb_data.csv")
dat
```

For the purposes of this workshop, we we start by treating the data as
independent and identically distributed (i.i.d.) random draws from a very large
target population. We could, with available options, account for the clustering
of the data (within sampled geographic units), but, for simplification, we avoid
these details in these workshop presentations, although modifications of our
methodology for biased samples, repeated measures, etc., are available.

We have 28 variables measured, of which 1 variable is set to be the outcome of
interest. This outcome, $Y$, is the weight-for-height Z-score (`whz` in `dat`);
the treatment of interest, $A$, is the randomized treatment group (`tr` in
`dat`); and the adjustment set, $W$, consists simply of *everything else*. This
results in our observed data structure being $n$ i.i.d. copies of $O_i = (W_i,
A_i, Y_i)$, for $i = 1, \ldots, n$.

Using the [`skimr` package](https://CRAN.R-project.org/package=skimr), we can
quickly summarize the variables measured in the WASH Benefits data set:

```{r skim_washb_data, message=FALSE, warning=FALSE}
library(skimr)
skim(dat)
```

A convenient summary of the relevant variables is given just above, complete
with a small visualization describing the marginal characteristics of each
covariate. Note that the *asset* variables reflect socio-economic status of the
study participants. Notice also the uniform distribution of the treatment groups
(with twice as many controls); this is, of course, by design.

<!--chapter:end:03-intro-TL.Rmd-->

# Ensemble Machine Learning

_Rachael Phillips_

Based on the [`sl3` `R` package](https://github.com/tlverse/sl3) by _Jeremy
Coyle, Nima Hejazi, Ivana Malenica, and Oleg Sofrygin_.

Updated: `r Sys.Date()`

## Learning Objectives
By the end of this lesson you will be able to:

1. Assemble an ensemble of learners based on the properties that identify what
   features they support.
2. Customize learner hyperparameters to incorporate a diversity of different
   settings.
3. Select a subset of available covariates and pass only those variables to the
   modeling algorithm.
4. Fit an ensemble with nested cross-validation to obtain an estimate of the
   performance of the ensemble itself.
5. Calculate `sl3` variable importance metrics.
6. Interpret the discrete and continuous super learner fits.
7. Rationalize the need to remove bias from the super learner to make an optimal
   bias-variance tradeoff for the parameter of interest.

## Introduction

Now that we have defined the statistical estimation problem in [The Targeted
Learning Roadmap](#intro), we are ready construct the TMLE; an asymptotically
efficient substitution estimator of this target quantity.

The first step in this estimation procedure is an initial estimate of the
data-generating distribution, or the relevant part of this distribution that is
needed to evaluate the target parameter. For this initial estimation, we use the
super learner [@van2007super], an important step for creating a robust
estimator.

#### Super Learner {-}

* Loss-function-based tool that uses V-fold cross-validation to obtain the best
  prediction of the relevant part of the likelihood that's needed to evaluate
  target parameter.

* Requires expressing the estimand as the minimizer of an expected loss, and
  proposing a library of algorithms ("learners" in `sl3` nomenclature) that we
  think might be consistent with the true data-generating distribution.

* Proven to be asymptotically as accurate as the best possible prediction
  algorithm that is tested [@vdl2003unified; @van2006oracle].

* The *discrete super learner*, or cross-validated selector, is the algorithm in
  the library that minimizes the V-fold cross-validated empirical risk.

* The *continuous super learner* is a weighted average of the library of
  algorithms, where the weights are chosen to minimize the V-fold
  cross-validated empirical risk of the library. Restricting the weights
  ("metalearner" in `sl3` nomenclature) to be positive and sum to one (convex
  combination) has been shown to improve upon the discrete super learner
  [@polley2010super; @van2007super].

 * This background material is described in greater detail in the accompanying
   `tlverse` handbook [`sl3`
   chapter](https://tlverse.org/tlverse-handbook/ensemble-machine-learning.html).

## Basic `sl3` Implementation

We begin by illustrating the core functionality of the super learner algorithm
as implemented in `sl3`.

The `sl3` implementation consists of the following steps:

0. Load the necessary libraries and data
1. Define the machine learning task
2. Make a super learner by creating library of base learners and a metalearner
3. Train the super learner on the machine learning task
4. Obtain predicted values

### WASH Benefits Study Example {-}

Using the WASH data, we are interested in predicting weight-for-height z-score
`whz` using the available covariate data.

### 0. Load the necessary libraries and data {-}

```{r setup, message=FALSE, warning=FALSE}
library(kableExtra)
library(knitr)
library(skimr)
library(tidyverse)
library(data.table)
library(sl3)
library(SuperLearner)
library(origami)

set.seed(7194)

# load data set and take a peek
washb_data <- fread("https://raw.githubusercontent.com/tlverse/tlverse-data/master/wash-benefits/washb_data.csv", stringsAsFactors = TRUE)

head(washb_data) %>%
  kable(digits = 4) %>%
  kable_styling(fixed_thead = T, font_size = 10) %>%
  scroll_box(width = "100%", height = "250px")
```

### 1. Define the machine learning task {-}

To define the machine learning **"task"** (predict weight-for-height z-score
`whz` using the available covariate data), we need to create an `sl3_Task`
object.

The `sl3_Task` keeps track of the roles the variables play in the
machine learning problem, the data, and any metadata (e.g., observational-level
weights, id, offset).

```{r task}
# specify the outcome and covariates
outcome <- "whz"
covars <- colnames(washb_data)[-which(names(washb_data) == outcome)]

# create the sl3 task
washb_task <- make_sl3_Task(
  data = washb_data,
  covariates = covars,
  outcome = outcome
)

# examine the task
washb_task
```

### 2. Make a super learner {-}

Now that we have defined our machine learning problem with the task, we are
ready to **"make"** the super learner. This requires specification of

* Base learning algorithms, to establish a library of learners that we think
might be consistent with the true data-generating distribution.
* Metalearner, to ensemble the base learners.

We might also incorporate

* Feature selection, to pass only a subset of the predictors to the algorithm.
* Hyperparameter specification, to tune base learners.

Learners have properties that indicate what features they support. We may use
`sl3_list_properties()` to get a list of all properties supported by at least
one learner.

```{r list-properties}
sl3_list_properties()
```
Since we have a continuous outcome, we may identify the learners that support
this outcome type with `sl3_list_learners()`.

```{r list-learners}
sl3_list_learners(c("continuous"))
```

Now that we have an idea of some learners, we can construct them using the
`make_learner` function.

```{r baselearners}
# choose base learners
lrnr_glm <- make_learner(Lrnr_glm)
lrnr_mean <- make_learner(Lrnr_mean)
lrnr_glmnet <- make_learner(Lrnr_glmnet)
```
We can customize learner hyperparameters to incorporate a diversity of different
settings.

Documentation for the learners and their hyperparameters can be found
in the [`sl3` Learners
Reference](https://tlverse.org/sl3/reference/index.html#section-sl-learners).

We can also include learners from the `SuperLearner` `R` package.

```{r extra-lrnr}
lrnr_ranger100 <- make_learner(Lrnr_ranger, num.trees = 100)
lrnr_hal_simple <- make_learner(Lrnr_hal9001, degrees = 1, n_folds = 2)
lrnr_gam <- Lrnr_pkg_SuperLearner$new("SL.gam")
lrnr_bayesglm <- Lrnr_pkg_SuperLearner$new("SL.bayesglm")
```

In order to assemble the library of learners, we need to **"stack"** them
together.

A `Stack` is a special learner and it has the same interface as all
other learners. What makes a stack special is that it combines multiple learners
by training them simultaneously, so that their predictions can be either
combined or compared.

```{r stack}
stack <- make_learner(
  Stack,
  lrnr_glm, lrnr_mean, lrnr_ranger100, lrnr_glmnet,
  lrnr_gam, lrnr_bayesglm
)
```

We will fit a non-negative least squares metalearner using `Lrnr_nnls`. Note
that any learner can be used as a metalearner.

```{r metalearner}
metalearner <- make_learner(Lrnr_nnls)
```
We can optionally select a subset of available covariates and pass only
those variables to the modeling algorithm.

Let's consider screening covariates based on their correlation with our outcome
of interest (`cor.test` p-value $\leq 0.1$).

```{r screener}
screen_cor <- Lrnr_pkg_SuperLearner_screener$new("screen.corP")
# which covariates are selected on the full data?
screen_cor$train(washb_task)
```
To **"pipe"** only the selected covariates to the modeling algorithm, we need to
make a `Pipeline`, which is a just set of learners to be fit sequentially, where
the fit from one learner is used to define the task for the next learner.

```{r screener-pipe}
cor_pipeline <- make_learner(Pipeline, screen_cor, stack)
```
Now our learners will be preceded by a screening step.

We also consider the original `stack`, just to compare how the feature selection
methods perform in comparison to the methods without feature selection.

Analogous to what we have seen before, we have to stack the pipeline and
original `stack` together, so we may use them as base learners in our super
learner.

```{r screeners-stack}
fancy_stack <- make_learner(Stack, cor_pipeline, stack)
# we can visualize the stack
dt_stack <- delayed_learner_train(fancy_stack, washb_task)
plot(dt_stack, color = FALSE, height = "400px", width = "100%")
```

We have made a library/stack of base learners and a metalearner, so we
are ready to make the super learner. The super learner algorithm fits a
metalearner on the validation-set predictions.

```{r make-sl}
sl <- make_learner(Lrnr_sl,
  learners = fancy_stack,
  metalearner = metalearner
)
# we can visualize the super learner
dt_sl <- delayed_learner_train(sl, washb_task)
plot(dt_sl, color = FALSE, height = "400px", width = "100%")
```

### 3. Train the super learner on the machine learning task {-}

Now we are ready to **"train"** our super learner on our `sl3_task` object, `washb_task`.

```{r sl-basic}
sl_fit <- sl$train(washb_task)
```

### 4. Obtain predicted values {-}

Now that we have fit the super learner, we are ready to obtain our predicted
values, and we can also obtain a summary of the results.

```{r sl-basic-summary}
sl_preds <- sl_fit$predict()
head(sl_preds)
sl_fit$print()
```
## Extensions

### Cross-validated Super Learner

We can cross-validate the super learner to see how well the super learner
performs on unseen data, and obtain an estimate of the cross-validated risk of
the super learner.

This estimation procedure requires an "external" layer of cross-validation,
also called nested cross-validation, which involves setting aside a separate
holdout sample that we don’t use to fit the super learner. This
external cross validation procedure may also incorporate 10 folds, which is the
default in `sl3`. However, we will incorporate 2 outer/external folds of
cross-validation for computational efficiency.

We also need to specify a loss function to evaluate super learner.
Documentation for the available loss functions can be found in the [`sl3` Loss
Function Reference](https://tlverse.org/sl3/reference/loss_functions.html).

```{r CVsl}
washb_task_new <- make_sl3_Task(
  data = washb_data,
  covariates = covars,
  outcome = outcome,
  folds = make_folds(washb_data, fold_fun = folds_vfold, V = 2)
)
CVsl <- CV_lrnr_sl(sl_fit, washb_task_new, loss_squared_error)
CVsl %>%
  kable(digits = 4) %>%
  kable_styling(fixed_thead = T, font_size = 10) %>%
  scroll_box(width = "100%", height = "250px")
```

### Variable Importance Measures with `sl3`

The `sl3` `varimp` function returns a table with variables listed in decreasing
order of importance, in which the measure of importance is based on a risk
difference between the learner fit with a permuted covariate and the learner
fit with the true covariate, across all covariates.

In this manner, the larger the risk difference, the more important the variable
is in the prediction.

```{r varimp}
washb_varimp <- varimp(sl_fit, loss_squared_error)
washb_varimp %>%
  kable(digits = 4) %>%
  kable_styling(fixed_thead = T, font_size = 10) %>%
  scroll_box(width = "100%", height = "250px")
```

## Exercise

### Predicting Myocardial Infarction with `sl3`

Follow the steps below to predict myocardial infarction (`mi`) using the
available covariate data. Thanks to Professor David Benkeser at Emory University
for making the this Cardiovascular Health Study (CHS) data accessible.

Work with a buddy/team. You have 20 minutes.

In the [etherpad](https://etherpad.net/p/acic2019-tlverse), submit your group's
answers to the following questions.

1. Which learner was the discrete super learner? What was the cross validated
mean risk of the discrete super learner?
2. What was the cross validated risk of the continuous super learner?
3. Did your group face any challenges?
4. Any additional comments/questions about this `sl3` section of the workshop?

```{r ex-setup}
# load the data set
db_data <-
 url("https://raw.githubusercontent.com/benkeser/sllecture/master/chspred.csv")
chspred <- read_csv(file = db_data, col_names = TRUE)
# take a quick peek
head(chspred) %>%
  kable(digits = 4) %>%
  kable_styling(fixed_thead = T, font_size = 10) %>%
  scroll_box(width = "100%", height = "250px")
```

1. Create an `sl3` task, setting myocardial infarction `mi` as the outcome and
   using all available covariate data.
2. Make a library of seven relatively fast base learning algorithms (i.e., do
   not consider BART or HAL). Customize hyperparameters for one of your
   learners. Feel free to use learners from `sl3` or `SuperLearner`. You may
   use the same base learning library that is presented above.
3. Incorporate feature selection with the `SuperLearner` screener `screen.corP`.
4. Fit the metalearning step with non-negative least squares, `Lrnr_nnls`.
5. With the metalearner and base learners, make the super learner and train it
   on the task.
6. Print your super learner fit by calling `print()` with `$`.
7. Cross-validate your super learner fit to see how well it performs on unseen
   data. Specify `loss_squared_error` as the loss function to evaluate the
   super learner.

## Summary

* The general ensemble learning approach of super learner can be applied to a
  diversity of estimation and prediction problems that can be defined by a loss
  function.

* Plug-in estimators of the estimand are desirable because a plug-in estimator
  respects both the local and global constraints of the statistical model.

* Asymptotically linear estimators are also advantageous, since they converge to
  the estimand at $1/\sqrt{n}$ rate, and thereby permit formal statistical
  inference.

* If we plug in the estimator returned by super learner into the target
  parameter mapping, then we would end up with an estimator that has the same
  bias as what we plugged in. This estimator would not be asymptotically linear.

* Targeted maximum likelihood estimation (TMLE) is a general strategy that
  succeeds in constructing asymptotically linear plug-in estimators.

* In the chapters that follow, we focus on the targeted maximum likelihood
  estimator and the targeted minimum loss-based estimator, both referred to as
  TMLE.

<!--chapter:end:04-sl3.Rmd-->

# The TMLE Framework

_Jeremy Coyle_

Based on the [`tmle3` `R` package](https://github.com/tlverse/tmle3).

Updated: `r Sys.Date()`

## Learning Objectives
1. Use `tmle3` to estimate an Average Treatment Effect (ATE)
2. Understand `tmle3` "Specs"
3. Fit `tmle3` for a custom set of parameters
4. Use the delta method to estimate transformations of parameters

## Easy-Bake Example: `tmle3` for ATE

We'll illustrate the most basic use of TMLE using the WASH Benefits data
introduced earlier and estimating an Average Treatment Effect (ATE).

As a reminder, the ATE is identified with the following statistical parameter
(under assumptions): $ATE = \mathbb{E}_0(Y(1)-Y(0)) =
\mathbb{E}_0\left(\mathbb{E}_0[Y \mid A=1,W]-\mathbb{E}_0[Y \mid A=0,W] \right)$

This Easy-Bake implementation consists of the following steps:

0. Load the necessary libraries and data
1. Define the variable roles
2. Create a "Spec" object
3. Define the super learners
4. Fit the TMLE
5. Evaluate the TMLE estimates

### 0. Load the Data {-}

We'll use the same WASH Benefits data as the earlier chapters:

```{r tmle3-load-data}
library(data.table)
library(tmle3)
library(sl3)
washb_data <- fread("https://raw.githubusercontent.com/tlverse/tlverse-data/master/wash-benefits/washb_data.csv", stringsAsFactors = TRUE)
```

### 1. Define the variable roles {-}

We'll use the common $W$ (covariates), $A$ (treatment/intervention), $Y$
(outcome) data structure. `tmle3` needs to know what variables in the dataset
correspond to each of these roles. We use a list of character vectors to tell
it. We call this a **"Node List"** as it corresponds to the nodes in a Directed
Acyclic Graph (DAG), a way of displaying causal relationships between variables.

```{r tmle3-node-list}
node_list <- list(
  W = c(
    "month", "aged", "sex", "momage", "momedu",
    "momheight", "hfiacat", "Nlt18", "Ncomp", "watmin",
    "elec", "floor", "walls", "roof", "asset_wardrobe",
    "asset_table", "asset_chair", "asset_khat",
    "asset_chouki", "asset_tv", "asset_refrig",
    "asset_bike", "asset_moto", "asset_sewmach",
    "asset_mobile"
  ),
  A = "tr",
  Y = "whz"
)
```

#### Handling Missingness {-}

Currently, missingness in `tmle3` is handled in a fairly simple way:

* Missing covariates are median (for continuous) or mode (for discrete)
  imputed, and additional covariates indicating imputation are generated
* Observations missing either treatment or outcome variables are excluded.

We plan to implement IPCW-TMLE to more efficiently handle missingness in the
treatment and outcome variables.

These steps are implemented in the `process_missing` function in `tmle3`:

```{r tmle3-process_missing}
processed <- process_missing(washb_data, node_list)
washb_data <- processed$data
node_list <- processed$node_list
```

### 2. Create a "Spec" Object {-}

`tmle3` is general, and allows most components of the TMLE procedure to be
specified in a modular way. However, most end-users will not be interested in
manually specifying all of these components. Therefore, `tmle3` implements a
`tmle3_Spec` object that bundles a set of components into a **specification**
that, with minimal additional detail, can be run by an end-user.

We'll start with using one of the specs, and then work our way down into the
internals of `tmle3`.

```{r tmle3-ate-spec}
ate_spec <- tmle_ATE(
  treatment_level = "Nutrition + WSH",
  control_level = "Control"
)
```

### 3. Define the Relevant Super Learners {-}

Currently, the only other thing a user must define are the `sl3` learners used
to estimate the relevant factors of the likelihood: Q and g.

This takes the form of a list of `sl3` learners, one for each likelihood factor
to be estimated with `sl3`:

```{r tmle3-learner-list}
# choose base learners
lrnr_mean <- make_learner(Lrnr_mean)
lrnr_xgboost <- make_learner(Lrnr_xgboost)

# define metalearners appropriate to data types
ls_metalearner <- make_learner(Lrnr_nnls)
mn_metalearner <- make_learner(
  Lrnr_solnp, metalearner_linear_multinomial,
  loss_loglik_multinomial
)
sl_Y <- Lrnr_sl$new(
  learners = list(lrnr_mean, lrnr_xgboost),
  metalearner = ls_metalearner
)
sl_A <- Lrnr_sl$new(
  learners = list(lrnr_mean, lrnr_xgboost),
  metalearner = mn_metalearner
)

learner_list <- list(A = sl_A, Y = sl_Y)
```

Here, we use a Super Learner as defined in the previous `sl3` section. In the
future, we plan to include reasonable default learners.

### 4. Fit the TMLE {-}

We now have everything we need to fit the tmle using `tmle3`:

```{r tmle3-spec-fit}
tmle_fit <- tmle3(ate_spec, washb_data, node_list, learner_list)
```

### 5. Evaluate the Estimates {-}

We can see the summary results by printing the fit object. Alternatively, we
can extra results from the summary by indexing into it:

```{r tmle3-spec-summary}
print(tmle_fit)

estimates <- tmle_fit$summary$psi_transformed
print(estimates)
```

## `tmle3` Components

Now that we've successfully used a spec to obtain a TML estimate, let's look
under the hood at the components. The spec has a number of functions that
generate the objects necessary to define and fit a TMLE.

### `tmle3_task`

First is, a `tmle3_Task`, analogous to an `sl3_Task`, containing the data we're
fitting the TMLE to, as well as an NPSEM generated from the `node_list` defined
above, describing the variables and their relationships.

```{r tmle3-spec-task}
tmle_task <- ate_spec$make_tmle_task(washb_data, node_list)
```

```{r tmle3-spec-task-npsem}
tmle_task$npsem
```

### Initial Likelihood

Next, is an object representing the likelihood, factorized according to the
NPSEM described above:

```{r tmle3-spec-initial-likelihood}
initial_likelihood <- ate_spec$make_initial_likelihood(
  tmle_task,
  learner_list
)
print(initial_likelihood)
```

These components of the likelihood indicate how the factors were estimated: the
marginal distribution of $W$ was estimated using NP-MLE, and the conditional
distributions of $A$ and $Y$ were estimated using `sl3` fits (as defined with
the `learner_list`) above.

We can use this in tandem with the `tmle_task` object to obtain likelihood
estimates for each observation:
```{r tmle3-spec-initial-likelihood-estimates}
initial_likelihood$get_likelihoods(tmle_task)
```

<!-- TODO: make helper to get learners out of fit objects -->

### Targeted Likelihood (updater)

We also need to define a "Targeted Likelihood" object. This is a special type
of likelihood that is able to be updated using an `tmle3_Update` object. This
object defines the update strategy (e.g. submodel, loss function, CV-TMLE or
not, etc).

```{r tmle3-spec-targeted-likelihood}
targeted_likelihood <- Targeted_Likelihood$new(initial_likelihood)
```

When constructing the targeted likelihood, you can specify different update
options. See the documentation for `tmle3_Update` for details of the different
options. For example, you can disable CV-TMLE (the default in `tmle3`) as
follows:

```{r tmle3-spec-targeted-likelihood-no-cv}
targeted_likelihood_no_cv <-
  Targeted_Likelihood$new(initial_likelihood,
    updater = list(cvtmle = FALSE)
  )
```

### Parameter Mapping

Finally, we need to define the parameters of interest. Here, the spec defines a
single parameter, the ATE. In the next section, we'll see how to add additional
parameters.

```{r tmle3-spec-params}
tmle_params <- ate_spec$make_params(tmle_task, targeted_likelihood)
print(tmle_params)
```

### Putting it all together

Having used the spec to manually generate all these components, we can now
manually fit a `tmle3`:

```{r tmle3-manual-fit}
tmle_fit_manual <- fit_tmle3(
  tmle_task, targeted_likelihood, tmle_params,
  targeted_likelihood$updater
)
print(tmle_fit_manual)
```

The result is equivalent to fitting using the `tmle3` function as above.

## Fitting `tmle3` with multiple parameters

Above, we fit a `tmle3` with just one parameter. `tmle3` also supports fitting
multiple parameters simultaneously. To illustrate this, we'll use the
`tmle_TSM_all` spec:

```{r tmle3-tsm-all}
tsm_spec <- tmle_TSM_all()
targeted_likelihood <- Targeted_Likelihood$new(initial_likelihood)
all_tsm_params <- tsm_spec$make_params(tmle_task, targeted_likelihood)
print(all_tsm_params)
```

This spec generates a Treatment Specific Mean (TSM) for each level of the
exposure variable. Note that we must first generate a new targeted likelihood,
as the old one was targeted to the ATE. However, we can recycle the initial
likelihood we fit above, saving us a super learner step.

### Delta Method

We can also define parameters based on Delta Method Transformations of other
parameters. For instance, we can estimate a ATE using the delta method and two
of the above TSM parameters:

```{r tmle3-delta-method-param}
ate_param <- define_param(
  Param_delta, targeted_likelihood,
  delta_param_ATE,
  list(all_tsm_params[[1]], all_tsm_params[[4]])
)
print(ate_param)
```

This can similarly be used to estimate other derived parameters like Relative
Risks, and Population Attributable Risks

### Fit

We can now fit a TMLE simultaneously for all TSM parameters, as well as the
above defined ATE parameter

```{r tmle3-tsm-plus-delta}
all_params <- c(all_tsm_params, ate_param)

tmle_fit_multiparam <- fit_tmle3(
  tmle_task, targeted_likelihood, all_params,
  targeted_likelihood$updater
)

print(tmle_fit_multiparam)
```

## Exercise

Follow the steps below to estimate an average treatment effect using data from
the Collaborative Perinatal Project (CPP), available in the `sl3` package. To simplify this example, we define a binary intervention variable, `parity01`
-- an indicator of having one or more children before the current child and a
binary outcome, `haz01` -- an indicator of having an above average height for
age.

Work with a buddy/team. You have 20 minutes.

In the [etherpad](https://etherpad.net/p/acic2019-tlverse), submit your group's
answers to the following:

1. Interpret the `tmle3` fit both causally and statistically.
2. Did your group face any challenges?
3. Any additional comments/questions about this `tmle3` section of the workshop?

```{r data, message=FALSE, warning=FALSE}
# load the data set
data(cpp)
cpp <- cpp[!is.na(cpp[, "haz"]), ]
cpp$parity01 <- as.numeric(cpp$parity > 0)
cpp[is.na(cpp)] <- 0
cpp$haz01 <- as.numeric(cpp$haz > 0)
```
<!--
We're interested in using this simplified data to estimate an Average Treatment
Effect (ATE):

$$\Psi(P_0) = E_0(E_0[Y|A=1,W]-E_0[Y|A=0,W])$$

The purely statistical (noncausal) parameter can be interpreted as the average
of the difference in means across the strata for $W$, and only requires the
positivity assumption, that the conditional treatment assignment probabilities
are positive for each possible $w:P_0(A=1|W =w)>0$ and $P_0(A=0|W =w)>0$ for
each possible $w$.

To interpret this parameter as causal, specifically the causal risk difference
$E_0Y_1-E_0Y_0$, then we would also need to make the randomization assumption
stating that $A$ is independent of the counterfactuals $(Y_0,Y_1)$ within
strata of $W$. This assumption might have been included in the original SCM
$\mathcal{M}^F$, but, if one knows there are unmeasured confounders, then the
model $\mathcal{M}^{F\*}$ would be more restrictive by enforcing this "known
to be wrong" randomization assumption. Still, this assumption does not change
the statistical model $\mathcal{M}$, and as a consequence, it does not affect
the estimation problem either. Thus, the theorem's that establish desirable
properties of the TMLE, still hold even when this non-testable randomization
assumption is violated.

We proceed with implementing a targeted minimum loss-based estimator (TMLE),
an efficient substitution estimator which is not only asymptotically
consistent, asymptotically normally distributed, and asymptotically efficient,
but also tailored to have robust finite sample performance.
-->

1. Define the variable roles $(W,A,Y)$ by creating a list of these nodes.
   Include the following baseline covariates in $W$: `apgar1`, `apgar5`,
   `gagebrth`, `mage`, `meducyrs`, `sexn`. Both $A$ and $Y$ are specified
   above.
2. Define a `tmle3_Spec` object for the ATE, `tmle_ATE()`.
3. Using the same base learning libraries defined above, specify `sl3` base
   learners for estimation of $Q = E(Y|A,Y)$ and $g=P(A|W)$.
4. Specify `Lrnr_nnls` as the metalearner for both $Q$ and $G$.
5. Define one super learner for estimating $Q$ and another for estimating $g$.
6. Create a list of the two super learners defined in Step 5 and call this
   object `learner_list`. The list names should be `A` (defining the super
   learner for estimating $g$) and `Y` (defining the super learner for
   estimating $Q$).
7. Fit the tmle with the `tmle3` function by specifying (1) the `tmle3_Spec`,
   which we defined in Step 2; (2) the data; (3) the list of nodes, which we
   specified in Step 1; and (4) the list of super learners for estimating $g$
   and $Q$, which we defined in Step 6. *Note*: Like before, you will need to
   make a data copy to deal with `data.table` weirdness (`cpp2 <- data.table::copy(cpp)`) and use `cpp2` as the data.

## Summary

`tmle3` is a general purpose framework for generating TML estimates. The
easiest way to use it is to use a predefined spec, allowing you to just fill in
the blanks for the data, variable roles, and `sl3` learners. However, digging
under the hood allows users to specify a wide range of TMLEs. In the next
sections, we'll see how this framework can be used to estimate advanced
parameters such as optimal treatments and shift interventions.

<!--chapter:end:05-tmle3.Rmd-->

# Optimal Individualized Treatment Regimes

_Ivana Malenica_

Based on the [`tmle3mopttx` `R` package](https://github.com/tlverse/tmle3mopttx)
by _Ivana Malenica, Jeremy Coyle, and Mark van der Laan_.

Updated: `r Sys.Date()`

## Learning Objectives
By the end of this lesson you will be able to:

1. Differentiate between dynamic and optimal dynamic treatment regimes from static
   interventions.
2. Understand the benefits, and challenges, associated with using
   optimal individualized treatment regimes in practice.
3. Contrast the impact of implementing an optimal individualized treatment
   in the population with static and dynamic regimes.
4. Estimate causal effects under optimal individualized treatment regimes with the
  `tmle3mopttx` `R` package.
5. Contrast the population impact of implementing optimal individualized treatment
   based on sub-optimal rules.
6. Construct realistic optimal individualized treatments that respect real data
   and subject-matter knowledge limitations on interventions.
7. Understand and implement variable importance analysis defined in
   terms of optimal individualized treatment interventions.

## Introduction to Optimal Individualized Interventions

Identifying which intervention will be effective for which patient
based on lifestyle, genetic and environmental factors is a common goal in
precision medicine. One opts to administer the intervention to individuals
who will profit from it, instead of assigning treatment on a population level.

* This aim motivates a different type of intervention, as opposed to the static 
exposures we might be used to. 

* In this chapter, we learn about dynamic 
(individualized) interventions that tailor the treatment decision based on the 
collected covariates. 

* In the statistics community, such a treatment strategy is
termed **individualized treatment regimes** (ITR), and the (counterfactual) population 
mean outcome under an ITR is the **value of the ITR**. 

* Even more, suppose one wishes 
to maximize the population mean of an outcome, where for each individual we have 
access to some set of measured covariates. An ITR with the maximal value is referred 
to as an **optimal ITR** or the **optimal individualized treatment**. 
Consequently, the value of an optimal ITR is termed the **optimal value**, or the 
**mean under the optimal individualized treatment**.

* One opts to administer the intervention to individuals who will profit from it, instead of 
assigning treatment on a population level. But how do we know which intervention works for which 
patient? 

* For example, one might seek to improve retention in 
HIV care. In a randomized clinical trial, several interventions show efficacy- including
appointment reminders through text messages, small cash incentives for on time clinic 
visits, and peer health workers. 

* Ideally, we want to improve effectiveness by assigning 
each patient the intervention they are most likely to benefit from, as well as improve 
efficiency by not allocating resources to individuals that do not need them, or would 

```{r, fig.cap="Illustration of a Dynamic Treatment Regime in a Clinical Setting", echo=FALSE, eval=TRUE, out.width='60%'}
knitr::include_graphics(path = "img/image/DynamicA_Illustration.png")
```


This aim motivates a different type of intervention, as opposed to the static exposures we 
might be used to. 

* In this chapter, we examine multiple examples of optimal individualized 
treatment regimes 
and estimate the mean outcome under the ITR 
where the candidate rules are restricted to depend only on user-supplied subset of the 
baseline covariates. 

* In order to accomplish this, we present the [`tmle3mopttx` R
package](https://github.com/tlverse/tmle3mopttx), which features an
implementation of a recently developed algorithm for computing targeted minimum
loss-based estimates of a causal effect based on optimal ITR for 
categorical treatment. 

* In particular, we will use `tmle3mopttx` to estimate 
optimal ITR and the corresponding population value, 
construct realistic optimal ITRs, and perform variable importance in terms of the 
mean under the optimal individualized treatment.

## Data Structure and Notation

* Suppose we observe $n$ independent and identically distributed observations of
the form $O=(W,A,Y) \sim P_0$. $P_0 \in \mathcal{M}$, where $\mathcal{M}$ is the
fully nonparametric model.

* Denote $A \in \mathcal{A}$ as categorical treatment, where
$\mathcal{A} \equiv \{a_1, \cdots, a_{n_A} \}$ and $n_A = |\mathcal{A}|$, with
$n_A$ denoting the number of categories.

* Denote $Y$ as the final outcome, and $W$ a vector-valued collection of baseline
covariates.

* The likelihood of the data admits a factorization, implied by the time ordering of $O$.
\begin{equation*}\label{eqn:likelihood_factorization}
  p_0(O) = p_{Y,0}(Y|A,W) p_{A,0}(A|W) p_{W,0}(W) = q_{Y,0}(Y|A,W) q_{A,0}(A|W) q_{W,0}(W),
\end{equation*}

* Consequently, we define
$P_{Y,0}(Y|A,W)=Q_{Y,0}(Y|A,W)$, $P_{A,0}(A|W)=g_0(A|W)$ and $P_{W,0}(W)=Q_{W,0}(W)$ as the
corresponding conditional distributions of $Y$, $A$ and $W$.

* We also define $\bar{Q}_{Y,0}(A,W) \equiv E_0[Y|A,W]$.

* Finally, denote $V$ as $V \in W$, defining a subset of the baseline covariates
the optimal individualized rule depends on.

## Defining the Causal Effect of an Optimal Individualized Intervention

* Consider dynamic treatment rules $V \rightarrow d(V) \in \{a_1, \cdots, a_{n_A} \} \times \{1\}$,
for assigning treatment $A$ based on $V \in W$.

* Dynamic treatment regime may be viewed as an intervention in which
$A$ is set equal to a value based on a hypothetical regime $d(V)$, and $Y_{d(V)}$
is the corresponding counterfactual outcome under $d(V)$.

* The goal of any causal analysis motivated by an optimal individualized
intervention is to estimate a parameter defined as the counterfactual mean of the outcome with
respect to the modified intervention distribution.

* Recall causal assumptions:

1. **Consistency**: $Y^{d(v_i)}_i = Y_i$ in the event $A_i = d(v_i)$,
   for $i = 1, \ldots, n$.
2. **Stable unit value treatment assumption (SUTVA)**: $Y^{d(v_i)}_i$ does
   not depend on $d(v_j)$ for $i = 1, \ldots, n$ and $j \neq i$, or lack
   of interference.
3. **Strong ignorability**: $A \perp \!\!\! \perp Y^{d(v)} \mid W$, for all $a \in \mathcal{A}$.
4. **Positivity (or overlap)**: $P_0(\min_{a \in \mathcal{A}} g_0(a|W) > 0)=1$

* Here, we also assume non-exceptional law is in effect.

* We are primarily interested in the value of an individualized rule,
$$E_0[Y_{d(V)}] = E_{0,W}[\bar{Q}_{Y,0}(A=d(V),W)].$$

* The optimal rule is the rule with the maximal value:
$$d_{opt}(V) \equiv \text{argmax}_{d(V) \in \mathcal{D}} E_0[Y_{d(V)}] $$
where $\mathcal{D}$ represents the set of possible rules, $d$, implied by $V$.

* The target causal estimand of our analysis is:
$$\psi_0 := E_0[Y_{d_{opt}(V)}] =  E_{0,W}[\bar{Q}_{Y,0}(A=d_{opt}(V),W)].$$

* General, high-level idea:

1. Learn the optimal ITR using the Super Learner.

2. Estimate its value with the cross-validated Targeted Minimum Loss-based
Estimator (CV-TMLE).

### Why CV-TMLE?

* CV-TMLE is necessary as the non-cross-validated TMLE 
is biased upward for the mean outcome under the rule, and therefore overly optimistic. 

* More generally however, using CV-TMLE allows us more freedom in estimation and therefore greater 
data adaptivity, without sacrificing inference!

## Binary Treatment

* How do we estimate the optimal individualized treatment regime? In the case of a
binary treatment, a key quantity for optimal ITR is the **blip** function.

* Optimal ITR ideally assigns treatment to individuals falling in strata in which the
stratum specific average treatment effect, the **blip** function, is positive and does not
assign treatment to individuals for which this quantity is negative.

* We define the blip function as:
$$\bar{Q}_0(V) \equiv E_0[Y_1-Y_0|V] \equiv E_0[\bar{Q}_{Y,0}(1,W) - \bar{Q}_{Y,0}(0,W) | V], $$
or the average treatment effect within a stratum of $V$.

* Optimal individualized
rule can now be derived as $d_{opt}(V) = I(\bar{Q}_{0}(V) > 0)$.

* Relying on the Targeted Maximum Likelihood (TML) estimator and the Super Learner estimate of the
blip function, we follow the below steps in order to obtain value of the ITR:

1. Estimate $\bar{Q}_{Y,0}(A,W)$ and $g_0(A|W)$ using `sl3`. We denote such estimates
as $\bar{Q}_{Y,n}(A,W)$ and $g_n(A|W)$.

2. Apply the doubly robust Augmented-Inverse Probability Weighted (A-IPW) transform to
our outcome, where we define:

$$D_{\bar{Q}_Y,g,a}(O) \equiv \frac{I(A=a)}{g(A|W)} (Y-\bar{Q}_Y(A,W)) + \bar{Q}_Y(A=a,W)$$

Note that under the randomization and positivity assumptions we have that 
$E[D_{\bar{Q}_Y,g,a}(O) | V] = E[Y_a |V].$ We emphasize the double robust nature 
of the A-IPW transform: consistency of $E[Y_a |V]$ will depend on correct estimation 
of either $\bar{Q}_{Y,0}(A,W)$ or $g_0(A|W)$. As such, in a randomized trial, we are 
guaranteed a consistent estimate of $E[Y_a |V]$ even if we get $\bar{Q}_{Y,0}(A,W)$ wrong! 

Using this transform, we can define the following contrast:

$$D_{\bar{Q}_Y,g}(O) = D_{\bar{Q}_Y,g,a=1}(O) - D_{\bar{Q}_Y,g,a=0}(O)$$

We estimate the blip function, $\bar{Q}_{0,a}(V)$, by regressing $D_{\bar{Q}_Y,g}(O)$ on $V$ using
the specified `sl3` library of learners and an appropriate loss function.

3. Our estimated rule is $d(V) = \text{argmax}_{a \in \mathcal{A}} \bar{Q}_{0,a}(V)$.

4. We obtain inference for the mean outcome under the estimated optimal rule using CV-TMLE.

### Evaluating the Causal Effect of an optimal ITR with Binary Treatment

To start, let us load the packages we will use and set a seed for simulation:

```{r setup-mopttx, message=FALSE, warning=FALSE}
library(here)
library(data.table)
library(sl3)
library(tmle3)
library(tmle3mopttx)
library(devtools)
set.seed(111)
```

#### Simulate Data

Our data generating distribution is of the following form:

$$W \sim \mathcal{N}(\bf{0},I_{3 \times 3})$$
$$P(A=1|W) = \frac{1}{1+\exp^{(-0.8*W_1)}}$$
$$P(Y=1|A,W) = 0.5\text{logit}^{-1}[-5I(A=1)(W_1-0.5)+5I(A=0)(W_1-0.5)] +
0.5\text{logit}^{-1}(W_2W_3)$$

```{r load sim_bin_data}
data("data_bin")
```

* The above composes our observed data structure $O = (W, A, Y)$.

* Note that the mean under the true optimal rule is $\psi=0.578$ for this data generating
distribution.

* Next, we specify the role that each variable in the data set plays as the nodes in a DAG.

```{r data_nodes2-mopttx}
# organize data and nodes for tmle3
data <- data_bin
node_list <- list(
  W = c("W1", "W2", "W3"),
  A = "A",
  Y = "Y"
)
```

* We now have an observed data structure (`data`), and a specification of the role
that each variable in the data set plays as the nodes in a DAG.

#### Constructing Optimal Stacked Regressions with `sl3`

* We generate three different ensemble learners that must be fit,
corresponding to the learners for the outcome regression, propensity score, and
the blip function.

```{r mopttx_sl3_lrnrs2}
# Define sl3 library and metalearners:
lrn_xgboost_50 <- Lrnr_xgboost$new(nrounds = 50)
lrn_xgboost_100 <- Lrnr_xgboost$new(nrounds = 100)
lrn_xgboost_500 <- Lrnr_xgboost$new(nrounds = 500)
lrn_mean <- Lrnr_mean$new()
lrn_glm <- Lrnr_glm_fast$new()

## Define the Q learner:
Q_learner <- Lrnr_sl$new(
  learners = list(lrn_xgboost_50, lrn_xgboost_100,
                  lrn_xgboost_500,lrn_mean, lrn_glm),
  metalearner = Lrnr_nnls$new()
)

## Define the g learner:
g_learner <- Lrnr_sl$new(
  learners = list(lrn_xgboost_100, lrn_glm),
  metalearner = Lrnr_nnls$new()
)

## Define the B learner:
b_learner <- Lrnr_sl$new(
  learners = list(lrn_xgboost_50, lrn_xgboost_100,
                  lrn_xgboost_500,lrn_mean, lrn_glm),
  metalearner = Lrnr_nnls$new()
)
```

We make the above explicit with respect to standard
notation by bundling the ensemble learners into a list object below:

```{r mopttx_make_lrnr_list}
# specify outcome and treatment regressions and create learner list
learner_list <- list(Y = Q_learner, A = g_learner, B = b_learner)
```

#### Targeted Estimation of the Mean under the Optimal Individualized Interventions Effects

* To start, we will initialize a specification for the TMLE of our parameter of
interest simply by calling `tmle3_mopttx_blip_revere`.

* We specify the argument  `V = c("W1", "W2", "W3")` when initializing the `tmle3_Spec`
object in order to communicate that we're interested in learning a rule dependent on `V`
covariates.

* We also need to specify the type of blip we will use in this estimation problem, and
the list of learners used to estimate relevant parts of the likelihood and the blip function.

* In addition, we need to specify whether we want to maximize or minimize the
mean outcome under the rule (`maximize=TRUE`).

* If `complex=FALSE`, `tmle3mopttx` will consider all the possible rules under a smaller set of
covariates including the static rules, and optimize the mean outcome over all the
suboptimal rules dependent on $V$.

* If `realistic=TRUE`, only treatments supported by the data
will be considered, therefore alleviating concerns regarding practical positivity
issues.

```{r mopttx_spec_init_complex}
# initialize a tmle specification
tmle_spec <- tmle3_mopttx_blip_revere(
  V = c("W1", "W2", "W3"), type = "blip1",
  learners = learner_list,
  maximize = TRUE, complex = TRUE,
  realistic = FALSE
)
```

```{r mopttx_fit_tmle_auto_blip_revere_complex, eval=T}
# fit the TML estimator
fit <- tmle3(tmle_spec, data, node_list, learner_list)
fit
```

We can see that the confidence interval covers our true mean under the true optimal 
individualized treatment!

## Categorical Treatment

**QUESTION:** What if the treatment is categorical? Can we still use the blip function?

* In this section, we consider how to evaluate the mean outcome under the optimal
individualized treatment when $A$ has more than two categories!

* We define **pseudo-blips** as vector valued entities where the output for a given
$V$ is a vector of length equal to the number of treatment categories, $n_A$.
As such, we define it as:
$$\bar{Q}_0^{pblip}(V) = \{\bar{Q}_{0,a}^{pblip}(V): a \in \mathcal{A} \}$$

* We implement three different pseudo-blips in `tmle3mopttx`.

1. **Blip1** corresponds to choosing a reference category of treatment, and
defining the blip for all other categories relative to the specified reference:
$$\bar{Q}_{0,a}^{pblip-ref}(V) \equiv E_0(Y_a-Y_0|V)$$

2. **Blip2** approach corresponds to defining the blip relative to the average of
all categories:
$$\bar{Q}_{0,a}^{pblip-avg}(V) \equiv E_0(Y_a- \frac{1}{n_A} \sum_{a \in \mathcal{A}} Y_a|V)$$

3. **Blip3** reflects an extension of Blip2, where the average is now a weighted average:
$$\bar{Q}_{0,a}^{pblip-wavg}(V) \equiv E_0(Y_a- \frac{1}{n_A} \sum_{a \in \mathcal{A}} Y_{a} P(A=a|V)
|V)$$

### Evaluating the Causal Effect of an optimal ITR with Categorical Treatment

While the procedure is analogous to the previously described binary treatment,
we now need to pay attention to the type of blip we define in the estimation stage,
as well as how we construct our learners.

#### Simulated Data

* First, we load the simulated data. Here, our data generating distribution was
of the following form:

$$W \sim \mathcal{N}(\bf{0},I_{4 \times 4})$$
$$P(A|W) = \frac{1}{1+\exp^{(-(0.05*I(A=1)*W_1+0.8*I(A=2)*W_1+0.8*I(A=3)*W_1))}}$$


$$P(Y|A,W) = 0.5\text{logit}^{-1}[15I(A=1)(W_1-0.5) - 3I(A=2)(2W_1+0.5) \\
+ 3I(A=3)(3W_1-0.5)] +\text{logit}^{-1}(W_2W_1)$$

* We can just load the data available as part of the package as follows:

```{r load sim_cat_data}
data("data_cat_realistic")
```

* The above composes our observed data structure $O = (W, A, Y)$. Note that the
mean under the true optimal rule is $\psi=0.658$, which is the quantity we aim
to estimate.

```{r data_nodes-mopttx}
# organize data and nodes for tmle3
data <- data_cat_realistic
node_list <- list(
  W = c("W1", "W2", "W3", "W4"),
  A = "A",
  Y = "Y"
)
```

#### Constructing Optimal Stacked Regressions with `sl3`

**QUESTION:** With categorical treatment, what is the dimension of the blip now?
How would we go about estimating it?

```{r sl3_lrnrs-mopttx}
# Initialize few of the learners:
lrn_xgboost_50 <- Lrnr_xgboost$new(nrounds = 50)
lrn_xgboost_100 <- Lrnr_xgboost$new(nrounds = 100)
lrn_xgboost_500 <- Lrnr_xgboost$new(nrounds = 500)
lrn_mean <- Lrnr_mean$new()
lrn_glm <- Lrnr_glm_fast$new()

## Define the Q learner, which is just a regular learner:
Q_learner <- Lrnr_sl$new(
  learners = list(lrn_xgboost_50, lrn_xgboost_100, lrn_xgboost_500, lrn_mean, lrn_glm),
  metalearner = Lrnr_nnls$new()
)

# Define the g learner, which is a multinomial learner:
#specify the appropriate loss of the multinomial learner:
mn_metalearner <- make_learner(Lrnr_solnp, loss_function = loss_loglik_multinomial,
                               learner_function = metalearner_linear_multinomial)
g_learner <- make_learner(Lrnr_sl, list(lrn_xgboost_100,lrn_xgboost_500,lrn_mean), mn_metalearner)

# Define the Blip learner, which is a multivariate learner:
learners <- list(lrn_xgboost_50, lrn_xgboost_100, lrn_xgboost_500, lrn_mean, lrn_glm)
b_learner <- create_mv_learners(learners = learners)
```

* We generate three different ensemble learners that must be fit,
corresponding to the learners for the outcome regression, propensity score, and the
blip function.

* Note that we need to estimate $g_0(A|W)$ for a categorical $A$- therefore
we use the multinomial Super Learner option available within the `sl3` package with learners
that can address multi-class classification problems.

* In order to see which learners can
be used to estimate $g_0(A|W)$ in `sl3`, we run the following:

```{r cat_learners}
# See which learners support multi-class classification:
sl3_list_learners(c("categorical"))
```

```{r make_lrnr_list-mopttx}
# specify outcome and treatment regressions and create learner list
learner_list <- list(Y = Q_learner, A = g_learner, B = b_learner)
```

#### Targeted Estimation of the Mean under the Optimal Individualized Interventions Effects

```{r spec_init}
# initialize a tmle specification
tmle_spec <- tmle3_mopttx_blip_revere(
  V = c("W1", "W2", "W3", "W4"), type = "blip2",
  learners = learner_list, maximize = TRUE, complex = TRUE,
  realistic = FALSE
)
```

```{r fit_tmle_auto, eval=T}
# fit the TML estimator
fit <- tmle3(tmle_spec, data, node_list, learner_list)
fit

# How many individuals got assigned each treatment?
table(tmle_spec$return_rule)
```

We can see that the confidence interval covers
our true mean under the true optimal individualized treatment.

**NOTICE the distribution of the assigned treatment! We will need this shortly.**

## Extensions to Causal Effect of an OIT

* We consider two extensions to the procedure described for
estimating the value of the ITR.

* The first one considers a setting where the user
might be interested in a grid of possible suboptimal rules, corresponding to
potentially limited knowledge of potential effect modifiers (**Simpler Rules**).

* The second extension concerns implementation of realistic optimal individual
interventions where certain regimes might be preferred, but due to practical or
global positivity restraints are not realistic to implement (**Realistic Interventions**).

### Simpler Rules

* In order to not only consider the most ambitious fully $V$-optimal rule, we
define $S$-optimal rules as the optimal rule that considers all possible subsets
of $V$ covariates, with card($S$) $\leq$ card($V$) and $\emptyset \in S$.

* This allows us to consider sub-optimal rules that are easier to estimate and
potentially provide more realistic rules- as such, we allow for statistical
inference for the counterfactual mean outcome under the sub-optimal rule.

```{r mopttx_spec_init_noncomplex}
# initialize a tmle specification
tmle_spec <- tmle3_mopttx_blip_revere(
  V = c("W4", "W3", "W2", "W1"), type = "blip2",
  learners = learner_list,
  maximize = TRUE, complex = FALSE, realistic = FALSE
)
```

```{r mopttx_fit_tmle_auto_blip_revere_noncomplex, eval=T}
# fit the TML estimator
fit <- tmle3(tmle_spec, data, node_list, learner_list)
fit
```

Even though the user specified all baseline covariates as the basis
for rule estimation, a simpler rule is sufficient to
maximize the mean under the optimal individualized treatment!

**QUESTION:** Why do you think the estimate
   if higher under the less complex rule? How does the set of covariates picked by `tmle3mopttx`
   compare to the baseline covariates the true rule depends on?

### Realistic Optimal Individual Regimes

* `tmle3mopttx` also provides an option to estimate the mean under the
realistic, or implementable, optimal individualized treatment.

* It is often the case that assigning particular regime might have the ability to
fully maximize (or minimize) the desired outcome, but due to
global or practical positivity constrains, such treatment
can never be implemented in real life (or is highly unlikely).

* Specifying `realistic="TRUE"`, we consider possibly suboptimal
treatments that optimize the outcome in question while being
supported by the data.

```{r mopttx_spec_init_realistic}
# initialize a tmle specification
tmle_spec <- tmle3_mopttx_blip_revere(
  V = c("W4", "W3", "W2", "W1"), type = "blip2",
  learners = learner_list,
  maximize = TRUE, complex = TRUE, realistic = TRUE
)
```

```{r mopttx_fit_tmle_auto_blip_revere_realistic, eval=T}
# fit the TML estimator
fit <- tmle3(tmle_spec, data, node_list, learner_list)
fit

# How many individuals got assigned each treatment?
table(tmle_spec$return_rule)
```

**QUESTION:** Referring back to the data-generating distribution, why do you
think the distribution of allocated treatment changed from the distribution 
we had under the "non-realistic"" rule?

### Variable Importance Analysis

* In the previous sections we have seen how to obtain a contrast between the
mean under the optimal individualized rule and the mean under the observed outcome for a
single covariate. We are now ready to run the variable importance analysis for all of our
observed covariates!

* In order to run `tmle3mopttx` variable importance measure, we
need considered covariates to be categorical variables.

* For illustration purpose,
we bin baseline covariates corresponding to the data-generating distribution
described in the previous section:

```{r data_vim-nodes-mopttx}
# bin baseline covariates to 3 categories:
data$W1<-ifelse(data$W1<quantile(data$W1)[2],1,ifelse(data$W1<quantile(data$W1)[3],2,3))

node_list <- list(
  W = c("W3", "W4", "W2"),
  A = c("W1", "A"),
  Y = "Y"
)
```

* Note that our node list now includes $W_1$ as treatments as well!
Don't worry, we will still properly adjust for all baseline covariates when
considering $A$ as treatment.

#### Variable Importance using Targeted Estimation of the value of the ITR

* We will initialize a specification for the TMLE of our parameter of
interest (called a `tmle3_Spec` in the `tlverse` nomenclature) simply by calling
`tmle3_mopttx_vim`.

```{r mopttx_spec_init_vim}
# initialize a tmle specification
tmle_spec <- tmle3_mopttx_vim(
  V=c("W2"),
  type = "blip2",
  learners = learner_list,
  contrast = "multiplicative",
  maximize = FALSE,
  method = "SL",
  complex = TRUE,
  realistic = FALSE
)
```

```{r mopttx_fit_tmle_auto_vim, eval=TRUE}
# fit the TML estimator
vim_results <- tmle3_vim(tmle_spec, data, node_list, learner_list,
  adjust_for_other_A = TRUE
)

print(vim_results)
```

The final result of `tmle3_vim` with the `tmle3mopttx` spec is an ordered list
of mean outcomes under the optimal individualized treatment for all categorical
covariates in our dataset.

## Exercise

### Real World Data and `tmle3mopttx`

Finally, we cement everything we learned so far with a real data application. 

As in the previous sections, we will be using the WASH Benefits data,
corresponding to the Effect of water quality, sanitation, hand washing, and
nutritional interventions on child development in rural Bangladesh trial.

The main aim of the cluster-randomized controlled trial was to assess the
impact of six intervention groups, including:

1. Control

2. Handwashing with soap

3. Improved nutrition through counselling and provision of lipid-based nutrient supplements

4. Combined water, sanitation, handwashing, and nutrition.

5. Improved sanitation

6. Combined water, sanitation, and handwashing

7. Chlorinated drinking water

We aim to estimate the optimal ITR and the corresponding value under the optimal ITR
for the main intervention in WASH Benefits data!

Our outcome of interest is the weight-for-height Z-score, whereas our treatment is
the six intervention groups aimed at improving living conditions.

**Work with a buddy. You have 20 minutes.**

In the etherpad, submit your group's answers to the following questions.

1. Define $V$ as mother's education (`momedu`), current living conditions (`floor`), 
   and possession of material items including the refrigerator (`asset_refrig`). 
   Why do you think we use these covariates as $V$?
   Do we want to minimize or maximize the outcome? Which blip type should we use?
   Construct an approprite `sl3` library for $A$, $Y$ and $B$.
   
2. Based on the $V$ defined in the previous question, estimate the mean under the ITR for
   the main randomized intervention used in the WASH Benefits trial
   with weight-for-height Z-score as the outcome. What's the TMLE value of the optimal ITR?
   How does it change from the initial estimate? Which intervention is the most dominant? 
   Why do you think that is?
   
3. Using the same formulation as in questions 1 and 2, estimate the realistic optimal ITR 
   and the corresponding value of the realistic ITR. Did the results change? Which intervention 
   is the most dominant under realistic rules? Why do you think that is?   

## Summary

* In summary, the mean outcome under the optimal individualized treatment is a counterfactual
quantity of interest representing what the mean outcome would have been if everybody, contrary
to the fact, received treatment that optimized their outcome.

* `tmle3mopttx` estimates the mean outcome under the optimal individualized treatment, where the candidate
rules are restricted to only respond to a user-supplied subset of the baseline and intermediate
covariates. In addition it provides options for realistic, data-adaptive interventions.

* In essence, our target parameter answers the key aim of precision medicine: allocating
the available treatment by tailoring it to the individual characteristics of the patient, with the
goal of optimizing the final outcome.

### Solutions

To start, let's load the data, convert all columns to be of class `numeric`,
and take a quick look at it:

```{r load-washb-data, message=FALSE, warning=FALSE, cache=FALSE, eval=FALSE}
washb_data <- fread("https://raw.githubusercontent.com/tlverse/tlverse-data/master/wash-benefits/washb_data.csv", stringsAsFactors = TRUE)
washb_data <- washb_data[!is.na(momage), lapply(.SD, as.numeric)]
head(washb_data, 3)
```

As before, we specify the NPSEM via the `node_list` object.

```{r washb-data-npsem-mopttx, message=FALSE, warning=FALSE, cache=FALSE, eval=FALSE}
node_list <- list(W = names(washb_data)[!(names(washb_data) %in% c("whz", "tr"))],
                  A = "tr", Y = "whz")
```

We pick few potential effect modifiers, including mother's education, current
living conditions (floor), and possession of material items including the refrigerator.
We concentrate of these covariates as they might be indicative of the socio-economic status
of individuals involved in the trial. We can explore the distribution of our $V$, $A$ and $Y$:

```{r summary_WASH, eval=FALSE}
#V1, V2 and V3:
table(washb_data$momedu)
table(washb_data$floor)
table(washb_data$asset_refrig)

#A:
table(washb_data$tr)

#Y:
summary(washb_data$whz)
```

We specify a simply library for the outcome regression, propensity score
and the blip function. Since our treatment is categorical, we need to define a
multinomial learner for $A$ and multivariate learner for $B$. We 
will define the `xgboost` over a grid of parameters, and initialize a mean learner.

```{r sl3_lrnrs-WASH-mopttx, eval=FALSE}
# Initialize few of the learners:
grid_params = list(nrounds = c(100, 500),
                     eta = c(0.01, 0.1))
grid = expand.grid(grid_params, KEEP.OUT.ATTRS = FALSE)
xgb_learners = apply(grid, MARGIN = 1, function(params_tune) {
    do.call(Lrnr_xgboost$new, c(as.list(params_tune)))
  })
lrn_mean <- Lrnr_mean$new()

## Define the Q learner, which is just a regular learner:
Q_learner <- Lrnr_sl$new(
  learners = list(xgb_learners[[1]], xgb_learners[[2]], xgb_learners[[3]],
                  xgb_learners[[4]], lrn_mean),
  metalearner = Lrnr_nnls$new()
)

# Define the g learner, which is a multinomial learner:
#specify the appropriate loss of the multinomial learner:
mn_metalearner <- make_learner(Lrnr_solnp, loss_function = loss_loglik_multinomial,
                               learner_function = metalearner_linear_multinomial)
g_learner <- make_learner(Lrnr_sl, list(xgb_learners[[4]], lrn_mean), mn_metalearner)

# Define the Blip learner, which is a multivariate learner:
learners <- list(xgb_learners[[1]], xgb_learners[[2]], xgb_learners[[3]],
                  xgb_learners[[4]], lrn_mean)
b_learner <- create_mv_learners(learners = learners)

learner_list <- list(Y = Q_learner, A = g_learner, B = b_learner)
```

As seen before, we initialize the `tmle3_mopttx_blip_revere` Specn in order to 
answer Question 1. We want to maximize our outcome, with higher the weight-for-height Z-score
the better. We will also use `blip2` as the blip type, but note that we could have used `blip1`
as well since "Control" is a good reference category. 

```{r spec_init_WASH, eval=FALSE}
## Question 2:

#Initialize a tmle specification
tmle_spec <- tmle3_mopttx_blip_revere(
  V = c("momedu", "floor", "asset_refrig"), type = "blip2",
  learners = learner_list, maximize = TRUE, complex = TRUE,
  realistic = FALSE
)

#Fit the TML estimator.
fit <- tmle3(tmle_spec, data=washb_data, node_list, learner_list)
fit

#Which intervention is the most dominant? 
table(tmle_spec$return_rule)
```

Using the same formulation as before, we estimate the realistic optimal ITR 
and the corresponding value of the realistic ITR:

```{r spec_init_WASH_simple_q3, eval=FALSE}
## Question 3:

#Initialize a tmle specification with "realistic=TRUE":
tmle_spec <- tmle3_mopttx_blip_revere(
  V = c("momedu", "floor", "asset_refrig"), type = "blip2",
  learners = learner_list, maximize = TRUE, complex = TRUE,
  realistic = TRUE
)

#Fit the TML estimator.
fit <- tmle3(tmle_spec, data=washb_data, node_list, learner_list)
fit

table(tmle_spec$return_rule)
```

<!--chapter:end:06-tmle3mopttx.Rmd-->

# Stochastic Treatment Regimes

_Nima Hejazi_

Based on the [`tmle3shift` `R` package](https://github.com/tlverse/tmle3shift)
by _Nima Hejazi, Jeremy Coyle, and Mark van der Laan_.

Updated: `r Sys.Date()`

## Learning Objectives

1. Differentiate stochastic treatment regimes from static, dynamic, and optimal
   treatment regimes.
2. Describe how estimating causal effects of stochastic interventions informs a
   real-world data analysis.
3. Contrast a population level stochastic intervention policy from a modified
   treatment policy.
4. Estimate causal effects under stochastic treatment regimes with the
   `tmle3shift` `R` package.
5. Specify a grid of counterfactual shift interventions to be used for defining
   a set of stochastic intervention policies.
6. Interpret a set of effect estimates from a grid of counterfactual shift
   interventions.
7. Construct marginal structural models to measure variable importance in terms
   of stochastic interventions, using a grid of shift interventions.
8. Implement a shift intervention at the individual level, to facilitate
   shifting each individual to a value that's supported by the data.
9. Define novel shift intervention functions to extend the `tmle3shift` `R`
   package.

## Introduction

In this section, we examine a simple example of stochastic treatment regimes in
the context of a continuous treatment variable of interest, defining an
intuitive causal effect through which to examine stochastic interventions more
generally. As a first step to using stochastic
treatment regimes in practice, we present the [`tmle3shift` R
package](https://github.com/tlverse/tmle3shift), which features an
implementation of a recently developed algorithm for computing targeted minimum
loss-based estimates of a causal effect based on a stochastic treatment regime
that shifts the natural value of the treatment based on a shifting function
$d(A,W)$. We will also use `tmle3shift` to construct marginal structural models
for variable importance measures, implement shift interventions at the
individual level, and define novel shift intervention functions.

## Stochastic Interventions

* Present a relatively simple yet extremely flexible manner by which _realistic_
  causal effects (and contrasts thereof) may be defined.
* May be applied to nearly any manner of treatment variable -- continuous,
  ordinal, categorical, binary -- allowing for a rich set of causal effects to
  be defined through this formalism.
* Arguably the most general of the classes of interventions through which causal
  effects may be defined, and are conceptually simple.

* We may consider stochastic interventions in two ways:

  1. The equation $f_A$, which produces $A$, is replaced by a probabilistic
     mechanism $g_{\delta}(A \mid W)$ that differs from the original $g(A \mid
     W)$. The _stochastically modified_ value of the treatment $A_{\delta}$ is
     drawn from a user-specified distribution $g_\delta(A \mid W)$, which may
     depend on the original distribution $g(A \mid W)$ and is indexed by a
     user-specified parameter $\delta$. In this case, the stochastically
     modified value of the treatment $A_{\delta} \sim g_{\delta}(\cdot \mid W)$.

  2. The observed value $A$ is replaced by a new value $A_{d(A,W)}$ based on
     applying a user-defined function $d(A,W)$ to $A$. In this case, the
     stochastic treatment regime may be viewed as an intervention in which $A$
     is set equal to a value based on a hypothetical regime $d(A, W)$, where
     regime $d$ depends on the treatment level $A$ that would be assigned in the
     absence of the regime as well as the covariates $W$. Stochastic
     interventions of this variety may be referred to as depending on the
     _natural value of treatment_ or as _modified treatment policies_
     [@haneuse2013estimation; @young2014identification].

### Identifying the Causal Effect of a Stochastic Intervention

* The stochastic intervention generates a counterfactual random variable
  $Y_{d(A,W)} := f_Y(d(A,W), W, U_Y) \equiv Y_{g_{\delta}} := f_Y(A_{\delta},
  W, U_Y)$, where $Y_{d(A,W)} \sim \mathcal{P}_0^{\delta}$.

* The target causal estimand of our analysis is $\psi_{0, \delta} :=
  \mathbb{E}_{P_0^{\delta}}\{Y_{d(A,W)}\}$, the mean of the counterfactual
  outcome variable $Y_{d(A, W)}$. The statistical target parameter may also be
  denoted $\Psi(P_0) = \mathbb{E}_{P_0}{\overline{Q}(d(A, W), W)}$, where
  $\overline{Q}(d(A, W), W)$ is the counterfactual outcome value of a given
  individual under the stochastic intervention distribution
  [@diaz2018stochastic].

* In prior work, @diaz2012population showed that the causal quantity of interest
  $\mathbb{E}_0 \{Y_{d(A, W)}\}$ is identified by a functional of the
  distribution of $O$:
  \begin{align*}\label{eqn:identification2012}
    \psi_{0,d} = \int_{\mathcal{W}} \int_{\mathcal{A}} & \mathbb{E}_{P_0}
     \{Y \mid A = d(a, w), W = w\} \cdot \\ &q_{0, A}^O(a \mid W = w) \cdot
     q_{0, W}^O(w) d\mu(a)d\nu(w).
  \end{align*}

* The four standard assumptions presented in \ref{intro} are necessary in order
  to establish identifiability of the causal parameter from the observed data
  via the statistical functional. These were

  1. _Consistency_: $Y^{d(a_i, w_i)}_i = Y_i$ in the event $A_i = d(a_i, w_i)$,
     for $i = 1, \ldots, n$
  2. _Stable unit value treatment assumption (SUTVA)_: $Y^{d(a_i, w_i)}_i$ does
     not depend on $d(a_j, w_j)$ for $i = 1, \ldots, n$ and $j \neq i$, or lack
     of interference [@rubin1978bayesian; @rubin1980randomization].
  3. _Strong ignorability_: $A_i \indep Y^{d(a_i, w_i)}_i \mid W_i$, for $i = 1,
     \ldots, n$.
  4. Positivity (or overlap)_: $a_i \in \mathcal{A} \implies d(a_i, w_i) \in
     \mathcal{A}$ for all $w \in \mathcal{W}$, where $\mathcal{A}$ denotes the
     support of $A \mid W = w_i \quad \forall i = 1, \ldots n$.

* With the identification assumptions satisfied, @diaz2012population and
  @diaz2018stochastic provide an efficient influence function with respect to
  the nonparametric model $\mathcal{M}$ as
  \begin{equation*}\label{eqn:eif}
    D(P_0)(x) = H(a, w)({y - \overline{Q}(a, w)}) +
    \overline{Q}(d(a, w), w) - \Psi(P_0),
  \end{equation*}
  where the auxiliary covariate $H(a,w)$ may be expressed
  \begin{equation*}\label{eqn:aux_covar_full}
    H(a,w) = \mathbb{I}(a + \delta < u(w)) \frac{g_0(a - \delta \mid w)} {g_0(a \mid w)}
      + \mathbb{I}(a + \delta \geq u(w)),
  \end{equation*}
  which may be reduced to
  \begin{equation*}\label{eqn:aux_covar_simple}
    H(a,w) = \frac{g_0(a - \delta \mid w)}{g_0(a \mid w)} + 1
  \end{equation*}
  in the case that the treatment is in the limits that arise from conditioning
  on $W$, i.e., for $A_i \in (u(w) - \delta, u(w))$.

### Interpreting the Causal Effect of a Stochastic Intervention

```{r, fig.cap="Animation of how a counterfactual outcome changes as the natural treatment distribution is subjected to a simple stochastic intervention", echo=FALSE, eval=TRUE, out.width='60%'}
knitr::include_graphics(path = "img/gif/shift_animation.gif")
```

## Estimating the Causal Effect of a Stochastic Intervention with `tmle3shift`

We use `tmle3shift` to construct a targeted maximum likelihood (TML) estimator of
of a causal effect of a stochastic treatment regime that shifts the natural
value of the treatment based on a shifting function $d(A,W)$. We will follow
the recipe provided by @diaz2018stochastic, tailored to the `tmle3` framework:

1. Construct initial estimators $g_n$ of $g_0(A, W)$ and $Q_n$ of
   $\overline{Q}_0(A, W)$, perhaps using data-adaptive regression techniques.
2. For each observation $i$, compute an estimate $H_n(a_i, w_i)$ of the
   auxiliary covariate $H(a_i,w_i)$.
3. Estimate the parameter $\epsilon$ in the logistic regression model
   $$ \text{logit}\overline{Q}_{\epsilon, n}(a, w) =
   \text{logit}\overline{Q}_n(a, w) + \epsilon H_n(a, w),$$
   or an alternative regression model incorporating weights.
4. Compute TML estimator $\Psi_n$ of the target parameter, defining update
   $\overline{Q}_n^{\star}$ of the initial estimate
   $\overline{Q}_{n, \epsilon_n}$:
   \begin{equation*}\label{eqn:tmle}
     \Psi_n = \Psi(P_n^{\star}) = \frac{1}{n} \sum_{i = 1}^n
     \overline{Q}_n^{\star}(d(A_i, W_i), W_i).
   \end{equation*}

To start, let's load the packages we'll use and set a seed for simulation:

```{r setup-shift, message=FALSE, warning=FALSE}
library(tidyverse)
library(data.table)
library(condensier)
library(sl3)
library(tmle3)
library(tmle3shift)
set.seed(429153)
```

**1. Construct initial estimators $g_n$ of $g_0(A, W)$ and $Q_n$ of
   $\overline{Q}_0(A, W)$.**

We need to estimate two components of the likelihood in order to construct a
TML estimator.

1. The outcome regression, $\hat{Q}_n$, which is a simple regression of the
   form $\mathbb{E}[Y \mid A,W]$.

```{r sl3_lrnrs-Qfit-shift, message=FALSE, warning=FALSE}
# learners used for conditional expectation regression
lrn_mean <- Lrnr_mean$new()
lrn_fglm <- Lrnr_glm_fast$new()
lrn_xgb <- Lrnr_xgboost$new(nrounds = 200)
sl_lrn <- Lrnr_sl$new(
  learners = list(lrn_mean, lrn_fglm, lrn_xgb),
  metalearner = Lrnr_nnls$new()
)
```

2. The treatment mechanism, $\hat{g}_n$, i.e., the _propensity score_. In the
   case of a continuous intervention, such a quantity is a conditional density.
   Generally speaking, conditional density estimation is a challenging
   problem that has received much attention in the literature. To estimate the
   treatment mechanism, we must make use of learning algorithms specifically
   suited to conditional density estimation; a list of such learners may be
   extracted from `sl3` by using `sl3_list_learners()`:

```{r sl3_density_lrnrs_search-shift, message=FALSE, warning=FALSE}
sl3_list_learners("density")
```

To proceed, we'll select two of the above learners, `Lrnr_haldensify` for using
the highly adaptive lasso for conditional density estimation, based on an
algorithm given by @diaz2011super and implemented in @hejazi2019haldensify, and
`Lrnr_rfcde`, an approach for using random forests for conditional density
estimation [@pospisil2018rfcde]. A Super Learner may be constructed by pooling
estimates from each of these modified conditional density regression techniques.

```{r sl3_lrnrs-gfit-shift, message=FALSE, warning=FALSE}
# learners used for conditional density regression (i.e., propensity score)
lrn_haldensify <- Lrnr_haldensify$new(
  n_bins = 5, grid_type = "equal_mass",
  lambda_seq = exp(seq(-1, -13, length = 500))
)
lrn_rfcde <- Lrnr_rfcde$new(
  n_trees = 1000, node_size = 5,
  n_basis = 31, output_type = "observed"
)
sl_lrn_dens <- Lrnr_sl$new(
  learners = list(lrn_haldensify, lrn_rfcde),
  metalearner = Lrnr_solnp_density$new()
)
```

Finally, we construct a `learner_list` object for use in constructing a TML
estimator of our target parameter of interest:

```{r learner-list-shift, message=FALSE, warning=FALSE}
Q_learner <- sl_lrn
g_learner <- sl_lrn_dens
learner_list <- list(Y = Q_learner, A = g_learner)
```

### Simulate Data

```{r sim_data, message=FALSE, warning=FALSE}
# simulate simple data for tmle-shift sketch
n_obs <- 1000 # number of observations
tx_mult <- 2 # multiplier for the effect of W = 1 on the treatment

## baseline covariates -- simple, binary
W <- replicate(2, rbinom(n_obs, 1, 0.5))

## create treatment based on baseline W
A <- rnorm(n_obs, mean = tx_mult * W, sd = 1)

## create outcome as a linear function of A, W + white noise
Y <- rbinom(n_obs, 1, prob = plogis(A + W))

# organize data and nodes for tmle3
data <- data.table(W, A, Y)
setnames(data, c("W1", "W2", "A", "Y"))
node_list <- list(W = c("W1", "W2"), A = "A", Y = "Y")
head(data)
```

We now have an observed data structure (`data`) and a specification of the role
that each variable in the data set plays as the nodes in a _directed acyclic
graph_ (DAG) via _nonparametric structural equation models_ (NPSEMs).

To start, we will initialize a specification for the TMLE of our parameter of
interest (a `tmle3_Spec` in the `tlverse` nomenclature) simply by calling
`tmle_shift`. We specify the argument `shift_val = 0.5` when initializing the
`tmle3_Spec` object to communicate that we're interested in a shift of $0.5$ on
the scale of the treatment $A$ -- that is, we specify $\delta = 0.5$.

```{r spec_init-shift, message=FALSE, warning=FALSE}
# initialize a tmle specification
tmle_spec <- tmle_shift(
  shift_val = 0.5,
  shift_fxn = shift_additive_bounded,
  shift_fxn_inv = shift_additive_bounded_inv
)
```

As seen above, the `tmle_shift` specification object (like all `tmle3_Spec`
objects) does _not_ store the data for our specific analysis of interest. Later,
we'll see that passing a data object directly to the `tmle3` wrapper function,
alongside the instantiated `tmle_spec`, will serve to construct a `tmle3_Task`
object internally (see the `tmle3` documentation for details).

Note that in the initialization of the `tmle3_Spec`, we specified a shifting
function `shift_additive_bounded` (and its inverse). This shifting function
corresponds to a stochastic regime slightly more complicated than that initially
considered in @diaz2018stochastic. In particular, `shift_additive_bounded` is
encapsulates a procedure that determines an acceptable set of shifting values
for the shift $\delta$, allowing for the observed treatment value of a given
observation to be shifted if the auxiliary covariate $H_n$ is bounded by a
constant and not shifting the given observation if this criterion does not
hold. We discuss this in greater detail in the sequel.

### Targeted Estimation of Stochastic Interventions Effects

```{r fit_tmle-shift, message=FALSE, warning=FALSE, cache=FALSE}
tmle_fit <- tmle3(tmle_spec, data, node_list, learner_list)
tmle_fit
```

The `print` method of the resultant `tmle_fit` object conveniently displays the
results from computing our TML estimator.

## Stochastic Interventions over a Grid of Counterfactual Shifts

* Consider an arbitrary scalar $\delta$ that defines a counterfactual outcome
  $\psi_n = Q_n(d(A, W), W)$, where, for simplicity, let $d(A, W) = A + \delta$.
  A simplified expression of the auxiliary covariate for the TMLE of $\psi$ is
  $H_n = \frac{g^{\star}(a \mid w)}{g(a \mid w)}$, where $g^{\star}(a \mid w)$
  defines the treatment mechanism with the stochastic intervention implemented.
  In this manner, we can specify a _grid_ of shifts $\delta$ to define a set of
  stochastic intervention policies in an _a priori_ manner.

* To ascertain whether a given choice of the shift $\delta$ is acceptable, let
  there be a bound $C(\delta) = \frac{g^{\star}(a \mid w)}{g(a \mid w)} < M$, where
  $g^{\star}(a \mid w)$ is a function of $\delta$ in part, and $M$ is a
  user-specified upper bound of $C(\delta)$. Then, $C(\delta)$ is a measure of
  the influence of a given observation (under a bound of the ratio of the
  conditional densities), which provides a way to limit the maximum influence of
  a given observation through a choice of the shift $\delta$.

* For the purpose of using such a shift in practice, the present software
  provides the functions `shift_additive_bounded` and
  `shift_additive_bounded_inv`, which define a variation of this shift:
  \begin{equation}
    \delta(a, w) =
      \begin{cases}
        \delta, & C(\delta) \leq M \\
        0, \text{otherwise} \\
      \end{cases},
  \end{equation}
  which corresponds to an intervention in which the natural value of treatment
  of a given observational unit is shifted by a value $\delta$ in the case that
  the ratio of the intervened density $g^{\star}(a \mid w)$ to the natural
  density $g(a \mid w)$ (that is, $C(\delta)$) does not exceed a bound $M$. In
  the case that the ratio $C(\delta)$ exceeds the bound $M$, the stochastic
  intervention policy does not apply to the given unit and they remain at their
  natural value of treatment $a$.

### Initializing `vimshift` through its `tmle3_Spec`

To start, we will initialize a specification for the TMLE of our parameter of
interest (called a `tmle3_Spec` in the `tlverse` nomenclature) simply by calling
`tmle_shift`. We specify the argument `shift_grid = seq(-1, 1, by = 1)`
when initializing the `tmle3_Spec` object to communicate that we're interested
in assessing the mean counterfactual outcome over a grid of shifts `r seq(-1,
1, by = 1)` on the scale of the treatment $A$.

```{r vim_spec_init, message=FALSE, warning=FALSE}
# what's the grid of shifts we wish to consider?
delta_grid <- seq(-1, 1, 1)

# initialize a tmle specification
tmle_spec <- tmle_vimshift_delta(
  shift_grid = delta_grid,
  max_shifted_ratio = 2
)
```

### Targeted Estimation of Stochastic Intervention Effects

One may walk through the step-by-step procedure for fitting the TML estimator
of the mean counterfactual outcome under each shift in the grid, using the
machinery exposed by the [`tmle3` R package](https://tlverse.org/tmle3), or
simply invoke the `tmle3` wrapper function  to fit the series of TML estimators
(one for each parameter defined by the grid delta) in a single function call.
For convenience, we choose the latter:

```{r fit_tmle_wrapper_vimshift, message=FALSE, warning=FALSE, cache=FALSE}
tmle_fit <- tmle3(tmle_spec, data, node_list, learner_list)
tmle_fit
```

_Remark_: The `print` method of the resultant `tmle_fit` object conveniently
displays the results from computing our TML estimator.

### Inference with Marginal Structural Models

Since we consider estimating the mean counterfactual outcome $\psi_n$ under
several values of the intervention $\delta$, taken from the aforementioned
$\delta$-grid, one approach for obtaining inference on a single summary measure
of these estimated quantities involves leveraging working marginal structural
models (MSMs). Summarizing the estimates $\psi_n$ through a working MSM allows
for inference on the _trend_ imposed by a $\delta$-grid to be evaluated via a
simple hypothesis test on a parameter of this working MSM. Letting
$\psi_{\delta}(P_0)$ be the mean outcome under a shift $\delta$ of the
treatment, we have $\vec{\psi}_{\delta} = (\psi_{\delta}: \delta)$ with
corresponding estimators $\vec{\psi}_{n, \delta} = (\psi_{n, \delta}: \delta)$.
Further, let $\beta(\vec{\psi}_{\delta}) = \phi((\psi_{\delta}: \delta))$. By a
straightforward application of the delta method (discussed previously), we may
write the efficient influence function of the MSM parameter $\beta$ in terms of
the EIFs of each of the corresponding point estimates. Based on this, inference
from a working MSM is rather straightforward. To wit, the limiting distribution
for $m_{\beta}(\delta)$ may be expressed $$\sqrt{n}(\beta_n - \beta_0) \to N(0,
\Sigma),$$ where $\Sigma$ is the empirical covariance matrix of
$\text{EIF}_{\beta}(O)$.

```{r msm_fit, message=FALSE, warning=FALSE}
tmle_fit$summary[4:5, ]
```

### Directly Targeting the MSM Parameter $\beta$

Note that in the above, a working MSM is fit to the individual TML estimates of
the mean counterfactual outcome under a given value of the shift $\delta$ in
the supplied grid. The parameter of interest $\beta$ of the MSM is
asymptotically linear (and, in fact, a TML estimator) as a consequence of its
construction from individual TML estimators. In smaller samples, it may be
prudent to perform a TML estimation procedure that targets the parameter
$\beta$ directly, as opposed to constructing it from several independently
targeted TML estimates. An approach for constructing such an estimator is
proposed in the sequel.

Suppose a simple working MSM $\mathbb{E}Y_{g^0_{\delta}} = \beta_0 + \beta_1
\delta$, then a TML estimator targeting $\beta_0$ and $\beta_1$ may be
constructed as
$$\overline{Q}_{n, \epsilon}(A,W) = \overline{Q}_n(A,W) + \epsilon (H_1(g),
H_2(g),$$ for all $\delta$, where $H_1(g)$ is the auxiliary covariate for
$\beta_0$ and $H_2(g)$ is the auxiliary covariate for $\beta_1$.

To construct a targeted maximum likelihood estimator that directly targets the
parameters of the working marginal structural model, we may use the
`tmle_vimshift_msm` Spec (instead of the `tmle_vimshift_delta` Spec that
appears above):

```{r vim_targeted_msm_fit, message=FALSE, warning=FALSE, cache=FALSE}
# initialize a tmle specification
tmle_msm_spec <- tmle_vimshift_msm(
  shift_grid = delta_grid,
  max_shifted_ratio = 2
)

# fit the TML estimator and examine the results
tmle_msm_fit <- tmle3(tmle_msm_spec, data, node_list, learner_list)
tmle_msm_fit
```

### Example with the WASH Benefits Data

To complete our walk through, let's turn to using stochastic interventions to
investigate the data from the WASH Benefits trial. To start, let's load the
data, convert all columns to be of class `numeric`, and take a quick look at it

```{r load-washb-data-shift, message=FALSE, warning=FALSE, cache=FALSE}
washb_data <- fread("https://raw.githubusercontent.com/tlverse/tlverse-data/master/wash-benefits/washb_data.csv", stringsAsFactors = TRUE)
washb_data <- washb_data[!is.na(momage), lapply(.SD, as.numeric)]
head(washb_data, 3)
```

Next, we specify our NPSEM via the `node_list` object. For our example analysis,
we'll consider the outcome to be the weight-for-height Z-score (as in previous
sections), the intervention of interest to be the mother's age at time of
child's birth, and take all other covariates to be potential confounders.

```{r washb-data-npsem-shift, message=FALSE, warning=FALSE, cache=FALSE}
node_list <- list(
  W = names(washb_data)[!(names(washb_data) %in%
    c("whz", "momage"))],
  A = "momage", Y = "whz"
)
```

Were we to consider the counterfactual weight-for-height Z-score under shifts in
the age of the mother at child's birth, how would we interpret estimates of our
parameter? To simplify our interpretation, consider a shift of just a year in
the mother's age (i.e., $\delta = 1$); in this setting, a stochastic
intervention would correspond to a policy advocating that potential mothers
defer having a child for a single calendar year, possibly implemented through an
encouragement design deployed in a clinical setting.

For this example, we'll use the variable importance strategy of considering a
grid of stochastic interventions to evaluate the weight-for-height Z-score under
a shift in the mother's age down by two years ($\delta = -2$), up by two years
($\delta = 2$), and under no shift at all ($\delta = 0$). To do this, we simply
initialize a `Spec` `tmle_vimshift_delta` just as we did in a previous example

```{r vim_spec_init_washb, message=FALSE, warning=FALSE}
# initialize a tmle specification for the variable importance parameter
washb_vim_spec <- tmle_vimshift_delta(
  shift_grid = c(-2, 2),
  max_shifted_ratio = 2
)
```

Prior to running our analysis, we'll modify the `learner_list` object we had
created such that the density estimation procedure we rely on will be only the
random forest conditional density estimation procedure of @pospisil2018rfcde, as
the nonparametric conditional density approach based on the highly adaptive
lasso [@diaz2011super; @benkeser2016hal; @coyle2018hal9001;
@hejazi2019haldensify] is currently unable to accommodate large datasets.

```{r sl3_lrnrs-gfit-shift-washb, message=FALSE, warning=FALSE}
# learners used for conditional density regression (i.e., propensity score)
lrn_rfcde <- Lrnr_rfcde$new(
  n_trees = 500, node_size = 3,
  n_basis = 20, output_type = "observed"
)
# modify learner list, using existing SL for Q fit
learner_list <- list(Y = sl_lrn, A = lrn_rfcde)
```

Having made the above preparations, we're now ready to estimate the
counterfactual mean of the weight-for-height Z-score under a small grid of
shifts in the mother's age at child's birth. Just as before, we do this through
a simple call to our `tmle3` wrapper function:

```{r fit_tmle_wrapper_washb, message=FALSE, warning=FALSE, eval=FALSE}
washb_tmle_fit <- tmle3(washb_vim_spec, washb_data, node_list, learner_list)
washb_tmle_fit
```

---

## Exercises

1. Set the `sl3` library of algorithms for the Super Learner to a simple,
   interpretable library and use this new library to estimate the counterfactual
   mean of mother's age at child's birth (`momage`) under a shift $\delta = 0$.
   What does this counterfactual mean equate to in terms of the observed data?

2. Describe two (equivalent) ways in which the causal effects of stochastic
   interventions may be interpreted.

3. Using a grid of values of the shift parameter $\delta$ (e.g., $\{-1, 0,
   +1\}$), repeat the analysis on the variable of interest (`momage`),
   summarizing the trend for this sequence of shifts using a marginal structural
   model.

4. How does the marginal structural model we used to summarize the trend along
   the sequence of shifts previously help to contextualize the estimated effect
   for a single shift? That is, how does access to estimates across several
   shifts and the marginal structural model parameters allow us to more richly
   interpret our findings?

<!--chapter:end:07-tmle3shift.Rmd-->

# A Primer on the `R6` Class System {#r6}

A central goal of the Targeted Learning statistical paradigm is to estimate
scientifically relevant parameters in realistic (usually nonparametric) models.

The `tlverse` is designed using basic OOP principles and the `R6` OOP framework.
While we've tried to make it easy to use the `tlverse` packages without worrying
much about OOP, it is helpful to have some intuition about how the `tlverse` is
structured. Here, we briefly outline some key concepts from OOP. Readers
familiar with OOP basics are invited to skip this section.

## Classes, Fields, and Methods

The key concept of OOP is that of an object, a collection of data and functions
that corresponds to some conceptual unit. Objects have two main types of
elements:

1. _fields_, which can be thought of as nouns, are information about an object,
   and
2. _methods_, which can be thought of as verbs, are actions an object can
   perform.

Objects are members of classes, which define what those specific fields and
methods are. Classes can inherit elements from other classes (sometimes called
base classes) -- accordingly, classes that are similar, but not exactly the
same, can share some parts of their definitions.

Many different implementations of OOP exist, with variations in how these
concepts are implemented and used. R has several different implementations,
including `S3`, `S4`, reference classes, and `R6`. The `tlverse` uses the `R6`
implementation. In `R6`, methods and fields of a class object are accessed using
the `$` operator. For a more thorough introduction to `R`'s various OOP systems,
see http://adv-r.had.co.nz/OO-essentials.html, from Hadley Wickham's _Advanced
R_ [@wickham2014advanced].

## Object Oriented Programming: `Python` and `R`

OO concepts (classes with inherentence) were baked into Python from the first
published version (version 0.9 in 1991). In contrast, `R` gets its OO "approach"
from its predecessor, `S`, first released in 1976. For the first 15 years, `S`
had no support for classes, then, suddenly, `S` got two OO frameworks bolted on
in rapid succession: informal classes with `S3` in 1991, and formal classes with
`S4` in 1998. This process continues, with new OO frameworks being periodically
released, to try to improve the lackluster OO support in `R`, with reference
classes (`R5`, 2010) and `R6` (2014). Of these, `R6` behaves most like Python
classes (and also most like OOP focused languages like C++ and Java), including
having method definitions be part of class definitions, and allowing objects to
be modified by reference.

<!--chapter:end:98-r6_primer.Rmd-->

`r if (knitr::is_html_output()) '
# References {-}
'`

<!--chapter:end:99-references.Rmd-->

