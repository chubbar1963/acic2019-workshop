<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 4 Optimal Individualized Treatment Regimes | The Hitchhiker’s Guide to the tlverse</title>
  <meta name="description" content="An open-source and fully-reproducible electronic handbook accompanying a full-day short-course on applying the targeted learning methodology in practice using the tlverse software ecosystem." />
  <meta name="generator" content="bookdown  and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 4 Optimal Individualized Treatment Regimes | The Hitchhiker’s Guide to the tlverse" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://tlverse.org/acic2019-workshop/" />
  
  <meta property="og:description" content="An open-source and fully-reproducible electronic handbook accompanying a full-day short-course on applying the targeted learning methodology in practice using the tlverse software ecosystem." />
  <meta name="github-repo" content="tlverse/acic2019-workshop" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 4 Optimal Individualized Treatment Regimes | The Hitchhiker’s Guide to the tlverse" />
  
  <meta name="twitter:description" content="An open-source and fully-reproducible electronic handbook accompanying a full-day short-course on applying the targeted learning methodology in practice using the tlverse software ecosystem." />
  

<meta name="author" content="Mark J. van der Laan, Alan E. Hubbard, Jeremy R. Coyle, Nima S. Hejazi, Ivana Malenica, Rachael V. Phillips" />


<meta name="date" content="2019-03-27" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="img/logos/favicons/favicon.png" type="image/x-icon" />
<link rel="prev" href="methods.html">
<link rel="next" href="stochastic-treatment-regimes.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Hitchhiker's Guide to the tlverse</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#about-this-workshop"><i class="fa fa-check"></i>About this workshop</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#motivation"><i class="fa fa-check"></i>Motivation</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#outline"><i class="fa fa-check"></i>Outline</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#about-the-instructors"><i class="fa fa-check"></i>About the instructors</a><ul>
<li class="chapter" data-level="0.0.1" data-path="index.html"><a href="index.html#mark-j.-van-der-laan"><i class="fa fa-check"></i><b>0.0.1</b> Mark J. van der Laan</a></li>
<li class="chapter" data-level="0.0.2" data-path="index.html"><a href="index.html#alan-e.-hubbard"><i class="fa fa-check"></i><b>0.0.2</b> Alan E. Hubbard</a></li>
<li class="chapter" data-level="0.0.3" data-path="index.html"><a href="index.html#jeremy-r.-coyle"><i class="fa fa-check"></i><b>0.0.3</b> Jeremy R. Coyle</a></li>
<li class="chapter" data-level="0.0.4" data-path="index.html"><a href="index.html#nima-s.-hejazi"><i class="fa fa-check"></i><b>0.0.4</b> Nima S. Hejazi</a></li>
<li class="chapter" data-level="0.0.5" data-path="index.html"><a href="index.html#ivana-malenica"><i class="fa fa-check"></i><b>0.0.5</b> Ivana Malenica</a></li>
<li class="chapter" data-level="0.0.6" data-path="index.html"><a href="index.html#rachael-v.-phillips"><i class="fa fa-check"></i><b>0.0.6</b> Rachael V. Phillips</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="literature.html"><a href="literature.html"><i class="fa fa-check"></i><b>2</b> Literature</a></li>
<li class="chapter" data-level="3" data-path="methods.html"><a href="methods.html"><i class="fa fa-check"></i><b>3</b> Methods</a></li>
<li class="chapter" data-level="4" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html"><i class="fa fa-check"></i><b>4</b> Optimal Individualized Treatment Regimes</a><ul>
<li class="chapter" data-level="4.1" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#learning-objectives"><i class="fa fa-check"></i><b>4.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="4.2" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#introduction-to-optimal-individualized-interventions"><i class="fa fa-check"></i><b>4.2</b> Introduction to Optimal Individualized Interventions</a></li>
<li class="chapter" data-level="4.3" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#data-structure-and-notation"><i class="fa fa-check"></i><b>4.3</b> Data Structure and Notation</a></li>
<li class="chapter" data-level="4.4" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#defining-the-causal-effect-of-an-optimal-individualized-intervention"><i class="fa fa-check"></i><b>4.4</b> Defining the Causal Effect of an Optimal Individualized Intervention</a><ul>
<li class="chapter" data-level="4.4.1" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#binary-treatment"><i class="fa fa-check"></i><b>4.4.1</b> Binary treatment</a></li>
<li class="chapter" data-level="4.4.2" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#categorical-treatment"><i class="fa fa-check"></i><b>4.4.2</b> Categorical treatment</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#interpreting-the-causal-effect-of-an-optimal-individualized-intervention"><i class="fa fa-check"></i><b>4.5</b> Interpreting the Causal Effect of an Optimal Individualized Intervention</a></li>
<li class="chapter" data-level="4.6" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#evaluating-the-causal-effect-of-an-optimal-individualized-intervention-with-binary-treatment"><i class="fa fa-check"></i><b>4.6</b> Evaluating the Causal Effect of an Optimal Individualized Intervention with Binary Treatment</a></li>
<li class="chapter" data-level="4.7" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#evaluating-the-causal-effect-of-an-optimal-individualized-intervention-with-categorical-treatment"><i class="fa fa-check"></i><b>4.7</b> Evaluating the Causal Effect of an Optimal Individualized Intervention with Categorical Treatment</a><ul>
<li class="chapter" data-level="4.7.1" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#simulated-data"><i class="fa fa-check"></i><b>4.7.1</b> Simulated Data</a></li>
<li class="chapter" data-level="4.7.2" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#constructing-optimal-stacked-regressions-with-sl3"><i class="fa fa-check"></i><b>4.7.2</b> Constructing Optimal Stacked Regressions with <code>sl3</code></a></li>
<li class="chapter" data-level="4.7.3" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#learning-the-mean-outcome-under-the-optimal-rule-with-q-learning"><i class="fa fa-check"></i><b>4.7.3</b> Learning the Mean Outcome under the Optimal Rule with Q-learning</a></li>
<li class="chapter" data-level="4.7.4" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#targeted-estimation-of-the-mean-under-the-optimal-individualized-interventions-effects"><i class="fa fa-check"></i><b>4.7.4</b> Targeted Estimation of the Mean under the Optimal Individualized Interventions Effects</a></li>
<li class="chapter" data-level="4.7.5" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#extensions-simpler-rules"><i class="fa fa-check"></i><b>4.7.5</b> Extensions: Simpler Rules</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#extensions-variable-importance-analysis-with-optimal-individualized-interventions"><i class="fa fa-check"></i><b>4.8</b> Extensions: Variable Importance Analysis with Optimal Individualized Interventions</a></li>
<li class="chapter" data-level="4.9" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#exercises"><i class="fa fa-check"></i><b>4.9</b> Exercises</a><ul>
<li class="chapter" data-level="4.9.1" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#basicsreview"><i class="fa fa-check"></i><b>4.9.1</b> Basics/Review</a></li>
<li class="chapter" data-level="4.9.2" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#using-the-ideas"><i class="fa fa-check"></i><b>4.9.2</b> Using the Ideas</a></li>
<li class="chapter" data-level="4.9.3" data-path="optimal-individualized-treatment-regimes.html"><a href="optimal-individualized-treatment-regimes.html#advanced"><i class="fa fa-check"></i><b>4.9.3</b> Advanced</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html"><i class="fa fa-check"></i><b>5</b> Stochastic Treatment Regimes</a><ul>
<li class="chapter" data-level="5.1" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#learning-objectives-1"><i class="fa fa-check"></i><b>5.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="5.2" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#introduction-to-stochastic-interventions"><i class="fa fa-check"></i><b>5.2</b> Introduction to Stochastic Interventions</a></li>
<li class="chapter" data-level="5.3" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#background-on-stochastic-interventions"><i class="fa fa-check"></i><b>5.3</b> Background on Stochastic Interventions</a></li>
<li class="chapter" data-level="5.4" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#data-structure-and-notation-1"><i class="fa fa-check"></i><b>5.4</b> Data Structure and Notation</a></li>
<li class="chapter" data-level="5.5" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#defining-the-causal-effect-of-a-stochastic-intervention"><i class="fa fa-check"></i><b>5.5</b> Defining the Causal Effect of a Stochastic Intervention</a></li>
<li class="chapter" data-level="5.6" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#interpreting-the-causal-effect-of-a-stochastic-intervention"><i class="fa fa-check"></i><b>5.6</b> Interpreting the Causal Effect of a Stochastic Intervention</a></li>
<li class="chapter" data-level="5.7" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#evaluating-the-causal-effect-of-a-stochastic-intervention"><i class="fa fa-check"></i><b>5.7</b> Evaluating the Causal Effect of a Stochastic Intervention</a><ul>
<li class="chapter" data-level="5.7.1" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#simulate-data"><i class="fa fa-check"></i><b>5.7.1</b> Simulate Data</a></li>
<li class="chapter" data-level="5.7.2" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#targeted-estimation-of-stochastic-interventions-effects"><i class="fa fa-check"></i><b>5.7.2</b> Targeted Estimation of Stochastic Interventions Effects</a></li>
<li class="chapter" data-level="5.7.3" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#statistical-inference-for-targeted-maximum-likelihood-estimates"><i class="fa fa-check"></i><b>5.7.3</b> Statistical Inference for Targeted Maximum Likelihood Estimates</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#extensions-variable-importance-analysis-with-stochastic-interventions"><i class="fa fa-check"></i><b>5.8</b> Extensions: Variable Importance Analysis with Stochastic Interventions</a><ul>
<li class="chapter" data-level="5.8.1" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#defining-a-grid-of-counterfactual-interventions"><i class="fa fa-check"></i><b>5.8.1</b> Defining a grid of counterfactual interventions</a></li>
<li class="chapter" data-level="5.8.2" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#initializing-vimshift-through-its-tmle3_spec"><i class="fa fa-check"></i><b>5.8.2</b> Initializing <code>vimshift</code> through its <code>tmle3_Spec</code></a></li>
<li class="chapter" data-level="5.8.3" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#targeted-estimation-of-stochastic-interventions-effects-1"><i class="fa fa-check"></i><b>5.8.3</b> Targeted Estimation of Stochastic Interventions Effects</a></li>
<li class="chapter" data-level="5.8.4" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#inference-with-marginal-structural-models"><i class="fa fa-check"></i><b>5.8.4</b> Inference with Marginal Structural Models</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#exercises-1"><i class="fa fa-check"></i><b>5.9</b> Exercises</a><ul>
<li class="chapter" data-level="5.9.1" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#basicsreview-1"><i class="fa fa-check"></i><b>5.9.1</b> Basics/Review</a></li>
<li class="chapter" data-level="5.9.2" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#using-the-ideas-1"><i class="fa fa-check"></i><b>5.9.2</b> Using the Ideas</a></li>
<li class="chapter" data-level="5.9.3" data-path="stochastic-treatment-regimes.html"><a href="stochastic-treatment-regimes.html#advanced-1"><i class="fa fa-check"></i><b>5.9.3</b> Advanced</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">The Hitchhiker’s Guide to the <code>tlverse</code></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="optimal-individualized-treatment-regimes" class="section level1">
<h1><span class="header-section-number">Chapter 4</span> Optimal Individualized Treatment Regimes</h1>
<p><em>Ivana Malenica, Jeremy Coyle, Mark van der Laan</em></p>
<p>Updated: 2019-03-27</p>
<div id="learning-objectives" class="section level2">
<h2><span class="header-section-number">4.1</span> Learning Objectives</h2>
<!--- appears as "X.1: Learning Objectives" in the book, where X is the chapter
corresponding to optimal interventions -->
<ol style="list-style-type: decimal">
<li>…</li>
<li>…</li>
<li>…</li>
<li>…</li>
<li>…</li>
</ol>
</div>
<div id="introduction-to-optimal-individualized-interventions" class="section level2">
<h2><span class="header-section-number">4.2</span> Introduction to Optimal Individualized Interventions</h2>
<p>The aim of precision medicine is to allow for patient specific interventions.
In the case of categorical treatment, one opts to administer the intervention to
individuals who will benefit from it, instead of assigning treatment on a population level.
For example, Abacavir and Tenofovir are commonly prescribed as part of the antiretroviral therapy to Human Immunodeficiency Virus (HIV) patients. However, not all individuals benefit from the two medications
equally. In particular, patients with renal dysfunction might further deteriorate if
prescribed Tenofovir, due to the high nephrotoxicity caused by the medication.
While Tenofovir is still highly effective treatment option for HIV patients, in order to maximize the
patient’s well-being, it would be benefitial to prescribe Tenofovir only to individuals
with healthy kindey function.</p>
<p>This motivates a diffent type of interention, as opposed to the static exposures we
might be used to. In particular, in this chapter we learn about dynamic or individualized
interventions that tailor the treatment decision based on the collected covariates.
In the statistics community such a treatment strategy is termed
</p>
<p>The problem of estimating the optimal individualized treatment has received much attention
in the statistics literature over the years, especially with the advancement of
precision medicine; see <span class="citation">Murphy (<a href="#ref-murphy2003">2003</a>)</span>, <span class="citation">(“Temporary,” <a href="#ref-robins2004">n.d.</a>)</span>, <span class="citation">(“Temporary,” <a href="#ref-moodie2013">n.d.</a>)</span> and <span class="citation">(“Temporary,” <a href="#ref-robins2014">n.d.</a>)</span> to name a few.
However, much of the early work depends on parametric assumptions. As such, even in a randomized trial,
the statistical inference for the optimal individualized treatment relies on assumptions that
are generally believed to be false, and can lead to biased results.</p>
<p>In this chapter, we consider estimation of the mean outcome under the optimal individualized treatment
where the candidate rules are restricted to depend only on user-supplied subset of the baseline covariates.
The estimation problem is addressed in a statistical model for the data distribution that is nonparametric,
and at most places restrictions on the probability of a patient receiving treatment given covariates (as in a
randomized trial). As
such, we don’t need to make any assumptions about the relationship of the outcome with the treatment and
covariates, or the relationship between the treatment and covariates. For a technical presentation of
the algorithm, the interested reader is invited to further consult <span class="citation">van der Laan and Luedtke (<a href="#ref-vanderLaanLuedtke15">2015</a>)</span> and <span class="citation">Luedtke and van der Laan (<a href="#ref-luedtke2016super">2016</a>)</span>.
For additional background on Targeted Learning, please consider consulting <span class="citation">van der Laan and Rose (<a href="#ref-vdl2011targeted">2011</a>)</span> and
<span class="citation">van der Laan and Rose (<a href="#ref-vdl2018targeted">2018</a>)</span>.</p>
<hr />
</div>
<div id="data-structure-and-notation" class="section level2">
<h2><span class="header-section-number">4.3</span> Data Structure and Notation</h2>
<p>Suppose we observe <span class="math inline">\(n\)</span> independent and identically distributed observations of the form <span class="math inline">\(O=(W,A,Y) \sim P_0\)</span>. We denote <span class="math inline">\(A\)</span> as categorical treatment, and <span class="math inline">\(Y\)</span> as the final outcome. Note that we treat <span class="math inline">\(W\)</span> as vector-valued, representing all of our collected baseline covariates. Therefore, for a single random individual <span class="math inline">\(i\)</span>, we have that their observed data is <span class="math inline">\(O_i\)</span>: with corresponding baseline covariates <span class="math inline">\(W_i\)</span>, treatment <span class="math inline">\(A_i\)</span>, and final outcome <span class="math inline">\(Y_i\)</span>. We say that <span class="math inline">\(O \sim P_0\)</span>, or that all data was drawn from some probability distribution <span class="math inline">\(P_0\)</span>. We emphasize that we make no assumptions about the distribution of <span class="math inline">\(P_0\)</span>, so that <span class="math inline">\(P_0 \in \mathcal{M}\)</span>, where <span class="math inline">\(\mathcal{M}\)</span> is the fully nonparametric model. We can break the data generating distribution <span class="math inline">\(P_0\)</span> into the following parts by time ordering:</p>
<p><span class="math display">\[P_0(O) = P_0(Y|A,W)P_0(A|W)P_0(W) = Q_{Y,0}(Y|A,W)g_0(A|W)Q_{W,0}(W)\]</span>
where <span class="math inline">\(P_0(Y|A,W)=Q_{Y,0}(Y|A,W)\)</span>, <span class="math inline">\(P_0(A|W)=g_0(A|W)\)</span> and <span class="math inline">\(P_0(W)=Q_{W,0}(W)\)</span>. For notational simplicity, we also define <span class="math inline">\(\bar{Q}_{Y,0}(A,W) \equiv E_0[Y|A,W]\)</span>.</p>
</div>
<div id="defining-the-causal-effect-of-an-optimal-individualized-intervention" class="section level2">
<h2><span class="header-section-number">4.4</span> Defining the Causal Effect of an Optimal Individualized Intervention</h2>
<p>Many methods for learning an optimal rule from data have been developed. Here, we focus on the methods developed in <span class="citation">Luedtke and van der Laan (<a href="#ref-luedtke2016super">2016</a>)</span> and <span class="citation">van der Laan and Luedtke (<a href="#ref-vanderLaanLuedtke15">2015</a>)</span>; however <code>tmle3mopttx</code> also supports the widely used Q-learning approach, based on generating an estimate of <span class="math inline">\(\bar{Q}_{Y,0}(A,W)\)</span> <span class="citation">Sutton, Barto, and others (<a href="#ref-Sutton1998">1998</a>)</span>. We cover how to use the Q-learning approach in the later implementation of the vignette.
However, we focus on the methodology outlined in <span class="citation">Luedtke and van der Laan (<a href="#ref-luedtke2016super">2016</a>)</span> and <span class="citation">van der Laan and Luedtke (<a href="#ref-vanderLaanLuedtke15">2015</a>)</span>, where we learn the optimal ITR using Super Learner <span class="citation">van der Laan, Polley, and Hubbard (<a href="#ref-vdl2007super">2007</a>)</span>, and estimate its value using the cross-validated Targeted Minimum Loss-based Estimation (CV-TMLE) <span class="citation">Zheng and van der Laan (<a href="#ref-cvtmle2010">2010</a>)</span>. Luedtke and van der Laan present three different appraches for learning the optimal rule, but <code>tmle3mopttx</code> relies on using the Super Learner to estimate the blip function (or “pseudo-blip” for categorical treatment).
In great generality, we first need to estimate an individual treatment regime which corresponds to dynamic treatment rule (<span class="math inline">\(d(V)\)</span>) that takes a subset of covariates <span class="math inline">\(V \in W\)</span> and assigns treatment. As specified in the introduction, we are also interested in the value of such a dynamic rule: <span class="math display">\[E_0[Y_{d(V)}] = E_{0,W}[\bar{Q}_{Y,0}(A=d(V),W)]\]</span> which, under causal assumptions, can be interpreted as the mean outcome if (possibly contrary to fact), treatment was assigned according to the rule. The optimal rule is the rule with the maximal value: <span class="math display">\[d_0 \equiv \text{argmax}_{d \in \mathcal{D}} E_0[Y_{d(V)}] \]</span>
where <span class="math inline">\(\mathcal{D}\)</span> represents the set of possible rules, <span class="math inline">\(d\)</span>. We note that minimization is completely ok as well, depending on the problem in hand.</p>
<div id="binary-treatment" class="section level3">
<h3><span class="header-section-number">4.4.1</span> Binary treatment</h3>
<p>In the case of a binary treatment, a key quantity for optimal ITR is the blip function. In particular, one can show that any optimal ITR assigns treatment to individuals falling in strata in which the stratum specific average treatment effect, the blip function, is positive and does not assign treatment to individuals for which this quantity is negative. Therefore for a binary treatment, we define a blip function as <span class="math display">\[E_0[Y_1-Y_0|V] \equiv E_0[\bar{Q}_{Y,0}(1,W) - \bar{Q}_{Y,0}(0,W) | V] \]</span>
The note that the rule can now be derived as <span class="math inline">\(d_0(V) = I(\bar{Q}_0(V) &gt; 0)\)</span>.</p>
<p>In particular, we will:</p>
<ol style="list-style-type: decimal">
<li><p>Estimate <span class="math inline">\(\bar{Q}_{Y,0}(A,W)\)</span> and <span class="math inline">\(g_0(A|W)\)</span> using <code>sl3</code>.</p></li>
<li><p>Apply the doubly robust A-IPW transform to our outcome, where we define:</p></li>
</ol>
<p><span class="math display">\[D_{\bar{Q},g,a}(O) \equiv \frac{I(A=a)}{g(A|W)} (Y-\bar{Q}_Y(A,W)) + \bar{Q}_Y(A=a,W),\]</span>
Using this transform, we can define the following contrast:
<span class="math inline">\(D_{\bar{Q},g}(O) = D_{\bar{Q},g,a=1}(O) - D_{\bar{Q},g,a=0}(O)\)</span></p>
<p>We estimate the blip function ({Q}_{0,a}(V)) by regressing <span class="math inline">\(D_{\bar{Q},g}(O)\)</span> on <span class="math inline">\(V\)</span> using <code>sl3</code>.</p>
<ol start="3" style="list-style-type: decimal">
<li><p>Our estimated rule is <span class="math inline">\(d(V) = \text{argmax}_{a \in \mathcal{A}} \bar{Q}_{0,a}(V)\)</span>.</p></li>
<li><p>Obtain inference for the mean outcome under the optimal rule using CV-TMLE.</p></li>
</ol>
</div>
<div id="categorical-treatment" class="section level3">
<h3><span class="header-section-number">4.4.2</span> Categorical treatment</h3>
<p>In line with the approach considered for binary treatment, we extend the blip function apprach to allow for categorical treatment by estimating “pseudo-blips”. We define pseudo-blips as vector valued entities where the output for a given <span class="math inline">\(V\)</span> is a vector of length equal to the number of treatment categories. As such, we define it as:
<span class="math display">\[\bar{Q}_0^{pblip}(V) = \{\bar{Q}_{0,a}^{pblip}(V): a \in \mathcal{A} \}\]</span></p>
<p>We implement three different pseudo-blips in <code>tmle3mopttx</code>.</p>
<ol style="list-style-type: decimal">
<li><p>“Blip1” corresponds to choosing a reference category of treatment, and defining the blip for all other categories relative to the specified reference. Hence we have that: <span class="math display">\[\bar{Q}_{0,a}^{pblip-ref}(V) \equiv E_0(Y_a-Y-0|V)\]</span> where <span class="math inline">\(Y_0\)</span> is the specified reference category. Note that, for the case of binary treatment, this strategy reduces to the apparoach described in the previous section.</p></li>
<li>“Blip2” approach corresponds to defining the blip relative to the average of all categories. As such, we can define <span class="math inline">\(\bar{Q}_{0,a}^{pblip-avg}(V)\)</span> as:
<span class="math display">\[\bar{Q}_{0,a}^{pblip-avg}(V) \equiv E_0(Y_a- \frac{1}{n_A} \sum_{a^{&#39;} \in \mathcal{A}} Y_{a^{&#39;}}|V)\]</span></li>
<li><p>“Blip3” reflects an extension of “Blip2”, where the average is now a weighted average.
<span class="math display">\[\bar{Q}_{0,a}^{pblip-wavg}(V) \equiv E_0(Y_a- \frac{1}{n_A} \sum_{a^{&#39;} \in \mathcal{A}} P(A=a^{&#39;}|V)
Y_{a^{&#39;}}|V)\]</span></p></li>
</ol>
<p>Just like in the binary case, pseudo-blips are estimated by regressing contrasts composed using the A-IPW transform on <span class="math inline">\(V\)</span>.</p>
</div>
</div>
<div id="interpreting-the-causal-effect-of-an-optimal-individualized-intervention" class="section level2">
<h2><span class="header-section-number">4.5</span> Interpreting the Causal Effect of an Optimal Individualized Intervention</h2>
<p>TODO</p>
</div>
<div id="evaluating-the-causal-effect-of-an-optimal-individualized-intervention-with-binary-treatment" class="section level2">
<h2><span class="header-section-number">4.6</span> Evaluating the Causal Effect of an Optimal Individualized Intervention with Binary Treatment</h2>
<p>TODO</p>
</div>
<div id="evaluating-the-causal-effect-of-an-optimal-individualized-intervention-with-categorical-treatment" class="section level2">
<h2><span class="header-section-number">4.7</span> Evaluating the Causal Effect of an Optimal Individualized Intervention with Categorical Treatment</h2>
<p>To start, let’s load the packages we’ll use and set a seed for simulation:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(data.table)
<span class="kw">library</span>(sl3)
<span class="kw">library</span>(tmle3)
<span class="kw">library</span>(tmle3mopttx)
<span class="kw">library</span>(devtools)
<span class="kw">set.seed</span>(<span class="dv">111</span>)</code></pre>
<div id="simulated-data" class="section level3">
<h3><span class="header-section-number">4.7.1</span> Simulated Data</h3>
<p>First, we load the simulated data. Here, our data generating distribution is of the following form:</p>
<p><span class="math display">\[W \sim \mathcal{N}(\bf{0},I_{4 \times 4})\]</span>
<span class="math display">\[P(A=a|W) = \frac{1}{1+\exp^{(-0.8*W_a)}}\]</span></p>
<p><span class="math display">\[P(Y=1|A,W) = 0.5\text{logit}^{-1}[3I(A=1)(W_1-0.5) - 3I(A=2)(2W_2+0.5) + 3I(A=3)(3W_3-0.5)] +\text{logit}^{-1}(W_2W_3)\]</span></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(<span class="st">&quot;data_cat&quot;</span>)</code></pre>
<p>The above composes our observed data structure <span class="math inline">\(O = (W, A, Y)\)</span>. Note that the
mean under the true optimal rule is <span class="math inline">\(\psi=0.625\)</span>.</p>
<p>To formally express this fact using the <code>tlverse</code> grammar introduced by the <code>tmle3</code> package,
we create a single data object and specify the functional relationships between
the nodes in the <em>directed acyclic graph</em> (DAG) via <em>nonparametric structural
equation models</em> (NPSEMs), reflected in the node list that we set up:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># organize data and nodes for tmle3</span>
data &lt;-<span class="st"> </span>data_cat
node_list &lt;-<span class="st"> </span><span class="kw">list</span>(
  <span class="dt">W =</span> <span class="kw">c</span>(<span class="st">&quot;W1&quot;</span>, <span class="st">&quot;W2&quot;</span>, <span class="st">&quot;W3&quot;</span>, <span class="st">&quot;W4&quot;</span>),
  <span class="dt">A =</span> <span class="st">&quot;A&quot;</span>,
  <span class="dt">Y =</span> <span class="st">&quot;Y&quot;</span>
)</code></pre>
<p>We now have an observed data structure (<code>data</code>) and a specification of the role
that each variable in the data set plays as the nodes in a DAG.</p>
</div>
<div id="constructing-optimal-stacked-regressions-with-sl3" class="section level3">
<h3><span class="header-section-number">4.7.2</span> Constructing Optimal Stacked Regressions with <code>sl3</code></h3>
<p>To easily incorporate ensemble machine learning into the estimation procedure,
we rely on the facilities provided in the <a href="https://sl3.tlverse.org"><code>sl3</code> R
package</a>. For a complete guide on using the <code>sl3</code> R
package, consider consulting <a href="https://sl3.tlverse.org" class="uri">https://sl3.tlverse.org</a>, or <a href="https://tlverse.org" class="uri">https://tlverse.org</a> for
the <a href="https://github.com/tlverse"><code>tlverse</code> ecosystem</a>, of which <code>sl3</code> is a major
part.</p>
<p>Using the framework provided by the <a href="https://sl3.tlverse.org"><code>sl3</code> package</a>,
the nuisance parameters of the TML estimator may be fit with ensemble learning,
using the cross-validation framework of the Super Learner algorithm of
<span class="citation">van der Laan, Polley, and Hubbard (<a href="#ref-vdl2007super">2007</a>)</span>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Initialize some of the learners.</span>
<span class="co">#Here we use xgboost with various parameters, glm, HAL and the simle mean.</span>
xgboost_<span class="dv">50</span>&lt;-Lrnr_xgboost<span class="op">$</span><span class="kw">new</span>(<span class="dt">nrounds =</span> <span class="dv">50</span>)
xgboost_<span class="dv">100</span>&lt;-Lrnr_xgboost<span class="op">$</span><span class="kw">new</span>(<span class="dt">nrounds =</span> <span class="dv">100</span>)
xgboost_<span class="dv">500</span>&lt;-Lrnr_xgboost<span class="op">$</span><span class="kw">new</span>(<span class="dt">nrounds =</span> <span class="dv">500</span>)
lrn1 &lt;-<span class="st"> </span>Lrnr_mean<span class="op">$</span><span class="kw">new</span>()
lrn2&lt;-Lrnr_glm_fast<span class="op">$</span><span class="kw">new</span>()
lrn3&lt;-Lrnr_hal9001<span class="op">$</span><span class="kw">new</span>()

<span class="co">#Define the Q learner, which is just a regular learner:</span>
Q_learner &lt;-<span class="st"> </span>Lrnr_sl<span class="op">$</span><span class="kw">new</span>(
  <span class="dt">learners =</span> <span class="kw">list</span>(xgboost_<span class="dv">50</span>,xgboost_<span class="dv">100</span>,xgboost_<span class="dv">500</span>,lrn1,lrn2),
  <span class="dt">metalearner =</span> Lrnr_nnls<span class="op">$</span><span class="kw">new</span>()
)

<span class="co">#Define the g learner, which is a multinomial learner:</span>
glib &lt;-<span class="st"> </span><span class="kw">list</span>(
  rf &lt;-<span class="st"> </span><span class="kw">make_learner</span>(Lrnr_randomForest),
  xgb &lt;-<span class="st"> </span><span class="kw">make_learner</span>(Lrnr_xgboost),
  glmnet &lt;-<span class="st"> </span><span class="kw">make_learner</span>(Lrnr_glmnet),
  multinom_gf &lt;-<span class="st"> </span><span class="kw">make_learner</span>(Lrnr_independent_binomial, <span class="kw">make_learner</span>(Lrnr_glm_fast)),
  mean &lt;-<span class="st"> </span><span class="kw">make_learner</span>(Lrnr_mean)
)

mn_metalearner &lt;-<span class="st"> </span><span class="kw">make_learner</span>(Lrnr_solnp, <span class="dt">loss_function =</span> loss_loglik_multinomial, 
                               <span class="dt">learner_function =</span> metalearner_linear_multinomial)
g_learner &lt;-<span class="st"> </span><span class="kw">make_learner</span>(Lrnr_sl, glib, mn_metalearner)

<span class="co">#Define the Blip learner, which is a multivariate learner:</span>
learners &lt;-<span class="st"> </span><span class="kw">list</span>(xgboost_<span class="dv">50</span>,xgboost_<span class="dv">100</span>,xgboost_<span class="dv">500</span>,lrn1,lrn2)
b_learner &lt;-<span class="st"> </span><span class="kw">create_mv_learners</span>(<span class="dt">learners =</span> learners)</code></pre>
<p>As seen above, we generate three different ensemble learners that must be fit, corresponding to the learners for the outcome regression, propensity score, and the blip function. Note that we need to estimate <span class="math inline">\(g_0(A|W)\)</span> for a categorical <span class="math inline">\(A\)</span>- therefore we use the multinomial Super Learner option available within the <code>sl3</code> package with learners that can address multi-class classification problems. In order to see which learners can be used to estimate <span class="math inline">\(g_0(A|W)\)</span> in <code>sl3</code>, we run the following:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">#See which learners support multi-class classification:</span>
<span class="kw">sl3_list_learners</span>(<span class="kw">c</span>(<span class="st">&quot;categorical&quot;</span>))</code></pre>
<pre><code> [1] &quot;Lrnr_bartMachine&quot;          &quot;Lrnr_dbarts&quot;              
 [3] &quot;Lrnr_glmnet&quot;               &quot;Lrnr_grf&quot;                 
 [5] &quot;Lrnr_h2o_glm&quot;              &quot;Lrnr_h2o_grid&quot;            
 [7] &quot;Lrnr_independent_binomial&quot; &quot;Lrnr_mean&quot;                
 [9] &quot;Lrnr_multivariate&quot;         &quot;Lrnr_optim&quot;               
[11] &quot;Lrnr_randomForest&quot;         &quot;Lrnr_ranger&quot;              
[13] &quot;Lrnr_rpart&quot;                &quot;Lrnr_solnp&quot;               
[15] &quot;Lrnr_svm&quot;                  &quot;Lrnr_xgboost&quot;             </code></pre>
<p>Also note that since the corresponding blip will be vector valued, with a column for each additional level of treatment. As such, we need to initialize a multivariate learners with the the helper function <code>create_mv_learners</code> that takes a list of initialized learners as input.</p>
<p>We make the above explicit with respect to standard notation by bundling the
ensemble learners into a list object below:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># specify outcome and treatment regressions and create learner list</span>
learner_list &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">Y =</span> Q_learner, <span class="dt">A =</span> g_learner, <span class="dt">B =</span> b_learner)</code></pre>
<p>The <code>learner_list</code> object above specifies the role that each of the ensemble
learners we’ve generated is to play in computing initial estimators to be used
in building a TMLE for the parameter of interest. In particular, it makes
explicit the fact that our <code>Y</code> is used in fitting the outcome regression
while our <code>A</code> is used in fitting our treatment mechanism regression, and finally <code>B</code> is used in fitting the blip function.</p>
</div>
<div id="learning-the-mean-outcome-under-the-optimal-rule-with-q-learning" class="section level3">
<h3><span class="header-section-number">4.7.3</span> Learning the Mean Outcome under the Optimal Rule with Q-learning</h3>
<p>Here we outline how to use <code>tmle3mopttx</code> package in order to estimate the mean under the ITR using Q-learning. As demonstrated in the previous sections, we first need to initialize a specification for the TMLE of our parameter of interest. As opposed to the previous section however, we will now use <code>tmle3_mopttx_Q</code> instead of <code>tmle3_mopttx_blip_revere</code> in order to indicate that we want to use Q-learning instead of TMLE.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># initialize a tmle specification</span>
tmle_spec_Q &lt;-<span class="st"> </span><span class="kw">tmle3_mopttx_Q</span>(<span class="dt">maximize =</span> <span class="ot">TRUE</span>)

<span class="co"># Define data:</span>
tmle_task &lt;-<span class="st"> </span>tmle_spec_Q<span class="op">$</span><span class="kw">make_tmle_task</span>(data, node_list)

<span class="co"># Define likelihood:</span>
initial_likelihood &lt;-<span class="st"> </span>tmle_spec_Q<span class="op">$</span><span class="kw">make_initial_likelihood</span>(tmle_task, learner_list)

<span class="co">#Estimate the parameter:</span>
<span class="kw">Q_learning</span>(tmle_spec_Q, initial_likelihood, tmle_task)</code></pre>
<pre><code>[1] 0.4567778</code></pre>
</div>
<div id="targeted-estimation-of-the-mean-under-the-optimal-individualized-interventions-effects" class="section level3">
<h3><span class="header-section-number">4.7.4</span> Targeted Estimation of the Mean under the Optimal Individualized Interventions Effects</h3>
<p>To start, we will initialize a specification for the TMLE of our parameter of
interest (called a <code>tmle3_Spec</code> in the <code>tlverse</code> nomenclature) simply by calling
<code>tmle3_mopttx_blip_revere</code>. We specify the argument <code>V = c(&quot;W1&quot;, &quot;W2&quot;, &quot;W3&quot;, &quot;W4&quot;)</code>
when initializing the <code>tmle3_Spec</code> object in order to communicate that we’re interested
in learning a rule dependent on <code>V</code> covariates. We also need to specify the type of
pseudo-blip we will use in this estimation problem, and finally the list of learners
used to estimate the blip function.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># initialize a tmle specification</span>
tmle_spec &lt;-<span class="st"> </span><span class="kw">tmle3_mopttx_blip_revere</span>(<span class="dt">V =</span> <span class="kw">c</span>(<span class="st">&quot;W1&quot;</span>, <span class="st">&quot;W2&quot;</span>, <span class="st">&quot;W3&quot;</span>, <span class="st">&quot;W4&quot;</span>), <span class="dt">type =</span> <span class="st">&quot;blip2&quot;</span>, <span class="dt">b_learner =</span> learner_list<span class="op">$</span>B, <span class="dt">maximize =</span> <span class="ot">TRUE</span>, <span class="dt">complex =</span> <span class="ot">TRUE</span>)</code></pre>
<p>As seen above, the <code>tmle3_mopttx_blip_revere</code> specification object (like all <code>tmle3_Spec</code>
objects) does <em>not</em> store the data for our specific analysis of interest. Later,
we’ll see that passing a data object directly to the <code>tmle3</code> wrapper function,
alongside the instantiated <code>tmle_spec</code>, will serve to construct a <code>tmle3_Task</code>
object internally (see the <code>tmle3</code> documentation for details).</p>
<p>In initializing the specification for the TMLE of our parameter of
interest, we have specified the set of covariates the rule depends on (<span class="math inline">\(V\)</span>), the type of pseudo-blip to use (“type”), and the learners used for estimating the pseudo-blip. In addition, we need to specify whether we want to maximize the mean outcome under the rule (“maximize=TRUE”), and whether we want to estimate the rule under all the covariates <span class="math inline">\(V\)</span> provided by the user. If FALSE, <code>tmle3mopttx</code> will instead consider all the possible rules under a smaller set of covariates including the static rules, and optimize the mean outcome over all the subsets of <span class="math inline">\(V\)</span>. As such, while the user might have provided a full set of collected covariates as input for <span class="math inline">\(V\)</span>, it is possible that the true rule only depends on a subset of the set provided by the user. In that case, our returned mean under the optimal individualized rule will be based on the smaller subset.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># fit the TML estimator</span>
fit &lt;-<span class="st"> </span><span class="kw">tmle3</span>(tmle_spec, data, node_list, learner_list)
fit</code></pre>
<pre><code>A tmle3_Fit that took 1 step(s)
   type         param  init_est  tmle_est         se     lower     upper
1:  TSM E[Y_{A=NULL}] 0.4945732 0.5915877 0.02468566 0.5432047 0.6399708
   psi_transformed lower_transformed upper_transformed
1:       0.5915877         0.5432047         0.6399708</code></pre>
</div>
<div id="extensions-simpler-rules" class="section level3">
<h3><span class="header-section-number">4.7.5</span> Extensions: Simpler Rules</h3>
</div>
</div>
<div id="extensions-variable-importance-analysis-with-optimal-individualized-interventions" class="section level2">
<h2><span class="header-section-number">4.8</span> Extensions: Variable Importance Analysis with Optimal Individualized Interventions</h2>
<hr />
</div>
<div id="exercises" class="section level2">
<h2><span class="header-section-number">4.9</span> Exercises</h2>
<div id="basicsreview" class="section level3">
<h3><span class="header-section-number">4.9.1</span> Basics/Review</h3>
</div>
<div id="using-the-ideas" class="section level3">
<h3><span class="header-section-number">4.9.2</span> Using the Ideas</h3>
</div>
<div id="advanced" class="section level3">
<h3><span class="header-section-number">4.9.3</span> Advanced</h3>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-luedtke2016super">
<p>Luedtke, A., and M. J van der Laan. 2016. “Super-Learning of an Optimal Dynamic Treatment Rule.” <em>International Journal of Biostatistics</em> 12 (1): 305–32.</p>
</div>
<div id="ref-murphy2003">
<p>Murphy, Susan A. 2003. “Optimal Dynamic Treatment Regimes.” <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em> 65 (2). Wiley Online Library: 331–55.</p>
</div>
<div id="ref-Sutton1998">
<p>Sutton, Richard S, Andrew G Barto, and others. 1998. <em>Introduction to Reinforcement Learning</em>. Vol. 135. MIT press Cambridge.</p>
</div>
<div id="ref-robins2004">
<p>“Temporary.” n.d.</p>
</div>
<div id="ref-moodie2013">
<p>“Temporary.” n.d.</p>
</div>
<div id="ref-robins2014">
<p>“Temporary.” n.d.</p>
</div>
<div id="ref-vdl2007super">
<p>van der Laan, Mark J, Eric C Polley, and Alan E Hubbard. 2007. “Super Learner.” <em>Statistical Applications in Genetics and Molecular Biology</em> 6 (1).</p>
</div>
<div id="ref-vdl2011targeted">
<p>van der Laan, Mark J, and Sherri Rose. 2011. <em>Targeted Learning: Causal Inference for Observational and Experimental Data</em>. Springer Science &amp; Business Media.</p>
</div>
<div id="ref-vdl2018targeted">
<p>van der Laan, Mark J, and Sherri Rose. 2018. <em>Targeted Learning in Data Science: Causal Inference for Complex Longitudinal Studies</em>. Springer Science &amp; Business Media.</p>
</div>
<div id="ref-vanderLaanLuedtke15">
<p>van der Laan, M. J, and A. Luedtke. 2015. “Targeted Learning of the Mean Outcome Under an Optimal Dynamic Treatment Rule.” <em>Journal of Causal Inference</em> 3 (1): 61–95.</p>
</div>
<div id="ref-cvtmle2010">
<p>Zheng, W., and M. J van der Laan. 2010. “Asymptotic Theory for Cross-validated Targeted Maximum Likelihood Estimation.” <em>U.C. Berkeley Division of Biostatistics Working Paper Series.</em></p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="methods.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="stochastic-treatment-regimes.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/tlverse/acic2019-workshop/edit/master/04-tmle3mopttx.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["handbook.pdf", "handbook.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
