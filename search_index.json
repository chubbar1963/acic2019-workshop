[
["index.html", "The Hitchhiker’s Guide to the tlverse or a Targeted Learning Practitioner’s Handbook Preface About this workshop Motivation Outline About the instructors 0.1 Preface", " The Hitchhiker’s Guide to the tlverse or a Targeted Learning Practitioner’s Handbook Mark van der Laan, Alan Hubbard, Jeremy Coyle, Nima Hejazi, Ivana Malenica, Rachael Phillips ACIC 2019 edition; updated: April 01, 2019 Preface This is an open source and fully-reproducible electronic handbook accompanying a full-day short-course on applying the targeted learning methodology in practice using the tlverse software ecosystem, given at the 2019 Atlantic Causal Inference Conference in Montréal, Québec, Canada on 22 May 2019. About this workshop This full-day workshop will provide a comprehensive introduction to both the tlverse software ecosystem and the field of targeted learning for causal inference. While this will primarily be a software workshop centered around the new tlverse ecosystem of R packages, there will be rigorous examination of both causal inference methodology – focusing on the field of targeted learning – and applications in both large-scale observational studies and randomized experiments. The focus will be on introducing modern methodological developments in statistical causal inference and their corresponding software implementations in the tlverse. Through vignette-guided live coding exercises, participants will perform hands-on implementation of novel estimators for assessing causal claims with complex, observational data. Topics to be addressed include ensemble machine learning; efficient substitution estimators in nonparametric and semiparametric models and targeted minimum loss-based estimation (TMLE); inference based on influence functions; static, dynamic, optimal dynamic, and stochastic interventions. TMLE provides a strategy for constructing (double) robust efficient plug-in estimators with normal limiting distributions, allowing for valid inference even when the functional nuisance parameters are estimated via machine learning. Causal parameters and corresponding estimators will be examined both mathematically and through their corresponding R package implementations from the tlverse ecosystem via hands-on data analysis, providing participants opportunities to develop skills that will translate to real-world causal inference analyses. Some background in mathematical statistics will be useful; familiarity with the R programming language will be essential. Motivation Randomized clinical trials (RCTs) have long served as the gold standard of evidence for comparing potential interventions in clinical medicine and public health, marketing, political science, and a great many other fields. Unfortunately, such trials are often not feasible due to ethical, logistic or economical constraints. Observational studies constitute a potentially rich alternative to RCTs, providing an opportunity to learn about the causal effects of interventions for which little or no trial data can be produced; however, in such studies intervention allocation may be strongly confounded by other important characteristics. Thus, great care is needed in attempts to disentangle observed relationships and, ultimately, infer causal effects. This workshop will provide a comprehensive introduction to the field of targeted learning, a modern statistical framework that utilizes state-of-the-art machine learning to flexibly adjust for confounding while yielding efficient, unbiased estimators and valid statistical inference, thus unlocking observational studies for causal inference. Targeted learning is a complex statistical approach and, in order for this method to be accessible in practice, it is crucial that it is accompanied by robust software. The tlverse software ecosystem was developed to fulfill this need. Not only does this software facilitate computationally reproducible and efficient analyses, but it is also a tool for targeted learning education since its workflow mirrors that of the methodology. That is, the tlverse paradigm does not focus on implementing a specific estimator or a small set of related estimators – instead, the focus is on exposing the statistical framework of targeted learning itself! Thus, users are required to explicitly define objects to model key statistical objects: the nonparametric structural equation model, the factorized likelihood, counterfactual interventions, causal parameters, and algorithmic step for computing estimators. All R packages in the tlverse ecosystem directly model the key objects defined in the mathematical and theoretical framework of targeted learning. What’s more, the tlverse R packages share a core set of design principles centered on extensibility, allowing for them to be used in conjunction with each other and built upon one other in a cohesive fashion. Outline This is a full-day (6-hour) workshop, featuring modules that introduce distinct causal questions, each motivated by a case study, alongside statistical methodology and software for assessing the causal claim of interest. A sample schedule may take the form: 09:30AM–09:45AM: Why we need a statistical revolution 09:45AM–10:15AM: The Roadmap, and the WASH Benefits data 10:15AM–10:30AM: Introduction to the tlverse software ecosystem 10:30AM–10:45AM: Morning break 10:45AM–11:45AM: Ensemble machine learning with the sl3 package 11:45AM–12:30PM: Targeted learning for causal inference with the tmle3 package 12:30PM–1:30PM: Lunch break 01:30PM–02:45PM: Optimal treatment regimes and the tmle3mopttx package 02:45PM–03:00PM: Afternoon break 3:00PM–4:00PM: Stochastic treatment regimes and the tmle3shift package 04:00PM–4:30PM: Coda: Why we need a statistical revolution About the instructors Mark van der Laan Mark van der Laan, Ph.D., is Professor of Biostatistics and Statistics at UC Berkeley. His research interests include statistical methods in computational biology, survival analysis, censored data, adaptive designs, targeted maximum likelihood estimation, causal inference, data-adaptive loss-based learning, and multiple testing. His research group developed loss-based super learning in semiparametric models, based on cross-validation, as a generic optimal tool for the estimation of infinite-dimensional parameters, such as nonparametric density estimation and prediction with both censored and uncensored data. Building on this work, his research group developed targeted maximum likelihood estimation for a target parameter of the data-generating distribution in arbitrary semiparametric and nonparametric models, as a generic optimal methodology for statistical and causal inference. Most recently, Mark’s group has focused in part on the development of a centralized, principled set of software tools for targeted learning, the tlverse. For more information, see https://vanderlaan-lab.org. Alan Hubbard Alan Hubbard, Ph.D., is Professor of Biostatistics, former head of the Division of Biostatistics at UC Berkeley, and head of data analytics core at UC Berkeley’s SuperFund research program. His current research interests include causal inference, variable importance analysis, statistical machine learning, estimation of and inference for data-adaptive statistical target parameters, and targeted minimum loss-based estimation. Research in his group is generally motivated by applications to problems in computational biology, epidemiology, and precision medicine. Jeremy Coyle Jeremy Coyle, Ph.D., is a consulting data scientist and statistical programmer, currently leading the software development effort that has produced the tlverse ecosystem of R packages and related software tools. Jeremy earned his Ph.D. in Biostatistics from UC Berkeley in 2016, primarily under the supervision of Alan Hubbard. Nima Hejazi Nima is a Ph.D. candidate in biostatistics with a designated emphasis in computational and genomic biology, working jointly with Mark van der Laan and Alan Hubbard. Nima is affiliated with UC Berkeley’s Center for Computational Biology and NIH Biomedical Big Data training program. His research interests span causal inference, nonparametric inference and machine learning, targeted loss-based estimation, survival analysis, statistical computing, reproducible research, and high-dimensional biology. He is also passionate about software development for applied statistics, including software design, automated testing, and reproducible coding practices. For more information, see https://nimahejazi.org. Ivana Malenica Ivana is a Ph.D. student in biostatistics advised by Mark van der Laan. Ivana is currently a fellow at the Berkeley Institute for Data Science, after serving as a NIH Biomedical Big Data and Freeport-McMoRan Genomic Engine fellow. She earned her Master’s in Biostatistics and Bachelor’s in Mathematics, and spent some time at the Translational Genomics Research Institute. Very broadly, her research interests span non/semi-parametric theory, probability theory, machine learning, causal inference and high-dimensional statistics. Most of her current work involves complex dependent settings (dependence through time and network) and adaptive sequential designs. Rachael Phillips Rachael is a Ph.D. student in biostatistics, advised by Alan Hubbard and Mark van der Laan. She has an M.A. in Biostatistics, B.S. in Biology with a Chemistry minor and a B.A. in Mathematics with a Spanish minor. Rachael is motivated to solve real-world, high-dimensional problems in human health. Her research interests span causal inference, machine learning, nonparametric statistical estimation, and finite sample inference. She is also passionate about online mediated education. Rachael is affiliated with UC Berkeley’s Center for Computational Biology, NIH Biomedical Big Data Training Program, and Superfund Research Program. 0.1 Preface The foundation of this handbook is grounded in the statistical approach and philosophy, “Targeted Learning”, developed by Principal Investigator, Professor Mark van der Laan, at the University of California, Berkeley. Capable of answering specific questions of interest based on real-world data, Targeted Learning unifies desirable aspects of algorithmic machine learning and causal inference to generate efficient and trustworthy inferences. It resurrects the pillars of statistics like the facts that a model represents real knowledge about the experiment that generated the data and that a target parameter represents what we are seeking to learn from the data as a feature of the distribution that generated the data. In this way, Targeted Learning defines a truth and establishes a standard for estimation, while current culture typically defines a parameter as a coefficient in a misspecified parametric (or other restrictive) statistical model, where different choices of such misspecified models result in different answers. This allows one to make arbitrary choices, potentially driven by data and human bias, even though these choices often result in different answers to the same estimation problem. This subjectivity presents a fundamental drive behind the epidemic of false positives and lack of power to detect true positives that scientific research is suffering from Laan and Starmans (2014). We are faced with an urgent scientific need to enhance the reproducibility and rigor of research and the current culture of data analysis enables a major contributor of this crisis – human bias. Consequences of not meeting this need will result in further decline in the rate of scientific progression, the reputation of biomedical science, and the public’s trust in its findings. Training of robust methods that avoid confirmation bias will lead to results being more reproducible and trustworthy. Our team at The University of California, Berkeley, is uniquely positioned to provide such a training. The objective for this handbook is to enhance the education of students, researchers, professors, etc. to empower them with the necessary knowledge and skills to utilize the sound research methodology of Targeted Learning. For any complex statistical methodology to be accessible in practice, it is crucial that it is accompanied by robust software. The tlverse software ecosystem was developed to fulfill this need. Not only does this software facilitate computationally reproducible and efficient analyses, it is also a tool for Targeted Learning education since its workflow mirrors that of the methodology. In particular, the tlverse paradigm does not focus on implementing a specific estimator or a small set of related estimators — instead, the focus is on exposing the statistical framework of Targeted Learning itself! All R packages in the tlverse ecosystem directly model the key objects defined in the mathematical and theoretical framework of Targeted Learning. In this handbook, the reader will embark on a journey through the tlverse. Guided by R programming exercises, case studies, and intuitive explanation readers will build a toolbox for applying the Targeted Learning statistical methodology, thereby increasing accessibility of this statistical approach and philosophy. The reader need not be a fully trained statistician to begin understanding and applying these methods. However, we do recommend ___ before References "],
["intro.html", "Chapter 1 Welcome to the tlverse 1.1 Learning Objectives 1.2 What is the tlverse? 1.3 tlverse components 1.4 Installation 1.5 Example Data - WASH Benefits", " Chapter 1 Welcome to the tlverse 1.1 Learning Objectives Understand the tlverse concept Identify the core components of the tlverse Install tlverse R packages Learn about the WASH Benefits example data 1.2 What is the tlverse? The tlverse is a new framework for doing Targeted Learning in R, inspired by the tidyverse ecosystem of R packages. By analogy to the tidyverse: The tidyverse is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures. So, the tlverse is an opinionated collection of R packages for Targeted Learning sharing an underlying philosophy, grammar, and set of data structures 1.3 tlverse components These are the main packages that represent the core of the tlverse: sl3: Modern Super Learning with Pipelines What? A modern object-oriented re-implementation of the Super Learner algorithm, employing recently developed paradigms for R programming. Why? A design that leverages modern tools for fast computation, is forward-looking, and can form one of the cornerstones of the tlverse. tmle3: An Engine for Targeted Learning What? A generalized framework that simplifies Targeted Learning by identifying and implementing a series of common statistical estimation procedures. Why? A common interface and engine that accommodates current algorithmic approaches to Targeted Learning and is still flexible enough to remain the engine even as new techniques are developed. In addition to the engines that drive development in the tlverse, there are some supporting packages – in particular, we have two… origami: A Generalized Framework for Cross-Validation What? A generalized framework for flexible cross-validation Why? Cross-validation is a key part of ensuring error estimates are honest and preventing overfitting. It is an essential part of the both the Super Learner algorithm and Targeted Learning. delayed: Parallelization Framework for Dependent Tasks What? A framework for delayed computations (futures) based on task dependencies. Why? Efficient allocation of compute resources is essential when deploying large-scale, computationally intensive algorithms. A key principle of the tlverse is extensibility. That is, we want to support new Targeted Learning estimators as they are developed. The model for this is new estimators are implemented in additional packages using the core packages above. There are currently two featured examples of this: tmle3mopttx: Optimal Treatments in tlverse What? Learn an optimal rule and estimate the mean outcome under the rule Why? Optimal Treatment is a powerful tool in precision healthcare and other settings where a one-size-fits-all treatment approach is not appropriate. tmle3shift: Shift Interventions in tlverse What? Shift interventions for continuous treatments Why? Not all treatment variables are discrete. Being able to estimate the effects of continuous treatment represents a powerful extension of the Targeted Learning approach. 1.4 Installation The tlverse ecosystem of packages are currently hosted at https://github.com/tlverse, not yet on CRAN. You can use the devtools package to install them: install.packages(&#39;devtools&#39;) devtools::install_github(&#39;tlverse/tlverse&#39;) The tlverse depends on a large number of other packages that are also hosted on GitHub. Because of this, you may see the followig error: Error: HTTP error 403. API rate limit exceeded for 71.204.135.82. (But here&#39;s the good news: Authenticated requests get a higher rate limit. Check out the documentation for more details.) Rate limit remaining: 0/60 Rate limit reset at: 2019-03-04 19:39:05 UTC To increase your GitHub API rate limit - Use `usethis::browse_github_pat()` to create a Personal Access Token. - Use `usethis::edit_r_environ()` and add the token as `GITHUB_PAT`. This just means that R tried to install too many packages from GitHub in too short of a window. To fix this, you need to tell R how to use github as your user (you’ll need a GitHub user account). Follow these two steps: Use usethis::browse_github_pat() to create a Personal Access Token. Use usethis::edit_r_environ() and add the token as GITHUB_PAT. 1.5 Example Data - WASH Benefits The data come from the Effect of water quality, sanitation, hand washing, and nutritional interventions on child development in rural Bangladesh (WASH Benefits Bangladesh): a cluster-randomised controlled trial ((???)). The study enrolled enrolled pregnant women in their first or second trimester from rural villages of Gazipur, Kishoreganj, Mymensingh, and Tangail districts of central Bangladesh, with an average of eight women per cluster. Groups of eight geographically adjacent clusters were block-randomised, using a random number generator, into six intervention groups (all of which received weekly visits from a community health promoter for the first 6 months and every 2 weeks for the next 18 months) and a double-sized control group (no intervention or health promoter visit). The six intervention groups were: chlorinated drinking water; improved sanitation; handwashing with soap; combined water, sanitation, and handwashing; improved nutrition through counselling and provision of lipid-based nutrient supplements; and combined water, sanitation, handwashing, and nutrition. In the workshop, we concentrate child-growth (size for age) as the outcome. This trial was registered with ClinicalTrials.gov, number NCT01590095. "],
["modern-super-machine-learning-with-sl3.html", "Chapter 2 Modern Super (Machine) Learning with sl3 2.1 Learning Objectives 2.2 Background 2.3 Modern Super (Machine) Learning with sl3 2.4 Exercise 2.5 Appendix: More advanced extensions of sl3", " Chapter 2 Modern Super (Machine) Learning with sl3 Rachael V. Phillips, Jeremy Coyle, Mark van der Laan Updated: 2019-04-01 2.1 Learning Objectives By the end of this chapter you will be able to: Assemble an ensemble of learners based on the properties that identify what features they support. Customize learner hyperparameters to incorporate a diversity of different settings. Select a subset of available covariates and pass only those variables to the modeling algorithm. Fit an ensemble with nested cross-validation to obtain an estimate of the performance of the ensemble itself. 2.2 Background Now that we have defined the statistical estimation problem, we are ready construct the TMLE; an asymptotically efficient substitution estimator of this target quantity. The first step in this estimation procedure is an initial estimate of the data-generating distribution, or the relevant part of this distribution that is needed to evaluate the target parameter. For this initial estimation, we use the Super Learner, an important step in creating a robust estimator. 2.2.0.1 Super Learner Loss-function-based tool that uses V-fold cross-validation to obtain the best prediction of the relevant part of the likelihood (needed to evaluate target parameter) based on a weighted average of a library of machine learning algorithms. The library of machine learning algorithms consists of functions (“learners” in the sl3 nomenclature) that we think might be consistent with the true data-generating distribution. Proven to be asymptotically as accurate as the best possible prediction algorithm that is tested. 2.3 Modern Super (Machine) Learning with sl3 2.3.1 Basic Implementation 0. Load necessary libraries First, we will load the relevant R packages and set a seed. library(here) library(tidyverse) library(data.table) library(sl3) library(SuperLearner) library(origami) set.seed(7194) 1. Load data We begin by illustrating the default functionality of the Super Learner algorithm as implemented in sl3. Using the WASH data, we are interested in predicting weight-for-height z-score whz using the available covariate data. # load data set and take a peek washb_data &lt;- fread(here(&quot;data&quot;, &quot;washb_data.csv&quot;), stringsAsFactors = TRUE) head(washb_data) whz tr fracode month aged sex momage momedu momheight 1: 0.00 Control N05265 9 268 male 30 Primary (1-5y) 146.40 2: -1.16 Control N05265 9 286 male 25 Primary (1-5y) 148.75 3: -1.05 Control N08002 9 264 male 25 Primary (1-5y) 152.15 4: -1.26 Control N08002 9 252 female 28 Primary (1-5y) 140.25 5: -0.59 Control N06531 9 336 female 19 Secondary (&gt;5y) 150.95 6: -0.51 Control N06531 9 304 male 20 Secondary (&gt;5y) 154.20 hfiacat Nlt18 Ncomp watmin elec floor walls roof 1: Food Secure 3 11 0 1 0 1 1 2: Moderately Food Insecure 2 4 0 1 0 1 1 3: Food Secure 1 10 0 0 0 1 1 4: Food Secure 3 5 0 1 0 1 1 5: Food Secure 2 7 0 1 0 1 1 6: Severely Food Insecure 0 3 1 1 0 1 1 asset_wardrobe asset_table asset_chair asset_khat asset_chouki asset_tv 1: 0 1 1 1 0 1 2: 0 1 0 1 1 0 3: 0 0 1 0 1 0 4: 1 1 1 1 0 0 5: 1 1 1 1 1 0 6: 0 0 0 0 1 0 asset_refrig asset_bike asset_moto asset_sewmach asset_mobile 1: 0 0 0 0 1 2: 0 0 0 0 1 3: 0 0 0 0 1 4: 0 1 0 0 1 5: 0 0 0 0 1 6: 0 0 0 0 1 2. Define machine learning task To define the machine learning “task” (predict weight-for-height z-score whz using the available covariate data), we need to create an sl3_Task object. The sl3_Task keeps track of the roles the variables play in the machine learning problem, the data, and any metadata (e.g., observational-level weights, id, offset). # specify the outcome and covariates outcome &lt;- &quot;whz&quot; covars &lt;- colnames(washb_data)[-which(names(washb_data) == outcome)] # create the sl3 task task &lt;- make_sl3_Task(data = washb_data, covariates = covars, outcome = outcome) Warning in .subset2(public_bind_env, &quot;initialize&quot;)(...): Missing Covariate Data Found. Imputing covariates using sl3_process_missing # examine it task A sl3 Task with 4695 obs and these nodes: $covariates [1] &quot;tr&quot; &quot;fracode&quot; &quot;month&quot; &quot;aged&quot; [5] &quot;sex&quot; &quot;momage&quot; &quot;momedu&quot; &quot;momheight&quot; [9] &quot;hfiacat&quot; &quot;Nlt18&quot; &quot;Ncomp&quot; &quot;watmin&quot; [13] &quot;elec&quot; &quot;floor&quot; &quot;walls&quot; &quot;roof&quot; [17] &quot;asset_wardrobe&quot; &quot;asset_table&quot; &quot;asset_chair&quot; &quot;asset_khat&quot; [21] &quot;asset_chouki&quot; &quot;asset_tv&quot; &quot;asset_refrig&quot; &quot;asset_bike&quot; [25] &quot;asset_moto&quot; &quot;asset_sewmach&quot; &quot;asset_mobile&quot; &quot;delta_momage&quot; [29] &quot;delta_momheight&quot; $outcome [1] &quot;whz&quot; $id NULL $weights NULL $offset NULL 3. Specify base learner library Now that we have defined our machine learning problem by making the task, we are ready to define the machine learning algorithms. Learners have properties that indicate what features they support. Use sl3_list_properties() to get a list of all properties supported by at least one learner. sl3_list_properties() [1] &quot;binomial&quot; &quot;categorical&quot; &quot;continuous&quot; [4] &quot;cv&quot; &quot;density&quot; &quot;ids&quot; [7] &quot;multivariate_outcome&quot; &quot;offset&quot; &quot;preprocessing&quot; [10] &quot;timeseries&quot; &quot;weights&quot; &quot;wrapper&quot; Since we have a continuous outcome, we may identify the learners that support this outcome type with sl3_list_learners(). sl3_list_learners(c(&quot;continuous&quot;)) [1] &quot;Lrnr_arima&quot; &quot;Lrnr_bartMachine&quot; [3] &quot;Lrnr_bilstm&quot; &quot;Lrnr_condensier&quot; [5] &quot;Lrnr_dbarts&quot; &quot;Lrnr_expSmooth&quot; [7] &quot;Lrnr_glm&quot; &quot;Lrnr_glm_fast&quot; [9] &quot;Lrnr_glmnet&quot; &quot;Lrnr_grf&quot; [11] &quot;Lrnr_h2o_glm&quot; &quot;Lrnr_h2o_grid&quot; [13] &quot;Lrnr_hal9001&quot; &quot;Lrnr_HarmonicReg&quot; [15] &quot;Lrnr_lstm&quot; &quot;Lrnr_mean&quot; [17] &quot;Lrnr_nnls&quot; &quot;Lrnr_optim&quot; [19] &quot;Lrnr_pkg_SuperLearner&quot; &quot;Lrnr_pkg_SuperLearner_method&quot; [21] &quot;Lrnr_pkg_SuperLearner_screener&quot; &quot;Lrnr_randomForest&quot; [23] &quot;Lrnr_ranger&quot; &quot;Lrnr_rpart&quot; [25] &quot;Lrnr_rugarch&quot; &quot;Lrnr_solnp&quot; [27] &quot;Lrnr_stratified&quot; &quot;Lrnr_svm&quot; [29] &quot;Lrnr_tsDyn&quot; &quot;Lrnr_xgboost&quot; Now that we have an idea of some learners, we can construct them by the make_learner function. # choose base learners lrnr_glm &lt;- make_learner(Lrnr_glm) lrnr_mean &lt;- make_learner(Lrnr_mean) lrnr_ranger &lt;- make_learner(Lrnr_ranger) lrnr_glmnet &lt;- make_learner(Lrnr_glmnet) In order to assemble the library of learners, we need to “stack” them together. A Stack is just a special learner and so has the same interface as all other learners: stack &lt;- make_learner(Stack, lrnr_glm, lrnr_mean, lrnr_ranger, lrnr_glmnet) A stack combines multiple learners by training them simultaneously, so that their predictions can be either combined or compared. We’re almost ready to super learn! Just one more necessary specification. 4. Specify meta-learner We will fit a non-negative least squares meta-learner using Lrnr_nnls. Note that any learner can be used as a meta-learner. metalearner &lt;- make_learner(Lrnr_nnls) 5. Super learn The Super Learner algorithm fits a meta-learner on the validation-set predictions in a cross-validated manner, thereby avoiding overfitting. This procedure is referred to as the continuous super learner. The cross-validation selector is the discrete super learner. First, we create a super learner object and then we need to “train” it on our sl3_task object: # run sl and predict on WASH sl &lt;- Lrnr_sl$new(learners = stack, metalearner = metalearner) sl_fit &lt;- sl$train(task) Now that we have fit the super leaner, we are ready to obtain our predicted values and summarized results. sl_preds &lt;- sl_fit$predict() head(sl_preds) [1] -0.5029638 -0.8878685 -0.7753261 -0.7882591 -0.6812345 -0.7038221 sl_fit$print() [1] &quot;SuperLearner:&quot; List of 4 $ : chr &quot;Lrnr_glm_TRUE&quot; $ : chr &quot;Lrnr_mean&quot; $ : chr &quot;Lrnr_ranger_500_TRUE&quot; $ : chr &quot;Lrnr_glmnet_NULL_deviance_10_1_100_TRUE&quot; [1] &quot;Lrnr_nnls&quot; lrnrs weights 1: Lrnr_glm_TRUE 0.1876734 2: Lrnr_mean 0.0000000 3: Lrnr_ranger_500_TRUE 0.4816424 4: Lrnr_glmnet_NULL_deviance_10_1_100_TRUE 0.3347854 [1] &quot;Cross-validated risk (MSE, squared error loss):&quot; learner coefficients mean_risk SE_risk 1: Lrnr_glm_TRUE NA 1.020570 0.02391262 2: Lrnr_mean NA 1.065278 0.02502098 3: Lrnr_ranger_500_TRUE NA 1.015457 0.02347748 4: Lrnr_glmnet_NULL_deviance_10_1_100_TRUE NA 1.015160 0.02361971 5: SuperLearner NA 1.009377 0.02343840 fold_SD fold_min_risk fold_max_risk 1: 0.04603086 0.9760878 1.133006 2: 0.06603243 0.9310730 1.181434 3: 0.04585768 0.9327879 1.100511 4: 0.05003559 0.9491794 1.131936 5: 0.04656630 0.9393638 1.110628 2.3.2 Extensions We can customize learner hyperparameters to incorporate a diversity of different settings. We can also include learners from the SuperLearner R package. lrnr_ranger100 &lt;- make_learner(Lrnr_ranger, num.trees = 100) lrnr_ranger1k &lt;- make_learner(Lrnr_ranger, num.trees = 1000) lrnr_polymars &lt;- Lrnr_pkg_SuperLearner$new(&quot;SL.polymars&quot;) lrnr_gam &lt;- Lrnr_pkg_SuperLearner$new(&quot;SL.gam&quot;) lrnr_bayesglm &lt;- Lrnr_pkg_SuperLearner$new(&quot;SL.bayesglm&quot;) # let&#39;s create a new stack with these new learners new_stack &lt;- make_learner(Stack, lrnr_glm, lrnr_mean, lrnr_ranger, lrnr_glmnet, lrnr_ranger1k, lrnr_ranger100, lrnr_polymars, lrnr_gam, lrnr_bayesglm) We can also select a subset of available covariates and “pipe” only those variables to the modeling algorithm. A Pipeline is a set of learners to be fit sequentially, where the fit from one learner is used to define the task for the next learner. # design a screener to reduce covariate size screen_cor &lt;- Lrnr_pkg_SuperLearner_screener$new(&quot;screen.corP&quot;) # incorporate screener in the learner combo (i.e., Pipeline) cor_pipeline &lt;- make_learner(Pipeline, screen_cor, stack) # put it all together again with a Stack stack &lt;- make_learner(Stack, cor_pipeline, new_stack) Now we can super learn with this “fancy” implementation. # run sl and predict on WASH sl &lt;- Lrnr_sl$new(learners = new_stack, metalearner = metalearner) sl_fit &lt;- sl$train(task) Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.polymars failed with message: loading required package (polspline) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.gam failed with message: loading required package (gam) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.bayesglm failed with message: loading required package (arm) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.polymars failed with message: loading required package (polspline) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.gam failed with message: loading required package (gam) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.bayesglm failed with message: loading required package (arm) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.polymars failed with message: loading required package (polspline) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.gam failed with message: loading required package (gam) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.bayesglm failed with message: loading required package (arm) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.polymars failed with message: loading required package (polspline) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.gam failed with message: loading required package (gam) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.bayesglm failed with message: loading required package (arm) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.polymars failed with message: loading required package (polspline) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.gam failed with message: loading required package (gam) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.bayesglm failed with message: loading required package (arm) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.polymars failed with message: loading required package (polspline) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.gam failed with message: loading required package (gam) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.bayesglm failed with message: loading required package (arm) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.polymars failed with message: loading required package (polspline) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.gam failed with message: loading required package (gam) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.bayesglm failed with message: loading required package (arm) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.polymars failed with message: loading required package (polspline) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.gam failed with message: loading required package (gam) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.bayesglm failed with message: loading required package (arm) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.polymars failed with message: loading required package (polspline) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.gam failed with message: loading required package (gam) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.bayesglm failed with message: loading required package (arm) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.polymars failed with message: loading required package (polspline) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.gam failed with message: loading required package (gam) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.bayesglm failed with message: loading required package (arm) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.polymars failed with message: loading required package (polspline) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.gam failed with message: loading required package (gam) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.bayesglm failed with message: loading required package (arm) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): The following learners failed for one or more folds and will be dropped from all folds: Lrnr_pkg_SuperLearner_SL.polymars, Lrnr_pkg_SuperLearner_SL.gam, Lrnr_pkg_SuperLearner_SL.bayesglm sl_preds &lt;- sl_fit$predict() sl_fit$print() [1] &quot;SuperLearner:&quot; List of 9 $ : chr &quot;Lrnr_glm_TRUE&quot; $ : chr &quot;Lrnr_mean&quot; $ : chr &quot;Lrnr_ranger_500_TRUE&quot; $ : chr &quot;Lrnr_glmnet_NULL_deviance_10_1_100_TRUE&quot; $ : chr &quot;Lrnr_ranger_1000_TRUE&quot; $ : chr &quot;Lrnr_ranger_100_TRUE&quot; $ : chr &quot;Lrnr_pkg_SuperLearner_SL.polymars&quot; $ : chr &quot;Lrnr_pkg_SuperLearner_SL.gam&quot; $ : chr &quot;Lrnr_pkg_SuperLearner_SL.bayesglm&quot; [1] &quot;Lrnr_nnls&quot; lrnrs weights 1: Lrnr_glm_TRUE 0.17814933 2: Lrnr_mean 0.00000000 3: Lrnr_ranger_500_TRUE 0.03905204 4: Lrnr_glmnet_NULL_deviance_10_1_100_TRUE 0.32750435 5: Lrnr_ranger_1000_TRUE 0.31613779 6: Lrnr_ranger_100_TRUE 0.14351863 [1] &quot;Cross-validated risk (MSE, squared error loss):&quot; learner coefficients mean_risk SE_risk 1: Lrnr_glm_TRUE NA 1.020570 0.02391262 2: Lrnr_mean NA 1.065278 0.02502098 3: Lrnr_ranger_500_TRUE NA 1.016101 0.02346094 4: Lrnr_glmnet_NULL_deviance_10_1_100_TRUE NA 1.015025 0.02361526 5: Lrnr_ranger_1000_TRUE NA 1.014837 0.02345965 6: Lrnr_ranger_100_TRUE NA 1.020746 0.02359695 7: SuperLearner NA 1.009078 0.02343206 fold_SD fold_min_risk fold_max_risk 1: 0.04603086 0.9760878 1.133006 2: 0.06603243 0.9310730 1.181434 3: 0.04829319 0.9282896 1.106287 4: 0.05006425 0.9464229 1.131301 5: 0.04534389 0.9375547 1.102942 6: 0.04768590 0.9399861 1.111754 7: 0.04693926 0.9394737 1.111902 2.4 Exercise Create an sl3 task with the same outcome and covariate data. Make a library of 10 algorithms. Customize hyperparameters for at least two of your learners. Feel free to use learners from sl3 or SuperLearner. Incorporate at least two variations of feature selection. Use nonnegative least squares to fit the meta-learning step. Justify this base learner library and meta-learner selection. With the meta-learner and base learners, make the Super Learner and train it on the task. Print your Super Learner fit by calling print() with $. Which learner is the discrete super learner? Report the weights that the continuous Super Learner assigned to each learner. What might be the case if the mean risk of the continuous Super Learner is higher than the mean risk of the discrete Super Learner? 2.5 Appendix: More advanced extensions of sl3 2.5.1 Variable importance get_variable_importance &lt;- function(data, outcome, covars){ # create the sl3 task task &lt;- make_sl3_Task(data = data, covariates = covars, outcome = outcome) # choose base learners lrnr_glm &lt;- make_learner(Lrnr_glm) lrnr_mean &lt;- make_learner(Lrnr_mean) lrnr_glmnet &lt;- make_learner(Lrnr_glmnet) lrnr_polymars &lt;- Lrnr_pkg_SuperLearner$new(&quot;SL.polymars&quot;) lrnr_gam &lt;- Lrnr_pkg_SuperLearner$new(&quot;SL.gam&quot;) lrnr_bayesglm &lt;- Lrnr_pkg_SuperLearner$new(&quot;SL.bayesglm&quot;) # stack them together stack &lt;- make_learner(Stack, lrnr_glm, lrnr_mean, lrnr_glmnet, lrnr_polymars, lrnr_gam, lrnr_bayesglm) # choose metalearner metalearner &lt;- make_learner(Lrnr_nnls) # run sl and predict on raw data sl &lt;- Lrnr_sl$new(learners = stack, metalearner = metalearner) sl_fit &lt;- sl$train(task) sl_preds &lt;- sl_fit$predict() risk &lt;- mean(loss_squared_error(task$Y, sl_preds)) risk_diffs &lt;- lapply(covars, function(x){ # scramble cov column and give it the same name as the raw cov col scrambled_col &lt;- data.table(sample(unlist(data[,x, with = FALSE]), nrow(data))) names(scrambled_col) &lt;- x # replace raw col with scrambled col in the task scrambled_col_names &lt;- task$add_columns(scrambled_col) scrambled_col_task &lt;- task$next_in_chain(column_names = scrambled_col_names) # obtain preds on the scrambled col task scrambled_sl_preds &lt;- sl_fit$predict_fold(scrambled_col_task) # risk on scrambled col task risk_scrambled &lt;- mean(loss_squared_error(task$Y,scrambled_sl_preds)) # calculate risk difference rd &lt;- risk_scrambled - risk return(rd) }) names(risk_diffs) &lt;- covars results &lt;- data.table(cov = rep(names(risk_diffs), sapply(risk_diffs,length)), risk_diff = unlist(risk_diffs)) return(results) } varimp_washb &lt;- get_variable_importance(data = washb_data, outcome = outcome, covars = covars) Warning in .subset2(public_bind_env, &quot;initialize&quot;)(...): Missing Covariate Data Found. Imputing covariates using sl3_process_missing Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.polymars failed with message: loading required package (polspline) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.gam failed with message: loading required package (gam) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.bayesglm failed with message: loading required package (arm) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.polymars failed with message: loading required package (polspline) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.gam failed with message: loading required package (gam) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.bayesglm failed with message: loading required package (arm) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.polymars failed with message: loading required package (polspline) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.gam failed with message: loading required package (gam) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.bayesglm failed with message: loading required package (arm) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.polymars failed with message: loading required package (polspline) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.gam failed with message: loading required package (gam) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.bayesglm failed with message: loading required package (arm) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.polymars failed with message: loading required package (polspline) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.gam failed with message: loading required package (gam) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.bayesglm failed with message: loading required package (arm) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.polymars failed with message: loading required package (polspline) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.gam failed with message: loading required package (gam) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.bayesglm failed with message: loading required package (arm) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.polymars failed with message: loading required package (polspline) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.gam failed with message: loading required package (gam) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.bayesglm failed with message: loading required package (arm) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.polymars failed with message: loading required package (polspline) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.gam failed with message: loading required package (gam) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.bayesglm failed with message: loading required package (arm) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.polymars failed with message: loading required package (polspline) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.gam failed with message: loading required package (gam) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.bayesglm failed with message: loading required package (arm) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.polymars failed with message: loading required package (polspline) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.gam failed with message: loading required package (gam) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.bayesglm failed with message: loading required package (arm) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.polymars failed with message: loading required package (polspline) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.gam failed with message: loading required package (gam) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): Lrnr_pkg_SuperLearner_SL.bayesglm failed with message: loading required package (arm) failed. It will be removed from the stack Warning in private$.train(subsetted_task, trained_sublearners): The following learners failed for one or more folds and will be dropped from all folds: Lrnr_pkg_SuperLearner_SL.polymars, Lrnr_pkg_SuperLearner_SL.gam, Lrnr_pkg_SuperLearner_SL.bayesglm "],
["tmle3-targeted-learning-framework.html", "Chapter 3 tmle3 – Targeted Learning Framework 3.1 Learning Objectives 3.2 Example: tmle3 for ATE 3.3 tmle3 Components 3.4 Fitting tmle3 with multiple parameters 3.5 Summary", " Chapter 3 tmle3 – Targeted Learning Framework 3.1 Learning Objectives Use tmle3 to estimate an Average Treatment Effect (ATE) Understand tmle3 “Specs” Fit tmle3 for a custom set of parameters Use the delta method to estimate transformations of parameters 3.2 Example: tmle3 for ATE We’ll illustrate the most basic use of TMLE using the WASH Benefits data introduced earlier and estimating an Average Treatment Effect (ATE) As a reminder, the ATE is identified with the following statistical parameter (under assumptions): \\(ATE = E_0(Y(1)=Y(0)) = E_0\\left( E_0[Y \\mid A=1,W]-E_0[Y \\mid A=0,W] \\right),\\) 3.2.1 Load the Data We’ll use the same WASH Benefits data as the earlier chapters: library(here) library(data.table) library(tmle3) library(sl3) washb_data &lt;- fread(here(&quot;data&quot;, &quot;washb_data.csv&quot;), stringsAsFactors = TRUE) 3.2.2 Define the variable roles We’ll use the common W (covariates), A (treatment/intervention), Y (outcome) data structure. tmle3 needs to know what variables in the dataset correspond to each of these roles. We use a list of character vectors to tell it. We call this a “Node List” as it corresponds to the nodes in a Directed Acyclic Graph (DAG), a way of displaying causal relationships between variables. node_list &lt;- list(W = c(&quot;month&quot;, &quot;aged&quot;, &quot;sex&quot;, &quot;momage&quot;, &quot;momedu&quot;, &quot;momheight&quot;, &quot;hfiacat&quot;, &quot;Nlt18&quot;, &quot;Ncomp&quot;, &quot;watmin&quot;, &quot;elec&quot;, &quot;floor&quot;, &quot;walls&quot;, &quot;roof&quot;, &quot;asset_wardrobe&quot;, &quot;asset_table&quot;, &quot;asset_chair&quot;, &quot;asset_khat&quot;, &quot;asset_chouki&quot;, &quot;asset_tv&quot;, &quot;asset_refrig&quot;, &quot;asset_bike&quot;, &quot;asset_moto&quot;, &quot;asset_sewmach&quot;, &quot;asset_mobile&quot;), A = &quot;tr&quot;, Y = &quot;whz&quot;) 3.2.3 Handle Missingness Currently, missingness in tmle3 is handled in a fairly simple way: Missing covariates are median (for continuous) or mode (for discrete) imputed, and additional covariates indicating imputation are generated Observations missing either treatment or outcome variables are excluded. We plan to implement IPCW-TMLE to more efficiently handle missingness in the treatment and outcome variables. These steps are implemented in the process_missing function in tmle3: processed &lt;- process_missing(washb_data, node_list) washb_data &lt;- processed$data node_list &lt;- processed$node_list 3.2.4 Create a “Spec” Object tmle3 is general, and allows most components of the TMLE procedure to be specified in a modular way. However, most end-users will not be interested in manually specifying all of these components. Therefore, tmle3 implements a tmle3_Spec object that bundles a set ofcomponents into a specification that, with minimal additional detail, can be run by an end-user. We’ll start with using one of the specs, and then work our way down into the internals of tmle3. ate_spec &lt;- tmle_ATE(treatment_level = &quot;Nutrition + WSH&quot;, control_level = &quot;Control&quot;) 3.2.5 Define the learners Currently, the only other thing a user must define are the sl3 learners used to estimate the relevant factors of the likelihood: Q and g. This takes the form of a list of sl3 learners, one for each likelihood factor to be estimated with sl3: # choose base learners lrnr_mean &lt;- make_learner(Lrnr_mean) lrnr_xgboost &lt;- make_learner(Lrnr_xgboost) # define metalearners appropriate to data types ls_metalearner &lt;- make_learner(Lrnr_nnls) mn_metalearner &lt;- make_learner(Lrnr_solnp, metalearner_linear_multinomial, loss_loglik_multinomial) sl_Y &lt;- Lrnr_sl$new(learners = list(lrnr_mean, lrnr_xgboost), metalearner = ls_metalearner) sl_A &lt;- Lrnr_sl$new(learners = list(lrnr_mean, lrnr_xgboost), metalearner = mn_metalearner) learner_list &lt;- list(A = sl_A, Y = sl_Y) Here, we use a SuperLearner as defined in the previous chapter. In the future, we plan to include reasonable defaults learners. 3.2.6 Fit the TMLE We now have everything we need to fit the tmle using tmle3: tmle_fit &lt;- tmle3(ate_spec, washb_data, node_list, learner_list) 3.2.7 Evaluate the Estimates We can see the summary results by printing the fit object. Alternatively, we can extra results from the summary by indexing into it: print(tmle_fit) A tmle3_Fit that took 1 step(s) type param init_est tmle_est 1: ATE ATE[Y_{A=Nutrition + WSH}-Y_{A=Control}] 0.00237243 0.001385835 se lower upper psi_transformed lower_transformed 1: 0.05051861 -0.09762882 0.1004005 0.001385835 -0.09762882 upper_transformed 1: 0.1004005 estimates &lt;- tmle_fit$summary$psi_transformed print(estimates) [1] 0.001385835 3.3 tmle3 Components Now that we’ve successfully used a spec to obtain a TML estimate, let’s look under the hood at the components. The spec has a number of functions that generate the objects necessary to define and fit a TMLE. 3.3.1 tmle3_task First is, a tmle3_Task, analogous to an sl3_Task, containing the data we’re fitting the TMLE to, as well as an NP-SEM generated from the node_list defined above, describing the variables and their relationships. tmle_task &lt;- ate_spec$make_tmle_task(washb_data, node_list) tmle_task$npsem $W tmle3_Node: W Variables: month, aged, sex, momedu, hfiacat, Nlt18, Ncomp, watmin, elec, floor, walls, roof, asset_wardrobe, asset_table, asset_chair, asset_khat, asset_chouki, asset_tv, asset_refrig, asset_bike, asset_moto, asset_sewmach, asset_mobile, momage, momheight, delta_momage, delta_momheight Parents: $A tmle3_Node: A Variables: tr Parents: W $Y tmle3_Node: Y Variables: whz Parents: A, W 3.3.2 Initial Likelihood Next, is an object representing the likelihood, factorized according to the NPSEM described above: initial_likelihood &lt;- ate_spec$make_initial_likelihood(tmle_task, learner_list) print(initial_likelihood) W: Lf_emp A: LF_fit Y: LF_fit These components of the likelihood indicate how the factors were estimated: the marginal distribution of \\(W\\) was estimated using NP-MLE, and the conditional distributions of \\(A\\) and \\(Y\\) were estimated using sl3 fits (as defined with the learner_list) above. We can use this in tandem with the tmle_task object to obtain likelihood estimates for each observation: initial_likelihood$get_likelihoods(tmle_task) W A Y 1: 0.0002129925 0.2473454 -0.6546753 2: 0.0002129925 0.2552501 -0.6295529 3: 0.0002129925 0.2604075 -0.6181996 4: 0.0002129925 0.2847072 -0.5993649 5: 0.0002129925 0.2540454 -0.5467837 --- 4691: 0.0002129925 0.1360638 -0.4725153 4692: 0.0002129925 0.1259960 -0.4900073 4693: 0.0002129925 0.1262773 -0.5685746 4694: 0.0002129925 0.1825613 -0.7998468 4695: 0.0002129925 0.1303175 -0.5440784 3.3.3 Targeted Likelihood (updater) We also need to define a “Targeted Likelihood” object. This is a special type of likelihood that is able to be updated using an tmle3_Update object. This object defines the update strategy (e.g. submodel, loss function, CV-TMLE or not, etc). targeted_likelihood &lt;- Targeted_Likelihood$new(initial_likelihood) When constructing the targeted likelihood, you can specify different update options. See the documentation for tmle3_Update for details of the different options. For example, you can disable CV-TMLE (the default in tmle3) as follows: targeted_likelihood_no_cv &lt;- Targeted_Likelihood$new(initial_likelihood, updater = list(cvtmle = FALSE)) 3.3.4 Parameter Mapping Finally, we need to define the parameters of interest. Here, the spec defines a single parameter, the ATE. In the next section, we’ll see how to add additional parameters. tmle_params &lt;- ate_spec$make_params(tmle_task, targeted_likelihood) print(tmle_params) [[1]] Param_ATE: ATE[Y_{A=Nutrition + WSH}-Y_{A=Control}] 3.3.5 Putting it all together Having used the spec to manually generate all these components, we can now manually fit a tmle3: tmle_fit_manual &lt;- fit_tmle3(tmle_task, targeted_likelihood, tmle_params, targeted_likelihood$updater) print(tmle_fit_manual) A tmle3_Fit that took 1 step(s) type param init_est tmle_est 1: ATE ATE[Y_{A=Nutrition + WSH}-Y_{A=Control}] 0.002247442 0.006710695 se lower upper psi_transformed lower_transformed 1: 0.05055907 -0.09238327 0.1058047 0.006710695 -0.09238327 upper_transformed 1: 0.1058047 The result is equivalent to fitting using the tmle3 function as above. 3.4 Fitting tmle3 with multiple parameters Above, we fit a tmle3 with just one parameter. tmle3 also supports fitting multiple parameters simultaneously. To illustrate this, we’ll use the tmle_TSM_all spec: tsm_spec &lt;- tmle_TSM_all() targeted_likelihood &lt;- Targeted_Likelihood$new(initial_likelihood) all_tsm_params &lt;- tsm_spec$make_params(tmle_task, targeted_likelihood) print(all_tsm_params) [[1]] Param_TSM: E[Y_{A=Control}] [[2]] Param_TSM: E[Y_{A=Handwashing}] [[3]] Param_TSM: E[Y_{A=Nutrition}] [[4]] Param_TSM: E[Y_{A=Nutrition + WSH}] [[5]] Param_TSM: E[Y_{A=Sanitation}] [[6]] Param_TSM: E[Y_{A=WSH}] [[7]] Param_TSM: E[Y_{A=Water}] This spec generates a Treatment Specific Mean (TSM) for each level of the exposure variable. Note that we must first generate a new targeted likelihood, as the old one was targeted to the ATE. However, we can recycle the initial likelihood we fit above, saving us a super learner step. 3.4.1 Delta Method We can also define parameters based on Delta Method Transformations of other parameters. For instance, we can estimate a ATE using the delta method and two of the above TSM parameters: ate_param &lt;- define_param(Param_delta, targeted_likelihood, delta_param_ATE, list(all_tsm_params[[1]], all_tsm_params[[4]])) print(ate_param) Param_delta: E[Y_{A=Nutrition + WSH}] - E[Y_{A=Control}] This can similarly be used to estimate other derived parameters like Relative Risks, and Population Attributable Risks 3.4.2 Fit We can now fit a TMLE simultaneously for all TSM parameters, as well as the above defined ATE parameter all_params &lt;- c(all_tsm_params, ate_param) tmle_fit_multiparam &lt;- fit_tmle3(tmle_task, targeted_likelihood, all_params, targeted_likelihood$updater) print(tmle_fit_multiparam) A tmle3_Fit that took 1 step(s) type param init_est tmle_est 1: TSM E[Y_{A=Control}] -0.593804743 -0.622181650 2: TSM E[Y_{A=Handwashing}] -0.605362011 -0.642260234 3: TSM E[Y_{A=Nutrition}] -0.601234281 -0.613433567 4: TSM E[Y_{A=Nutrition + WSH}] -0.591557301 -0.615427062 5: TSM E[Y_{A=Sanitation}] -0.587711009 -0.588980244 6: TSM E[Y_{A=WSH}] -0.533535560 -0.440634258 7: TSM E[Y_{A=Water}] -0.576955609 -0.537524713 8: ATE E[Y_{A=Nutrition + WSH}] - E[Y_{A=Control}] 0.002247442 0.006754588 se lower upper psi_transformed lower_transformed 1: 0.03000588 -0.68099209 -0.5633712 -0.622181650 -0.68099209 2: 0.04204882 -0.72467440 -0.5598461 -0.642260234 -0.72467440 3: 0.04286839 -0.69745406 -0.5294131 -0.613433567 -0.69745406 4: 0.04082454 -0.69544169 -0.5354124 -0.615427062 -0.69544169 5: 0.04247206 -0.67222395 -0.5057365 -0.588980244 -0.67222395 6: 0.04492029 -0.52867641 -0.3525921 -0.440634258 -0.52867641 7: 0.03864565 -0.61326879 -0.4617806 -0.537524713 -0.61326879 8: 0.05054913 -0.09231988 0.1058291 0.006754588 -0.09231988 upper_transformed 1: -0.5633712 2: -0.5598461 3: -0.5294131 4: -0.5354124 5: -0.5057365 6: -0.3525921 7: -0.4617806 8: 0.1058291 3.5 Summary tmle3 is a general purpose framework for generating TML estimates. The easiest way to use it is to use a predefined spec, allowing you to just fill in the blanks for the data, variable roles, and sl3 learners. However, digging under the hood allows users to specify a wide range of TMLEs. In the next sections, we’ll see how this framework can be used to estimate advanced parameters such as optimal treatments and shift interventions. "],
["optimal-individualized-treatment-regimes.html", "Chapter 4 Optimal Individualized Treatment Regimes 4.1 Learning Objectives 4.2 Introduction to Optimal Individualized Interventions 4.3 Data Structure and Notation 4.4 Defining the Causal Effect of an Optimal Individualized Intervention 4.5 Interpreting the Causal Effect of an Optimal Individualized Intervention 4.6 Evaluating the Causal Effect of an Optimal Individualized Intervention with Categorical Treatment 4.7 Evaluating the Causal Effect of an Optimal Individualized Intervention with Binary Treatment 4.8 Learning the Mean Outcome under the Optimal Rule with Q-learning 4.9 Variable Importance Analysis with Optimal Individualized Interventions 4.10 Exercises", " Chapter 4 Optimal Individualized Treatment Regimes Ivana Malenica, Jeremy Coyle, Mark van der Laan Updated: 2019-04-01 4.1 Learning Objectives Understand and describe the essential properties of dynamic and optimal individualized treatment regimes. How may this formalism be used to define causal effects? How do dynamic treatment regimes differ from static and stochastic regimes? Understand and describe the benefits and challenges associated with using optimal individualized treatment regimes in practice. Use the tmle3mopttx R package to successfully estimate the causal effects of an optimal individualized treatment on simulated data. Understand and describe how variable importance measures may be defined in terms of optimal individualized treatment interventions. Perform hands-on, real-world data analysis to assess the causal effect of optimal individualized treatment, successfully describing what may be learned from the data based on the inferential properties of targeted minimum loss-based estimators. 4.2 Introduction to Optimal Individualized Interventions The aim of precision medicine is to allow for patient specific interventions. In the case of categorical treatment, one opts to administer the intervention to individuals who will benefit from it, instead of assigning treatment on a population level. For example, Abacavir and Tenofovir are commonly prescribed as part of the antiretroviral therapy to Human Immunodeficiency Virus (HIV) patients. However, not all individuals benefit from the two medications equally. In particular, patients with renal dysfunction might further deteriorate if prescribed Tenofovir, due to the high nephrotoxicity caused by the medication. While Tenofovir is still highly effective treatment option for HIV patients, in order to maximize the patient’s well-being, it would be beneficial to prescribe Tenofovir only to individuals with healthy kidney function. This motivates a different type of intervention, as opposed to the static exposures we might be used to. In particular, in this chapter we learn about dynamic or individualized interventions that tailor the treatment decision based on the collected covariates. In particular, dynamic treatments represent interventions that at each treatment-decision stage are allowed to respond to the currently available treatment and covariate history. In the statistics community such a treatment strategy is termed The problem of estimating the optimal individualized treatment has received much attention in the statistics literature over the years, especially with the advancement of precision medicine; see Murphy (2003), Robins (2004), (“Temporary,” n.d.) and (???) to name a few. However, much of the early work depends on parametric assumptions. As such, even in a randomized trial, the statistical inference for the optimal individualized treatment relies on assumptions that are generally believed to be false, and can lead to biased results. In this chapter, we consider estimation of the mean outcome under the optimal individualized treatment where the candidate rules are restricted to depend only on user-supplied subset of the baseline covariates. The estimation problem is addressed in a statistical model for the data distribution that is nonparametric, and at most places restrictions on the probability of a patient receiving treatment given covariates (as in a randomized trial). As such, we don’t need to make any assumptions about the relationship of the outcome with the treatment and covariates, or the relationship between the treatment and covariates. Further, we provide a Targeted Maximum Likelihood Estimator for the mean under the optimal individualized treatment that allows us to generate valid inference for our parameter, without having any parametric assumptions. For a technical presentation of the algorithm, the interested reader is invited to further consult van der Laan and Luedtke (2015) and Luedtke and van der Laan (2016). For additional background on Targeted Learning, please consider consulting van der Laan and Rose (2011) and van der Laan and Rose (2018). 4.3 Data Structure and Notation Suppose we observe \\(n\\) independent and identically distributed observations of the form \\(O=(W,A,Y) \\sim P_0\\). We denote \\(A\\) as categorical treatment, and \\(Y\\) as the final outcome. In particular, we define \\(A \\in \\mathcal{A}\\) where \\(\\mathcal{A} \\equiv \\{a_1, \\cdots, a_{n_A} \\}\\) and \\(n_A = |\\mathcal{A}|\\), with \\(n_A\\) denoting the number of categories (possibly only two, for a binary setup). Note that we treat \\(W\\) as vector-valued, representing all of our collected baseline covariates. Therefore, for a single random individual \\(i\\), we have that their observed data is \\(O_i\\): with corresponding baseline covariates \\(W_i\\), treatment \\(A_i\\), and final outcome \\(Y_i\\). We say that \\(O \\sim P_0\\), or that all data was drawn from some probability distribution \\(P_0\\). We emphasize that we make no assumptions about the distribution of \\(P_0\\), so that \\(P_0 \\in \\mathcal{M}\\), where \\(\\mathcal{M}\\) is the fully nonparametric model. As previously mentioned, this means that we make no assumptions on the relationship between \\(Y\\) and \\(A\\) and \\(W\\), but might make assumptions regarding the relationship of \\(A\\) and \\(W\\), as is the case in a randomized trial. We can break the data generating distribution \\(P_0\\) into the following parts by time ordering: \\[P_0(O) = P_0(Y|A,W)P_0(A|W)P_0(W) = Q_{Y,0}(Y|A,W)g_0(A|W)Q_{W,0}(W)\\] where \\(P_0(Y|A,W)=Q_{Y,0}(Y|A,W)\\), \\(P_0(A|W)=g_0(A|W)\\) and \\(P_0(W)=Q_{W,0}(W)\\). For notational simplicity, we also define \\(\\bar{Q}_{Y,0}(A,W) \\equiv E_0[Y|A,W]\\). In addition, we define \\(V\\) as \\(V \\in W\\), denoting a subset of the baseline covariates the optimal individualized rule will depend on. Note that \\(V\\) could be all of \\(W\\), or an empty set, depending on the subject matter knowledge. In particular, a researcher might want to consider known effect modifiers available at the time of treatment decision as possible \\(V\\) covariates. We can assume a nonparametric structural equation model (NPSEM) to describe generation of \\(O\\) Pearl (2009). Specifically, we have that: \\[\\begin{align*} W &amp;= f_W(U_W) \\\\ A &amp;= f_A(W, U_A) \\\\ Y &amp;= f_Y(A, W, U_Y) \\end{align*}\\] In particular, NPSEM parameterizes \\(P_0(O)\\) in terms of the distribution of random variables \\(O\\) and \\(U\\), where \\(U=(U_W,U_A,U_Y)\\) are the exogenous random variables. Note that \\(f_W\\), \\(f_A\\), \\(f_Y\\) are deterministic unspecified or partially specified functions. 4.4 Defining the Causal Effect of an Optimal Individualized Intervention Many methods for learning an optimal rule from data have been developed . In this chapter, we focus on the methods developed in Luedtke and van der Laan (2016) and van der Laan and Luedtke (2015). Note however, that tmle3mopttx also supports the widely used Q-learning approach, where the optimal individualized rule is based on the initial estimate of \\(\\bar{Q}_{Y,0}(A,W)\\) Sutton, Barto, and others (1998). In particular, we follow the methodology outlined in Luedtke and van der Laan (2016) and van der Laan and Luedtke (2015), where we learn the optimal ITR using Super Learner van der Laan, Polley, and Hubbard (2007), and estimate its value using the cross-validated Targeted Minimum Loss-based Estimation (CV-TMLE) Zheng and van der Laan (2010). Luedtke and van der Laan present three different approaches for learning the optimal rule- namely: Super Learning the Blip Function Super Learning the Weighted Classification Problem Joint Super Learner of the Blip and Weighted Classification Problem The package tmle3mopttx relies on using the Super Learner to estimate the blip function, as it easily extends to more general categorical treatment. With that in mind, the loss function utilized for learning the optimal individualized rule corresponds to conditional mean type losses. In great generality, we first need to estimate the true individual treatment regime, which corresponds to dynamic treatment rule (\\(d(V)\\)) that takes a subset of covariates \\(V \\in W\\) and assigns treatment to each individual based on their observed covariates \\(v\\). We can define counterfactuals \\(Y_{d(V)}\\) by modifying the NPSEM such that \\(A=d(V)\\), and denote the distribution of the counterfactual quantities as \\(P_{0,d}(O)\\). We are mostly interested in the value of such an individualized rule: \\[E_0[Y_{d(V)}] = E_{0,W}[\\bar{Q}_{Y,0}(A=d(V),W)]\\] which, under typical causal assumptions, can be interpreted as the mean outcome if (possibly contrary to fact), treatment was assigned according to the rule. The optimal rule is the rule with the maximal value: \\[d_{opt} \\equiv \\text{argmax}_{d \\in \\mathcal{D}} E_0[Y_{d(V)}] \\] where \\(\\mathcal{D}\\) represents the set of possible rules, \\(d\\). We note that, in case the problem in hand requires minimizing the mean of an outcome, our optimal individualized rule will be the rule with the minimal value instead. Under causal assumptions, we can identify \\(P_{0,d}(O)\\) with observed data using the G-computation formula: \\[P_{0,d_{opt}}(O) = Q_{Y,0}(Y|A=d_{opt}(V),W)g_0(A=d_{opt}(V)|W)Q_{W,0}(W)\\] 4.4.1 Binary treatment How do we estimate the optimal individualized rule? In the case of a binary treatment, a key quantity for optimal ITR is the blip function. In particular, one can show that any optimal ITR assigns treatment to individuals falling in strata in which the stratum specific average treatment effect, the blip function, is positive and does not assign treatment to individuals for which this quantity is negative. Therefore for a binary treatment, we define a blip function as: \\[\\bar{Q}_0(V) \\equiv E_0[Y_1-Y_0|V] \\equiv E_0[\\bar{Q}_{Y,0}(1,W) - \\bar{Q}_{Y,0}(0,W) | V], \\] the average treatment effect within a stratum of \\(V\\). The note that the optimal individualized rule can now be derived as \\(d_{opt}(V) = I(\\bar{Q}_{0}(V) &gt; 0)\\). In particular, we will: Estimate \\(\\bar{Q}_{Y,0}(A,W)\\) and \\(g_0(A|W)\\) using sl3. We denote such estimates as \\(\\bar{Q}_{Y,n}(A,W)\\) and \\(g_n(A|W)\\). Apply the doubly robust Augmented-Inverse Probability Weighted (A-IPW) transform to our outcome, where we define: \\[D_{\\bar{Q}_Y,g,a}(O) \\equiv \\frac{I(A=a)}{g(A|W)} (Y-\\bar{Q}_Y(A,W)) + \\bar{Q}_Y(A=a,W)\\] note that under the randomization and positivity assumptions we have that \\(E[D_{\\bar{Q}_Y,g,a}(O) | V] = E[Y_a |V]\\). Also, we emphasize its double robust nature- consistency of \\(E[Y_a |V]\\) will depend on correct estimation of either \\(\\bar{Q}_{Y,0}(A,W)\\) or \\(g_0(A|W)\\). As such, in a randomized trial, we are guaranteed a consistent estimate of \\(E[Y_a |V]\\) even if we get \\(\\bar{Q}_{Y,0}(A,W)\\) wrong! Using this transform, we can define the following contrast: \\(D_{\\bar{Q}_Y,g}(O) = D_{\\bar{Q}_Y,g,a=1}(O) - D_{\\bar{Q}_Y,g,a=0}(O)\\) We estimate the blip function, \\(\\bar{Q}_{0,a}(V)\\), by regressing \\(D_{\\bar{Q}_Y,g}(O)\\) on \\(V\\) using the specified sl3 library of learners and an appropriate loss function. Our estimated rule is \\(d(V) = \\text{argmax}_{a \\in \\mathcal{A}} \\bar{Q}_{0,a}(V)\\). Obtain inference for the mean outcome under the estimated optimal rule using CV-TMLE. 4.4.2 Categorical treatment In line with the approach considered for binary treatment, we extend the blip function to allow for categorical treatment. We denote such blip function extensions as , which are our new estimation targets in a categorical setting. We define pseudo-blips as vector valued entities where the output for a given \\(V\\) is a vector of length equal to the number of treatment categories, \\(n_A\\). As such, we define it as: \\[\\bar{Q}_0^{pblip}(V) = \\{\\bar{Q}_{0,a}^{pblip}(V): a \\in \\mathcal{A} \\}\\] We implement three different pseudo-blips in tmle3mopttx. corresponds to choosing a reference category of treatment, and defining the blip for all other categories relative to the specified reference. Hence we have that: \\[\\bar{Q}_{0,a}^{pblip-ref}(V) \\equiv E_0(Y_a-Y_0|V)\\] where \\(Y_0\\) is the specified reference category with \\(A=0\\). Note that, for the case of binary treatment, this strategy reduces to the approach described for the binary setup. approach corresponds to defining the blip relative to the average of all categories. As such, we can define \\(\\bar{Q}_{0,a}^{pblip-avg}(V)\\) as: \\[\\bar{Q}_{0,a}^{pblip-avg}(V) \\equiv E_0(Y_a- \\frac{1}{n_A} \\sum_{a \\in \\mathcal{A}} Y_{a|V)\\] In the case where subject-matter knowledge regarding which reference category to use is not available, blip2 might be a viable option. reflects an extension of Blip2, where the average is now a weighted average: \\[\\bar{Q}_{0,a}^{pblip-wavg}(V) \\equiv E_0(Y_a- \\frac{1}{n_A} \\sum_{a \\in \\mathcal{A}} Y_{a} P(A=a|V) |V)\\] Just like in the binary case, pseudo-blips are estimated by regressing contrasts composed using the A-IPW transform on \\(V\\). ## Inference In a randomized trial, statistical inference relies on the second-order difference between the estimator of the optimal individualized treatment and the optimal individualized treatment itself to be asymptotically negligible. This is a reasonable condition if we consider rules that depend on small number of covariates, or if we are willing to make smoothness assumptions. Alternatively, we can consider TMLEs and statistical inference for data-adaptive target parameters defined in terms of an estimate of the optimal individualized treatment. In particular, instead of trying to estimate the mean under the true optimal individualized treatment, we aim to estimate the mean under the estimated optimal individualized treatment. As such, we develop cross-validated TMLE approach that provides asymptotic inference under minimal conditions for the mean under the estimate of the optimal individualized treatment. In particular, considering the data adaptive parameter allows us to avoid consistency and rate condition for the fitted optimal rule, as required for asymptotic linearity of the TMLE of the mean under the actual, true optimal rule. Practically, the estimated (data-adaptive) rule should be preferred, as this possibly sub-optimal rule is the one implemented in the population. 4.4.3 Why CV-TMLE? As discussed in van der Laan and Luedtke (2015), CV-TMLE is necessary as the non-cross-validated TMLE is biased upward for the mean outcome under the rule- and therefore overly optimistic. More generally however, using CV-TMLE allows us more freedom in estimation and therefore greater data adaptivity, without sacrificing inference. 4.5 Interpreting the Causal Effect of an Optimal Individualized Intervention In summary, the mean outcome under the optimal individualized treatment is a counterfactual quantity of interest representing what the mean outcome would have been if everybody, contrary to the fact, received treatment that optimized their outcome. The optimal individualized treatment regime is a rule that optimizes the mean outcome under the dynamic treatment, where the candidate rules are restricted to only respond to a user-supplied subset of the baseline and intermediate covariates. In essence, our target parameter answers the key aim of precision medicine: allocating the available treatment by tailoring it to the individual characteristics of the patient, with the goal of optimizing the final outcome. 4.6 Evaluating the Causal Effect of an Optimal Individualized Intervention with Categorical Treatment Finally, we demonstrate how to evaluate the mean outcome under the optimal individualized treatment using tmle3mopptx. To start, let’s load the packages we’ll use and set a seed: library(data.table) library(sl3) library(tmle3) library(tmle3mopttx) library(devtools) set.seed(111) 4.6.1 Simulated Data First, we load the simulated data. We will start with the more general setup where the treatment is a categorical variable; later in the chapter we will consider another data generating distribution where \\(A\\) is binary. In this example, our data generating distribution is of the following form: \\[W \\sim \\mathcal{N}(\\bf{0},I_{4 \\times 4})\\] \\[P(A=a|W) = \\frac{1}{1+\\exp^{(-0.8*W_a)}}\\] \\[P(Y=1|A,W) = 0.5\\text{logit}^{-1}[3I(A=1)(W_1-0.5) - 3I(A=2)(2W_2+0.5) + 3I(A=3)(3W_3-0.5)] +\\text{logit}^{-1}(W_2W_3)\\] We can just load the data available as part of the package as follows: data(&quot;data_cat&quot;) The above composes our observed data structure \\(O = (W, A, Y)\\). Note that the mean under the true optimal rule is \\(\\psi=0.625\\). To formally express this fact using the tlverse grammar introduced by the tmle3 package, we create a single data object and specify the functional relationships between the nodes in the directed acyclic graph (DAG) via nonparametric structural equation models (NPSEMs), reflected in the node list that we set up: # organize data and nodes for tmle3 data &lt;- data_cat node_list &lt;- list( W = c(&quot;W1&quot;, &quot;W2&quot;, &quot;W3&quot;, &quot;W4&quot;), A = &quot;A&quot;, Y = &quot;Y&quot; ) We now have an observed data structure (data) and a specification of the role that each variable in the data set plays as the nodes in a DAG. 4.6.2 Constructing Optimal Stacked Regressions with sl3 To easily incorporate ensemble machine learning into the estimation procedure, we rely on the facilities provided in the sl3 R package. Using the framework provided by the sl3 package, the nuisance parameters of the TML estimator may be fit with ensemble learning, using the cross-validation framework of the Super Learner algorithm of van der Laan, Polley, and Hubbard (2007). #Initialize some of the learners. #Here we use xgboost with various parameters, glm, HAL and the mean. xgboost_50&lt;-Lrnr_xgboost$new(nrounds = 50) xgboost_100&lt;-Lrnr_xgboost$new(nrounds = 100) xgboost_500&lt;-Lrnr_xgboost$new(nrounds = 500) lrn1 &lt;- Lrnr_mean$new() lrn2&lt;-Lrnr_glm_fast$new() lrn3&lt;-Lrnr_hal9001$new() #Define the Q learner, which is just a regular learner: Q_learner &lt;- Lrnr_sl$new( learners = list(xgboost_50,xgboost_100,xgboost_500,lrn1,lrn2), metalearner = Lrnr_nnls$new() ) #Define the g learner, which is a multinomial learner: glib &lt;- list( rf &lt;- make_learner(Lrnr_randomForest), xgb &lt;- make_learner(Lrnr_xgboost), glmnet &lt;- make_learner(Lrnr_glmnet), multinom_gf &lt;- make_learner(Lrnr_independent_binomial, make_learner(Lrnr_glm_fast)), mean &lt;- make_learner(Lrnr_mean) ) #Specify the appropriate loss of the multinomial learner: mn_metalearner &lt;- make_learner(Lrnr_solnp, loss_function = loss_loglik_multinomial, learner_function = metalearner_linear_multinomial) g_learner &lt;- make_learner(Lrnr_sl, glib, mn_metalearner) #Define the Blip learner, which is a multivariate learner: learners &lt;- list(xgboost_50,xgboost_100,xgboost_500,lrn1,lrn2) b_learner &lt;- create_mv_learners(learners = learners) As seen above, we generate three different ensemble learners that must be fit, corresponding to the learners for the outcome regression, propensity score, and the blip function. Note that we need to estimate \\(g_0(A|W)\\) for a categorical \\(A\\)- therefore we use the multinomial Super Learner option available within the sl3 package with learners that can address multi-class classification problems. In order to see which learners can be used to estimate \\(g_0(A|W)\\) in sl3, we run the following: #See which learners support multi-class classification: sl3_list_learners(c(&quot;categorical&quot;)) [1] &quot;Lrnr_bartMachine&quot; &quot;Lrnr_dbarts&quot; [3] &quot;Lrnr_glmnet&quot; &quot;Lrnr_grf&quot; [5] &quot;Lrnr_h2o_glm&quot; &quot;Lrnr_h2o_grid&quot; [7] &quot;Lrnr_independent_binomial&quot; &quot;Lrnr_mean&quot; [9] &quot;Lrnr_multivariate&quot; &quot;Lrnr_optim&quot; [11] &quot;Lrnr_randomForest&quot; &quot;Lrnr_ranger&quot; [13] &quot;Lrnr_rpart&quot; &quot;Lrnr_solnp&quot; [15] &quot;Lrnr_svm&quot; &quot;Lrnr_xgboost&quot; Also note that since the corresponding blip will be vector valued, we will have a column for each additional level of treatment. As such, we need to use multivariate learners with the the helper function create_mv_learners that takes a list of initialized learners as input. We make the above explicit with respect to standard notation by bundling the ensemble learners into a list object below: # specify outcome and treatment regressions and create learner list learner_list &lt;- list(Y = Q_learner, A = g_learner, B = b_learner) The learner_list object above specifies the role that each of the ensemble learners we’ve generated is to play in computing initial estimators to be used in building a TMLE for the parameter of interest. In particular, it makes explicit the fact that our Y is used in fitting the outcome regression while our A is used in fitting our treatment mechanism regression, and finally B is used in fitting the blip function. 4.6.3 Targeted Estimation of the Mean under the Optimal Individualized Interventions Effects To start, we will initialize a specification for the TMLE of our parameter of interest simply by calling tmle3_mopttx_blip_revere. We specify the argument V = c(&quot;W1&quot;, &quot;W2&quot;, &quot;W3&quot;, &quot;W4&quot;) when initializing the tmle3_Spec object in order to communicate that we’re interested in learning a rule dependent on V covariates. We also need to specify the type of pseudo-blip we will use in this estimation problem, and finally the list of learners used to estimate the blip function. # initialize a tmle specification tmle_spec &lt;- tmle3_mopttx_blip_revere(V = c(&quot;W1&quot;, &quot;W2&quot;, &quot;W3&quot;, &quot;W4&quot;), type = &quot;blip2&quot;, b_learner = learner_list$B, maximize = TRUE, complex = TRUE) As seen above, the tmle3_mopttx_blip_revere specification object (like all tmle3_Spec objects) does not store the data for our specific analysis of interest. Later, we’ll see that passing a data object directly to the tmle3 wrapper function, alongside the instantiated tmle_spec, will serve to construct a tmle3_Task object internally. In initializing the specification for the TMLE of our parameter of interest, we have specified the set of covariates the rule depends on (V), the type of pseudo-blip to use (type), and the learners used for estimating the pseudo-blip. In addition, we need to specify whether we want to maximize the mean outcome under the rule (maximize=TRUE), and whether we want to estimate the rule under all the covariates \\(V\\) provided by the user (complex). If FALSE, tmle3mopttx will instead consider all the possible rules under a smaller set of covariates including the static rules, and optimize the mean outcome over all the subsets of \\(V\\). As such, while the user might have provided a full set of collected covariates as input for \\(V\\), it is possible that the true rule only depends on a subset of the set provided by the user. In that case, our returned mean under the optimal individualized rule will be based on the smaller subset. We explore this important feature of tmle3mopttx in the later sections. # fit the TML estimator fit &lt;- tmle3(tmle_spec, data, node_list, learner_list) fit A tmle3_Fit that took 1 step(s) type param init_est tmle_est se lower upper 1: TSM E[Y_{A=NULL}] 0.4804245 0.5808087 0.02546001 0.530908 0.6307094 psi_transformed lower_transformed upper_transformed 1: 0.5808087 0.530908 0.6307094 We can see that the estimate of \\(psi_0\\) is \\(0.58\\), and that the confidence interval covers our true mean under the true optimal individualized treatment. 4.6.4 Learning the Mean Outcome under the Optimal Rule with Q-learning Here we outline how to use tmle3mopttx package in order to estimate the mean under the ITR using Q-learning. As demonstrated in the previous sections, we first need to initialize a specification for the TMLE of our parameter of interest. As opposed to the previous section however, we will now use tmle3_mopttx_Q instead of tmle3_mopttx_blip_revere in order to indicate that we want to use Q-learning instead of TMLE. # initialize a tmle specification tmle_spec_Q &lt;- tmle3_mopttx_Q(maximize = TRUE) # Define data: tmle_task &lt;- tmle_spec_Q$make_tmle_task(data, node_list) # Define likelihood: initial_likelihood &lt;- tmle_spec_Q$make_initial_likelihood(tmle_task, learner_list) # Estimate the parameter: (broken by tmle3@1bc8f32) Q_learning(tmle_spec_Q, initial_likelihood, tmle_task) 4.7 Evaluating the Causal Effect of an Optimal Individualized Intervention with Binary Treatment Next, we consider how to evaluate the mean outcome under the optimal individualized treatment when \\(A\\) is binary. As outlined in previous sections, our estimation procedure should rely on simple blip estimation corresponding to type=blip1 for binary treatment. 4.7.1 Simulated Data First, we load the simulated data. Here, our data generating distribution was of the following form: \\[W \\sim \\mathcal{N}(\\bf{0},I_{3 \\times 3})\\] \\[P(A=1|W) = \\frac{1}{1+\\exp^{(-0.8*W_1)}}\\] \\[P(Y=1|A,W) = 0.5\\text{logit}^{-1}[-5I(A=1)(W_1-0.5)+5I(A=0)(W_1-0.5)] + 0.5\\text{logit}^{-1}(W_2W_3)\\] data(&quot;data_bin&quot;) The above composes our observed data structure \\(O = (W, A, Y)\\). Note that the mean under the true optimal rule is \\(\\psi=0.578\\) for this data generating distribution. # organize data and nodes for tmle3 data &lt;- data_bin node_list &lt;- list( W = c(&quot;W1&quot;, &quot;W2&quot;, &quot;W3&quot;), A = &quot;A&quot;, Y = &quot;Y&quot; ) 4.7.2 Constructing Optimal Stacked Regressions with sl3 # Define sl3 library and metalearners: xgboost_50&lt;-Lrnr_xgboost$new(nrounds = 50) xgboost_100&lt;-Lrnr_xgboost$new(nrounds = 100) xgboost_500&lt;-Lrnr_xgboost$new(nrounds = 500) lrn1 &lt;- Lrnr_mean$new() lrn2&lt;-Lrnr_glm_fast$new() lrn3&lt;-Lrnr_hal9001$new() Q_learner &lt;- Lrnr_sl$new( learners = list(xgboost_50,xgboost_100,xgboost_500, lrn1,lrn2), metalearner = Lrnr_nnls$new() ) g_learner &lt;- Lrnr_sl$new( learners = list(xgboost_100,lrn2), metalearner = Lrnr_nnls$new() ) b_learner &lt;- Lrnr_sl$new( learners = list(xgboost_50,xgboost_100,xgboost_500, lrn1,lrn2), metalearner = Lrnr_nnls$new() ) As seen above, we generate three different ensemble learners that must be fit, corresponding to the learners for the outcome regression, propensity score, and the blip function. We make the above explicit with respect to standard notation by bundling the ensemble learners into a list object below: # specify outcome and treatment regressions and create learner list learner_list &lt;- list(Y = Q_learner, A = g_learner, B = b_learner) 4.7.3 Targeted Estimation of the Mean under the Optimal Individualized Interventions Effects # initialize a tmle specification tmle_spec &lt;- tmle3_mopttx_blip_revere(V = c(&quot;W1&quot;, &quot;W2&quot;, &quot;W3&quot;), type = &quot;blip1&quot;, b_learner = learner_list$B, maximize = TRUE, complex = TRUE) # fit the TML estimator fit &lt;- tmle3(tmle_spec, data, node_list, learner_list) fit A tmle3_Fit that took 1 step(s) type param init_est tmle_est se lower upper 1: TSM E[Y_{A=NULL}] 0.427284 0.5691145 0.02720572 0.5157923 0.6224368 psi_transformed lower_transformed upper_transformed 1: 0.5691145 0.5157923 0.6224368 We can see that the estimate of \\(psi_0\\) is \\(0.56\\), and that the confidence interval covers our true mean under the true optimal individualized treatment. 4.7.4 Extension: Simpler Rules In order to not only consider the most ambitious fully V-optimal rule, we define S-optimal rules as the optimal rule that considers all possible subsets of \\(V\\) covariates, with card(\\(S\\)) \\(\\leq\\) card(\\(V\\)) and \\(\\emptyset \\in S\\). This allows us to consider sub-optimal rules that are easier to estimate and potentially provide more realistic rules- as such, we allow for statistical inference for the counterfactual mean outcome under the sub-optimal rule. Within the tmle3mopttx paradigm, we just need to change the complex parameter to FALSE: # initialize a tmle specification tmle_spec &lt;- tmle3_mopttx_blip_revere(V = c(&quot;W1&quot;, &quot;W2&quot;, &quot;W3&quot;), type = &quot;blip1&quot;, b_learner = learner_list$B, maximize = TRUE, complex = FALSE) # fit the TML estimator fit &lt;- tmle3(tmle_spec, data, node_list, learner_list) fit A tmle3_Fit that took 1 step(s) type param init_est tmle_est se lower upper 1: TSM E[Y_{A=W3}] 0.4263868 0.5674792 0.02705617 0.5144501 0.6205083 psi_transformed lower_transformed upper_transformed 1: 0.5674792 0.5144501 0.6205083 Therefore even though the user specified all baseline covariates as the basis for rule estimation, a simpler rule based on only \\(W_3\\) is sufficient to maximize the mean under the optimal individualized treatment. 4.8 Learning the Mean Outcome under the Optimal Rule with Q-learning Alternatively, we could estimate the mean under the optimal individualized treatment using Q-learning. The optimal rule can be learned through fitting the likelihood, and consequently estimating the optimal rule under this fit of the likelihood . Below we outline how to use tmle3mopttx package in order to estimate the mean under the ITR using Q-learning. As demonstrated in the previous sections, we first need to initialize a specification for the TMLE of our parameter of interest. As opposed to the previous section however, we will now use tmle3_mopttx_Q instead of tmle3_mopttx_blip_revere in order to indicate that we want to use Q-learning instead of TMLE. # initialize a tmle specification tmle_spec_Q &lt;- tmle3_mopttx_Q(maximize = TRUE) # Define data: tmle_task &lt;- tmle_spec_Q$make_tmle_task(data, node_list) # Define likelihood: initial_likelihood &lt;- tmle_spec_Q$make_initial_likelihood(tmle_task, learner_list) # Estimate the parameter: Q_learning(tmle_spec_Q, initial_likelihood, tmle_task) [1] 0.3175011 4.9 Variable Importance Analysis with Optimal Individualized Interventions Suppose one wishes to assess the importance of each observed covariate, in terms of maximizing (or minimizing) the population mean of an outcome under an optimal individualized treatment regime. In particular, a covariate that maximizes (or minimizes) the population mean outcome the most under an optimal individualized treatment out of all other considered covariates under optimal assignment might be considered “more important” for the outcome. To put it in context, perhaps optimal allocation of treatment 1, denoted \\(A_1\\), results in a larger mean outcome than optimal allocation of another treatment (\\(A_2\\)). Therefore, we would label \\(A_1\\) as having a higher variable importance as regard to maximizing the mean outcome under the optimal individualized treatment. 4.9.1 Simulated Data We consider the same data as described in the previous section, with our treatment and outcome being binary variables. Note that here we have three baseline covariates, hence our variable importance algorithm will consider optimal allocation of all the available \\(W\\)s and \\(A\\). 4.9.2 Constructing Optimal Stacked Regressions with sl3 #Define sl3 library and metalearners: qlib &lt;- make_learner_stack( &quot;Lrnr_mean&quot;, &quot;Lrnr_glm_fast&quot; ) glib &lt;- make_learner_stack( &quot;Lrnr_mean&quot;, &quot;Lrnr_glmnet&quot;, &quot;Lrnr_xgboost&quot; ) blib &lt;- make_learner_stack( &quot;Lrnr_mean&quot;, &quot;Lrnr_glm_fast&quot; ) metalearner &lt;- make_learner(Lrnr_nnls) mn_metalearner &lt;- make_learner(Lrnr_solnp, loss_function = loss_loglik_multinomial, learner_function = metalearner_linear_multinomial) Q_learner &lt;- make_learner(Lrnr_sl, qlib, metalearner) g_learner &lt;- make_learner(Lrnr_sl, glib, mn_metalearner) b_learner &lt;- make_learner(Lrnr_sl, blib, metalearner) # specify outcome and treatment regressions and create learner list learner_list &lt;- list(Y = Q_learner, A = g_learner, B = b_learner) 4.9.3 Variable Importance using Targeted Estimation of the Mean under the Optimal Individualized Interventions Effects In the previous sections we have seen how to obtain a contrast between the mean under the optimal individualized rule and the mean under the observed outcome for a single covariate- we are now ready to run the variable importance analysis for all of our observed covariates. In order to run the variable importance analysis, we first need to initialize a specification for the TMLE of our parameter of interest as we have done before. In addition, we need to specify the data and the corresponding list of nodes, as well as the appropriate learners for the outcome regression, propensity score, and the blip function. Finally, we need to specify whether we should adjust for all the other covariates we are assessing variable importance for. Note that we are able to assess importance of only categorical covariates- hence all continuous baseline covariates \\(W\\) will not be included in the variable importance loop, only \\(A\\) terms. However, we will adjust for all \\(W\\)s in our analysis, and if adjust_for_other_A=TRUE, also for all \\(A\\) covariates that are not treated as exposure in the variable importance loop. For computational reasons, we set adjust_for_other_A=FALSE below. To start, we will initialize a specification for the TMLE of our parameter of interest (called a tmle3_Spec in the tlverse nomenclature) simply by calling tmle3_mopttx_vim. First, we indicate the method used for learning the optimal individualized treatment by specifying the method argument of tmle3_mopttx_vim. If method=&quot;Q&quot;, then we will be using Q-learning for rule estimation, and we do not need to specify V, type and b_learner arguments in the spec, since they are not important for Q-learning. However, if method=&quot;SL&quot;, which corresponds to learning the optimal individualized treatment using the above outlined methodology, then we need to specify the type of pseudo-blip we will use in this estimation problem and the list of learners used to estimate the blip function. Finally, for method=&quot;SL&quot; we also need to communicate that we’re interested in learning a rule dependent on V covariates by specifying the V argument. For both method=&quot;Q&quot; and method=&quot;SL&quot;, we need to indicate whether we want to maximize or minimize the mean under the optimal individualized rule. Finally, we also need to specify whether the final comparison of the mean under the optimal individualized rule and the mean under the observed outcome should be on the multiplicative scale (risk ratio) or linear (similar to average treatment effect). # initialize a tmle specification tmle_spec &lt;- tmle3_mopttx_vim(V = c(&quot;W1&quot;, &quot;W2&quot;, &quot;W3&quot;), type = &quot;blip1&quot;, b_learner = learner_list$B, contrast = &quot;multiplicative&quot;, maximize = FALSE, method=&quot;SL&quot;) # fit the TML estimator vim_results &lt;- tmle3_vim(tmle_spec, data, node_list, learner_list, adjust_for_other_A = FALSE) vim_results The final result of tmle3_vim with the tmle3mopttx spec is an ordered list of mean outcomes under the optimal individualized treatment for all categorical covariates in our dataset. 4.9.4 Variable Importance using Q-learning We can also perform variable importance with the optimal individualized treatment estimated by Q-learning. In order to do that, we need to initialize our tmle3 spec with method=&quot;Q&quot;, then run as in the above section. # initialize a tmle specification: tmle_spec_Q &lt;- tmle3_mopttx_vim(contrast = &quot;multiplicative&quot;, maximize = FALSE, method=&quot;Q&quot;) vim_results_Q &lt;- tmle3_vim(tmle_spec_Q, data, node_list=node_list, learner_list, adjust_for_other_A = FALSE) vim_results_Q 4.10 Exercises 4.10.1 Basics/Review 4.10.2 Using the Ideas 4.10.3 Advanced References "],
["stochastic-treatment-regimes.html", "Chapter 5 Stochastic Treatment Regimes 5.1 Learning Objectives 5.2 Introduction to Stochastic Interventions 5.3 Data Structure and Notation 5.4 Defining the Causal Effect of a Stochastic Intervention 5.5 Interpreting the Causal Effect of a Stochastic Intervention 5.6 Evaluating the Causal Effect of a Stochastic Intervention 5.7 Extensions: Variable Importance Analysis with Stochastic Interventions 5.8 Exercises", " Chapter 5 Stochastic Treatment Regimes Nima Hejazi, Jeremy Coyle, Mark van der Laan Updated: 2019-04-01 5.1 Learning Objectives Understand and describe the essential properties of stochastic treatment regimes. How may this formalism be used to define causal effects? How do stochastic treatment regimes differ from static, dynamic, and optimal treatment regimes? Understand and describe the challenges associated with using stochastic treatment regimes in practice. Understand and describe how variable importance measures may be defined in terms of stochastic interventions, using marginal structural models. Use the tmle3shift R package to successfully estimate the causal effects of a shift-based stochastic treatment regime on simple, simulated data. Perform hands-on, real-world data analysis to assess the causal effect of stochastically shifting a treatment variable, successfully describing what may be learned from the data based on the inferential properties of targeted minimum loss-based estimators. 5.2 Introduction to Stochastic Interventions Stochastic treatment regimes present a relatively simple yet extremely flexible manner by which realistic causal effects (and contrasts thereof) may be defined. Importantly, stochastic treatment regimes may be applied to nearly any manner of treatment variable – continuous, ordinal, categorical, binary – allowing for a rich set of causal effects to be defined through this formalism. In this chapter, we examine a simple example of stochastic treatment regimes in the context of a continuous treatment variable of interest, defining an intuitive causal effect through which to examine stochastic interventions more generally. In later sections, we introduce numerous extensions based on this broad class of interventions – from stochastic interventions on binary treatment variables to stochastic mediation effects and data-adaptive inference for stochastic intervention effects. As a first step to using stochastic treatment regimes in practice, we present the tmle3shift R package, which features an implementation of a recently developed algorithm for computing targeted minimum loss-based estimates of a causal effect based on a stochastic treatment regime that shifts the natural value of the treatment based on a shifting function \\(d(A,W)\\). For a comprehensive technical presentation of some of the material in this chapter, the interested reader is invited to consult Díaz and van der Laan (2018). Additional background on the field of Targeted Learning, as well as prior work on stochastic treatment regimes, is available in van der Laan and Rose (2011), van der Laan and Rose (2018), and Díaz and van der Laan (2012). While stochastic treatment regimes are arguably the most general of the classes of interventions through which causal effects may be defined, such interventions are conceptually simple. 5.3 Data Structure and Notation Consider \\(n\\) observed units \\(O_1, \\ldots, O_n\\), where each random variable \\(O = (W, A, Y)\\) corresponds to a single observational unit. Let \\(W\\) denote baseline covariates (e.g., age, sex, education level), \\(A\\) an intervention variable of interest (e.g., nutritional supplements), and \\(Y\\) an outcome of interest (e.g., disease status). Though it need not be the case, let \\(A\\) be continuous-valued, i.e. \\(A \\in \\mathbb{R}\\). Let \\(O_i \\sim \\mathcal{P} \\in \\mathcal{M}\\), where \\(\\mathcal{M}\\) is the nonparametric statistical model defined as the set of continuous densities on \\(O\\) with respect to some dominating measure. To formalize the definition of stochastic interventions and their corresponding causal effects, we introduce a nonparametric structural equation model (NPSEM), based on Pearl (2009), to define how the system changes under posited interventions: \\[\\begin{align*}\\label{eqn:npsem} W &amp;= f_W(U_W) \\\\ A &amp;= f_A(W, U_A) \\\\ Y &amp;= f_Y(A, W, U_Y), \\end{align*}\\] where the set of structural equations provide a mechanistic model by which the observed data \\(O\\) is assumed to have been generated. There are several standard assumptions embedded in the NPSEM – specifically, a temporal ordering that supposes that \\(Y\\) occurs after \\(A\\), which occurs after \\(W\\); each variable (i.e., \\(\\{W, A, Y\\}\\)) is assumed to have been generated from its corresponding deterministic function (i.e., \\(\\{f_W, f_A, f_Y\\}\\)) of the observed variables that precede it temporally, as well as an exogenous variable, denoted by \\(U\\); lastly, each exogenous variable is assumed to contain all unobserved causes of the corresponding observed variable. The likelihood of the data \\(O\\) admits a factorization, wherein, for \\(p_0^O\\), the density of \\(O\\) with respect to the product measure, the density evaluated on a particular observation \\(o\\) may be a written \\[\\begin{equation*}\\label{eqn:likelihood_factorization} p_0^O(x) = q^O_{0,Y}(y \\mid A = a, W = w) q^O_{0,A}(a \\mid W = w) q^O_{0,W}(w), \\end{equation*}\\] where \\(q_{0, Y}\\) is the conditional density of \\(Y\\) given \\((A, W)\\) with respect to some dominating measure, \\(q_{0, A}\\) is the conditional density of \\(A\\) given \\(W\\) with respect to dominating measure \\(\\mu\\), and \\(q_{0, W}\\) is the density of \\(W\\) with respect to dominating measure \\(\\nu\\). Further, for ease of notation, let \\(Q(A, W) = \\mathbb{E}[Y \\mid A, W]\\), \\(g(A \\mid W) = \\mathbb{P}(A \\mid W)\\), and \\(q_W\\) the marginal distribution of \\(W\\). These components of the likelihood will be essential in developing an understanding of the manner in which stochastic treatment regimes pertrub a system and how a corresponding causal effect may be evaluated. Importantly, the NPSEM parameterizes \\(p_0^O\\) in terms of the distribution of random variables \\((O, U)\\) modeled by the system of equations. In turn, this implies a model for the distribution of counterfactual random variables generated by interventions on the data-generating process. 5.4 Defining the Causal Effect of a Stochastic Intervention As causal effects are defined in terms of hypothetical interventions on the NPSEM (), we may consider stochastic interventions in two equivalent ways: (1) where the equation \\(f_A\\), giving rise to \\(A\\), is replaced by a probabilistic mechanism \\(g_{\\delta}(A \\mid W)\\) that differs from the original \\(g(A \\mid W)\\), or (2) where the observed value \\(A\\) is replaced by a new value \\(A_{d(A,W)}\\) based on applying a user-defined function \\(d(A,W)\\) to \\(A\\). In the former case, the stochastically modified value of the treatment \\(A_{\\delta}\\) is drawn from a user-specified distribution \\(g_\\delta(A \\mid W)\\), which may depend on the original distribution \\(g(A \\mid W)\\) and is indexed by a user-specified parameter \\(\\delta\\). In this case, the stochastically modified value of the treatment \\(A_{\\delta} \\sim g_{\\delta}(\\cdot \\mid W)\\). Alternatively, in the latter case, the stochastic treatment regime may be viewed as an intervention in which \\(A\\) is set equal to a value based on a hypothetical regime \\(d(A, W)\\), where regime \\(d\\) depends on the treatment level \\(A\\) that would be assigned in the absence of the regime as well as the covariates \\(W\\). In either case, one may view the stochastic intervention as generating a counterfactual random variable \\(Y_{d(A,W)} := f_Y(d(A,W), W, U_Y) \\equiv Y_{g_{\\delta}} := f_Y(A_{\\delta}, W, U_Y)\\), where the counterfactual outcome \\(Y_{d(A,W)} \\sim \\mathcal{P}_0^{\\delta}\\). Stochastic interventions of this second variety may be referred to as depending on the natural value of treatment or as modified treatment policies. Haneuse and Rotnitzky (2013) and Young, Hernán, and Robins (2014) provide a discussion of the critical differences and similarities in the identification and interpretation of these two classes of stochastic intervention. In the sequel, we will restrict our attention to a simple stochastic treatment regime that has been characterized as a modified treatment policy (MTP). Letting \\(A\\) denote a continuous-valued treatment, such as the taking of nutritional supplements (e.g., number of vitamin pills) and assume that the distribution of \\(A\\) conditional on \\(W = w\\) has support in the interval \\((l(w), u(w))\\). That is, the minimum observed number of pills taken \\(A\\) for an individual with covariates \\(W = w\\) is \\(l(w)\\); similarly, the maximum is \\(u(w)\\). Then, a simple stochastic intervention, based on a shift \\(\\delta\\), may be defined \\[\\begin{equation}\\label{eqn:shift} d(a, w) = \\begin{cases} a - \\delta &amp; \\text{if } a &gt; l(w) + \\delta \\\\ a &amp; \\text{if } a \\leq l(w) + \\delta, \\end{cases} \\end{equation}\\] where \\(0 \\leq \\delta \\leq u(w)\\) is an arbitrary pre-specified value that defines the degree to which the observed value \\(A\\) is to be shifted, where possible. Such a stochastic treatment regime may be interpreted as the result of a clinic policy that encourages individuals to consume \\(\\delta\\) more vitamin pills than they would normally, i.e., based on their baseline characteristics. The interpretation of this stochastic intervention may be made more interesting by allowing the modification \\(\\delta\\) that it engenders to be a function of the baseline covariates \\(W\\), thereby allowing for the number of vitamin pills taken to be a function of covariates such as age, sex, comorbidities, etc. This class of stochastic interventions was first introduced by Díaz and van der Laan (2012) and has been further discussed in Haneuse and Rotnitzky (2013), Díaz and van der Laan (2018), and Hejazi et al. (n.d.). Note that this intervention may be written in a manner consistent with the first class of stochastic treatment regimes discussed as well – that is, as per Díaz and van der Laan (2012), \\(\\mathbb{P}_{\\delta}(g_0)(A = a \\mid W) = g_0(a - \\delta(W) \\mid W)\\). The goal of any causal analysis motivated by such a stochastic intervention is to estimate a parameter defined as the counterfactual mean of the outcome with respect to the stochastically modified intervention distribution. In particular, the target causal estimand of our analysis is \\(\\psi_{0, \\delta} := \\mathbb{E}_{P_0^{\\delta}}\\{Y_{d(A,W)}\\}\\), the mean of the counterfactual outcome variable \\(Y_{d(A, W)}\\). In prior work, Díaz and van der Laan (2012) showed that the causal quantity of interest \\(\\mathbb{E}_0 \\{Y_{d(A, W)}\\}\\) is identified by a functional of the distribution of \\(O\\): \\[\\begin{align*}\\label{eqn:identification2012} \\psi_{0,d} = \\int_{\\mathcal{W}} \\int_{\\mathcal{A}} &amp; \\mathbb{E}_{P_0} \\{Y \\mid A = d(a, w), W = w\\} \\cdot \\\\ &amp;q_{0, A}^O(a \\mid W = w) \\cdot q_{0, W}^O(w) d\\mu(a)d\\nu(w). \\end{align*}\\] If the identification conditions may be assumed to hold, then the statistical parameter in matches exactly the counterfactual outcome \\(\\psi_{0, \\delta}\\) under such an intervention, allowing for the causal effect to be learned from the observed data \\(O\\). Díaz and van der Laan (2012) provide a derivation based on the efficient influence function (EIF) in the nonparametric model \\(\\mathcal{M}\\) and develop several estimators of this quantity, including substitution, inverse probability weighted (IPW), augmented inverse probability weighted (AIPW), and targeted maximum likelihood (TML) estimators, allowing for semiparametric-efficient estimation and inference on the quantity of interest. As per Díaz and van der Laan (2018), the statistical target parameter may also be denoted \\(\\Psi(P_0) = \\mathbb{E}_{P_0}{\\overline{Q}(d(A, W), W)}\\), where \\(\\overline{Q}(d(A, W), W)\\) is the counterfactual outcome value of a given individual under the stochastic intervention distribution. Although the focus of this work is neither the establishment of identification results nor the development of theoretical details, we review the necessary identification details for the counterfactual mean under a stochastic intervention here, in the interest of completeness. Paraphrasing from Díaz and van der Laan (2012) and Díaz and van der Laan (2018), four standard assumptions are necessary in order to establish identifiability of the causal parameter from the observed data via the statistical functional – these are Consistency: \\(Y^{d(a_i, w_i)}_i = Y_i\\) in the event \\(A_i = d(a_i, w_i)\\), for \\(i = 1, \\ldots, n\\) Stable unit value treatment assumption (SUTVA): \\(Y^{d(a_i, w_i)}_i\\) does not depend on \\(d(a_j, w_j)\\) for \\(i = 1, \\ldots, n\\) and \\(j \\neq i\\), or lack of interference (Rubin 1978, 1980). Strong ignorability: \\(A_i \\indep Y^{d(a_i, w_i)}_i \\mid W_i\\), for \\(i = 1, \\ldots, n\\). Positivity (or overlap)_: \\(a_i \\in \\mathcal{A} \\implies d(a_i, w_i) \\in \\mathcal{A}\\) for all \\(w \\in \\mathcal{W}\\), where \\(\\mathcal{A}\\) denotes the support of \\(A \\mid W = w_i \\quad \\forall i = 1, \\ldots n\\). With the identification assumptions satisfied, Díaz and van der Laan (2012) and Díaz and van der Laan (2018) provide an efficient influence function with respect to the nonparametric model \\(\\mathcal{M}\\) as \\[\\begin{equation*}\\label{eqn:eif} D(P_0)(x) = H(a, w)({y - \\overline{Q}(a, w)}) + \\overline{Q}(d(a, w), w) - \\Psi(P_0), \\end{equation*}\\] where the auxiliary covariate \\(H(a,w)\\) may be expressed \\[\\begin{equation*}\\label{eqn:aux_covar_full} H(a,w) = \\mathbb{I}(a + \\delta &lt; u(w)) \\frac{g_0(a - \\delta \\mid w)} {g_0(a \\mid w)} + \\mathbb{I}(a + \\delta \\geq u(w)), \\end{equation*}\\] which may be reduced to \\[\\begin{equation*}\\label{eqn:aux_covar_simple} H(a,w) = \\frac{g_0(a - \\delta \\mid w)}{g_0(a \\mid w)} + 1 \\end{equation*}\\] in the case that the treatment is in the limits that arise from conditioning on \\(W\\), i.e., for \\(A_i \\in (u(w) - \\delta, u(w))\\). Using the efficient influence function, a few different varieties of semiparametric-efficient estimators may be constructed. In the sequel, we focus on a targeted maximum likelihood (TML) estimator, for which Díaz and van der Laan (2018) give a recipe: Construct initial estimators \\(g_n\\) of \\(g_0(A, W)\\) and \\(Q_n\\) of \\(\\overline{Q}_0(A, W)\\), perhaps using data-adaptive regression techniques. For each observation \\(i\\), compute an estimate \\(H_n(a_i, w_i)\\) of the auxiliary covariate \\(H(a_i,w_i)\\). Estimate the parameter \\(\\epsilon\\) in the logistic regression model \\[ \\text{logit}\\overline{Q}_{\\epsilon, n}(a, w) = \\text{logit}\\overline{Q}_n(a, w) + \\epsilon H_n(a, w),\\] or an alternative regression model incorporating weights. Compute TML estimator \\(\\Psi_n\\) of the target parameter, defining update \\(\\overline{Q}_n^{\\star}\\) of the initial estimate \\(\\overline{Q}_{n, \\epsilon_n}\\): \\[\\begin{equation*}\\label{eqn:tmle} \\Psi_n = \\Psi(P_n^{\\star}) = \\frac{1}{n} \\sum_{i = 1}^n \\overline{Q}_n^{\\star}(d(A_i, W_i), W_i). \\end{equation*}\\] 5.5 Interpreting the Causal Effect of a Stochastic Intervention Figure 5.1: Animation of how a counterfactual outcome changes as the natural treatment distribution is subjected to a simple stochastic intervention 5.6 Evaluating the Causal Effect of a Stochastic Intervention To start, let us load the packages we will use and set a seed for simulation: library(tidyverse) library(data.table) library(condensier) library(sl3) library(tmle3) library(tmle3shift) set.seed(429153) We need to estimate two components of the likelihood in order to construct a TML estimator. The first of these components is the outcome regression, \\(\\hat{Q}_n\\), which is a simple regression of the form \\(\\mathbb{E}[Y \\mid A,W]\\). An estimate for such a quantity may be constructed using the Super Learner algorithm. We construct the components of an sl3-style Super Learner for a regression below, using a small variety of parametric and nonparametric regression techniques: # learners used for conditional expectation regression lrn_mean &lt;- Lrnr_mean$new() lrn_fglm &lt;- Lrnr_glm_fast$new() lrn_xgb &lt;- Lrnr_xgboost$new(nrounds=200) lrn_hal &lt;- Lrnr_hal9001$new() sl_lrn &lt;- Lrnr_sl$new( learners = list(lrn_mean, lrn_fglm), #, lrn_xgb, lrn_hal), metalearner = Lrnr_nnls$new() ) The second of these is an estimate of the treatment mechanism, \\(\\hat{g}_n\\), i.e., the propensity score. In the case of a continuous intervention node \\(A\\), such a quantity takes the form \\(p(A \\mid W)\\), which is a conditional density. Generally speaking, conditional density estimation is a challenging problem that has received much attention in the literature. To perform conditional density estimation, we focus on an approach advocated by Díaz and van der Laan (2011), in which arbitrary regression functions may be used to generate conditional density estimates based on a hazard-based approach. A Super Learner may be constructed by pooling estimates from each of these modified conditional density regression techniques. # learners used for conditional density regression lrn_mean_dens &lt;- Lrnr_condensier$new( nbins = 20, bin_estimator = lrn_mean, bin_method = &quot;dhist&quot; ) lrn_fglm_dens &lt;- Lrnr_condensier$new( nbins = 10, bin_estimator = lrn_fglm, bin_method = &quot;dhist&quot; ) lrn_xgb_dens &lt;- Lrnr_condensier$new( nbins = 5, bin_estimator = lrn_xgb, bin_method = &quot;dhist&quot; ) sl_lrn_dens &lt;- Lrnr_sl$new( learners = list(lrn_mean_dens, lrn_fglm_dens, lrn_xgb_dens), metalearner = Lrnr_solnp_density$new() ) # specify outcome and treatment regressions and create learner list Q_learner &lt;- sl_lrn g_learner &lt;- sl_lrn_dens learner_list &lt;- list(Y = Q_learner, A = g_learner) The learner_list object above specifies the role that each of the ensemble learners we have generated is to play in computing initial estimators to be used in building a TMLE for the parameter of interest here. In particular, it makes explicit the fact that our Q_learner is used in fitting the outcome regression while our g_learner is used in estimating the treatment mechanism. 5.6.1 Simulate Data # simulate simple data for tmle-shift sketch n_obs &lt;- 1000 # number of observations tx_mult &lt;- 2 # multiplier for the effect of W = 1 on the treatment ## baseline covariates -- simple, binary W &lt;- replicate(2, rbinom(n_obs, 1, 0.5)) ## create treatment based on baseline W A &lt;- rnorm(n_obs, mean = tx_mult * W, sd = 1) ## create outcome as a linear function of A, W + white noise Y &lt;- rbinom(n_obs, 1, prob = plogis(A + W)) # organize data and nodes for tmle3 data &lt;- data.table(W, A, Y) setnames(data, c(&quot;W1&quot;, &quot;W2&quot;, &quot;A&quot;, &quot;Y&quot;)) node_list &lt;- list(W = c(&quot;W1&quot;, &quot;W2&quot;), A = &quot;A&quot;, Y = &quot;Y&quot;) head(data) W1 W2 A Y 1: 1 1 3.5806529 1 2: 1 0 3.2071846 1 3: 1 1 1.0358382 1 4: 0 0 -0.6578495 1 5: 1 1 3.0199033 1 6: 1 1 2.7803127 1 The above composes our observed data structure \\(O = (W, A, Y)\\). To formally express this fact using the tlverse grammar introduced by the tmle3 package, we create a single data object and specify the functional relationships between the nodes in the directed acyclic graph (DAG) via nonparametric structural equation models (NPSEMs), reflected in the node list that we set up: We now have an observed data structure (data) and a specification of the role that each variable in the data set plays as the nodes in a DAG. To start, we will initialize a specification for the TMLE of our parameter of interest (called a tmle3_Spec in the tlverse nomenclature) simply by calling tmle_shift. We specify the argument shift_val = 0.5 when initializing the tmle3_Spec object to communicate that we’re interested in a shift of \\(0.5\\) on the scale of the treatment \\(A\\) – that is, we specify \\(\\delta = 0.5\\) (note that this is an arbitrarily chosen value for this example). # initialize a tmle specification tmle_spec &lt;- tmle_shift(shift_val = 0.5, shift_fxn = shift_additive_bounded, shift_fxn_inv = shift_additive_bounded_inv) As seen above, the tmle_shift specification object (like all tmle3_Spec objects) does not store the data for our specific analysis of interest. Later, we’ll see that passing a data object directly to the tmle3 wrapper function, alongside the instantiated tmle_spec, will serve to construct a tmle3_Task object internally (see the tmle3 documentation for details). 5.6.2 Targeted Estimation of Stochastic Interventions Effects tmle_fit &lt;- tmle3(tmle_spec, data, node_list, learner_list) Iter: 1 fn: 1845.0103 Pars: 0.9513029795 0.0486969185 0.0000001021 Iter: 2 fn: 1845.0103 Pars: 0.95130300211 0.04869694590 0.00000005199 solnp--&gt; Completed in 2 iterations tmle_fit A tmle3_Fit that took 1 step(s) type param init_est tmle_est se lower upper 1: TSM E[Y_{A=NULL}] 0.7977323 0.7948962 0.01189624 0.77158 0.8182124 psi_transformed lower_transformed upper_transformed 1: 0.7948962 0.77158 0.8182124 The print method of the resultant tmle_fit object conveniently displays the results from computing our TML estimator. 5.6.3 Statistical Inference for Targeted Maximum Likelihood Estimates Recall that the asymptotic distribution of TML estimators has been studied thoroughly: \\[\\psi_n - \\psi_0 = (P_n - P_0) \\cdot D(\\bar{Q}_n^*, g_n) + R(\\hat{P}^*, P_0),\\] which, provided the following two conditions: If \\(D(\\bar{Q}_n^*, g_n)\\) converges to \\(D(P_0)\\) in \\(L_2(P_0)\\) norm, and the size of the class of functions considered for estimation of \\(\\bar{Q}_n^*\\) and \\(g_n\\) is bounded (technically, \\(\\exists \\mathcal{F}\\) st \\(D(\\bar{Q}_n^*, g_n) \\in \\mathcal{F}\\) whp, where \\(\\mathcal{F}\\) is a Donsker class), readily admits the conclusion that \\(\\psi_n - \\psi_0 = (P_n - P_0) \\cdot D(P_0) + R(\\hat{P}^*, P_0)\\). Under the additional condition that the remainder term \\(R(\\hat{P}^*, P_0)\\) decays as \\(o_P \\left( \\frac{1}{\\sqrt{n}} \\right),\\) we have that \\[\\psi_n - \\psi_0 = (P_n - P_0) \\cdot D(P_0) + o_P \\left( \\frac{1}{\\sqrt{n}} \\right),\\] which, by a central limit theorem, establishes a Gaussian limiting distribution for the estimator: \\[\\sqrt{n}(\\psi_n - \\psi) \\to N(0, V(D(P_0))),\\] where \\(V(D(P_0))\\) is the variance of the efficient influence curve (canonical gradient) when \\(\\psi\\) admits an asymptotically linear representation. The above implies that \\(\\psi_n\\) is a \\(\\sqrt{n}\\)-consistent estimator of \\(\\psi\\), that it is asymptotically normal (as given above), and that it is locally efficient. This allows us to build Wald-type confidence intervals in a straightforward manner: \\[\\psi_n \\pm z_{\\alpha} \\cdot \\frac{\\sigma_n}{\\sqrt{n}},\\] where \\(\\sigma_n^2\\) is an estimator of \\(V(D(P_0))\\). The estimator \\(\\sigma_n^2\\) may be obtained using the bootstrap or computed directly via the following \\[\\sigma_n^2 = \\frac{1}{n} \\sum_{i = 1}^{n} D^2(\\bar{Q}_n^*, g_n)(O_i)\\] Having now re-examined these facts, let’s simply examine the results of computing our TML estimator: 5.7 Extensions: Variable Importance Analysis with Stochastic Interventions 5.7.1 Defining a grid of counterfactual interventions In order to specify a grid of shifts \\(\\delta\\) to be used in defining a set of stochastic intervention policies in an a priori manner, let us consider an arbitrary scalar \\(\\delta\\) that defines a counterfactual outcome \\(\\psi_n = Q_n(d(A, W), W)\\), where, for simplicity, let \\(d(A, W) = A + \\delta\\). A simplified expression of the auxiliary covariate for the TMLE of \\(\\psi\\) is \\(H_n = \\frac{g^*(a \\mid w)}{g(a \\mid w)}\\), where \\(g^*(a \\mid w)\\) defines the treatment mechanism with the stochastic intervention implemented. Then, to ascertain whether a given choice of the shift \\(\\delta\\) is admissable (in the sense of avoiding violations of the positivity assumption), let there be a bound \\(C(\\delta) = \\frac{g^*(a \\mid w)}{g(a \\mid w)} &lt; M\\), where \\(g^*(a \\mid w)\\) is a function of \\(\\delta\\) in part, and \\(M\\) is a potentially user-specified upper bound of \\(C(\\delta)\\). Then, \\(C(\\delta)\\) is a measure of the influence of a given observation (under a bound of the conditional densities), which provides a way to limit the maximum influence of a given observation through a choice of the shift \\(\\delta\\). We formalize and extend the procedure to determine an acceptable set of values for the shift \\(\\delta\\) in the sequel. Specifically, let there be a shift \\(d(A, W) = A + \\delta(A, W)\\), where the shift \\(\\delta(A, W)\\) is defined as \\[\\begin{equation} \\delta(a, w) = \\begin{cases} \\delta, &amp; \\delta_{\\text{min}}(a,w) \\leq \\delta \\leq \\delta_{\\text{max}}(a,w) \\\\ \\delta_{\\text{max}}(a,w), &amp; \\delta \\geq \\delta_{\\text{max}}(a,w) \\\\ \\delta_{\\text{min}}(a,w), &amp; \\delta \\leq \\delta_{\\text{min}}(a,w) \\\\ \\end{cases}, \\end{equation}\\] where \\[\\delta_{\\text{max}}(a, w) = \\text{argmax}_{\\left\\{\\delta \\geq 0, \\frac{g(a - \\delta \\mid w)}{g(a \\mid w)} \\leq M \\right\\}} \\frac{g(a - \\delta \\mid w)}{g(a \\mid w)}\\] and \\[\\delta_{\\text{min}}(a, w) = \\text{argmin}_{\\left\\{\\delta \\leq 0, \\frac{g(a - \\delta \\mid w)}{g(a \\mid w)} \\leq M \\right\\}} \\frac{g(a - \\delta \\mid w)}{g(a \\mid w)}.\\] The above provides a strategy for implementing a shift at the level of a given observation \\((a_i, w_i)\\), thereby allowing for all observations to be shifted to an appropriate value – whether \\(\\delta_{\\text{min}}\\), \\(\\delta\\), or \\(\\delta_{\\text{max}}\\). 5.7.2 Initializing vimshift through its tmle3_Spec To start, we will initialize a specification for the TMLE of our parameter of interest (called a tmle3_Spec in the tlverse nomenclature) simply by calling tmle_shift. We specify the argument shift_grid = seq(-1, 1, by = 1) when initializing the tmle3_Spec object to communicate that we’re interested in assessing the mean counterfactual outcome over a grid of shifts -1, 0, 1 on the scale of the treatment \\(A\\) (note that the numerical choice of shift is an arbitrarily chosen set of values for this example). # what&#39;s the grid of shifts we wish to consider? delta_grid &lt;- seq(-1, 1, 1) # initialize a tmle specification tmle_spec &lt;- tmle_vimshift_delta(shift_grid = delta_grid, max_shifted_ratio = 2) As seen above, the tmle_vimshift specification object (like all tmle3_Spec objects) does not store the data for our specific analysis of interest. Later, we’ll see that passing a data object directly to the tmle3 wrapper function, alongside the instantiated tmle_spec, will serve to construct a tmle3_Task object internally (see the tmle3 documentation for details). 5.7.3 Targeted Estimation of Stochastic Interventions Effects One may walk through the step-by-step procedure for fitting the TML estimator of the mean counterfactual outcome under each shift in the grid, using the machinery exposed by the tmle3 R package. One may invoke the tmle3 wrapper function (a user-facing convenience utility) to fit the series of TML estimators (one for each parameter defined by the grid delta) in a single function call: tmle_fit &lt;- tmle3(tmle_spec, data, node_list, learner_list) Iter: 1 fn: 1844.2284 Pars: 0.96656215268 0.03343778776 0.00000005682 Iter: 2 fn: 1844.2284 Pars: 0.966562195572 0.033437800382 0.000000004046 solnp--&gt; Completed in 2 iterations tmle_fit A tmle3_Fit that took 1 step(s) type param init_est tmle_est se lower 1: TSM E[Y_{A=NULL}] 0.6128936 0.6140405 0.015480054 0.5837001 2: TSM E[Y_{A=NULL}] 0.7389799 0.7390000 0.013895038 0.7117662 3: TSM E[Y_{A=NULL}] 0.8489649 0.8503043 0.009667032 0.8313573 4: MSM_linear MSM(intercept) 0.7333938 0.7342298 0.012575015 0.7095832 5: MSM_linear MSM(slope) 0.1168980 0.1172290 0.004747348 0.1079244 upper psi_transformed lower_transformed upper_transformed 1: 0.6443808 0.6140405 0.5837001 0.6443808 2: 0.7662338 0.7390000 0.7117662 0.7662338 3: 0.8692513 0.8503043 0.8313573 0.8692513 4: 0.7588763 0.7342298 0.7095832 0.7588763 5: 0.1265336 0.1172290 0.1079244 0.1265336 Remark: The print method of the resultant tmle_fit object conveniently displays the results from computing our TML estimator. 5.7.4 Inference with Marginal Structural Models In the directly preceding section, we consider estimating the mean counterfactual outcome \\(\\psi_n\\) under several values of the intervention \\(\\delta\\), taken from the aforementioned \\(\\delta\\)-grid. We now turn our attention to an approach for obtaining inference on a single summary measure of these estimated quantities. In particular, we propose summarizing the estimates \\(\\psi_n\\) through a marginal structural model (MSM), obtaining inference by way of a hypothesis test on a parameter of this working MSM. For a data structure \\(O = (W, A, Y)\\), let \\(\\psi_{\\delta}(P_0)\\) be the mean outcome under a shift \\(\\delta\\) of the treatment, so that we have \\(\\vec{\\psi}_{\\delta} = (\\psi_{\\delta}: \\delta)\\) with corresponding estimators \\(\\vec{\\psi}_{n, \\delta} = (\\psi_{n, \\delta}: \\delta)\\). Further, let \\(\\beta(\\vec{\\psi}_{\\delta}) = \\phi((\\psi_{\\delta}: \\delta))\\). For a given MSM \\(m_{\\beta}(\\delta)\\), we have that \\[\\beta_0 = \\text{argmin}_{\\beta} \\sum_{\\delta}(\\psi_{\\delta}(P_0) - m_{\\beta}(\\delta))^2 h(\\delta),\\] which is the solution to \\[u(\\beta, (\\psi_{\\delta}: \\delta)) = \\sum_{\\delta}h(\\delta) \\left(\\psi_{\\delta}(P_0) - m_{\\beta}(\\delta) \\right) \\frac{d}{d\\beta} m_{\\beta}(\\delta) = 0.\\] This then leads to the following expansion \\[\\beta(\\vec{\\psi}_n) - \\beta(\\vec{\\psi}_0) \\approx -\\frac{d}{d\\beta} u(\\beta_0, \\vec{\\psi}_0)^{-1} \\frac{d}{d\\psi} u(\\beta_0, \\psi_0)(\\vec{\\psi}_n - \\vec{\\psi}_0),\\] where we have \\[\\frac{d}{d\\beta} u(\\beta, \\psi) = -\\sum_{\\delta} h(\\delta) \\frac{d}{d\\beta} m_{\\beta}(\\delta)^t \\frac{d}{d\\beta} m_{\\beta}(\\delta) -\\sum_{\\delta} h(\\delta) m_{\\beta}(\\delta) \\frac{d^2}{d\\beta^2} m_{\\beta}(\\delta),\\] which, in the case of an MSM that is a linear model (since \\(\\frac{d^2}{d\\beta^2} m_{\\beta}(\\delta) = 0\\)), reduces simply to \\[\\frac{d}{d\\beta} u(\\beta, \\psi) = -\\sum_{\\delta} h(\\delta) \\frac{d}{d\\beta} m_{\\beta}(\\delta)^t \\frac{d}{d\\beta} m_{\\beta}(\\delta),\\] and \\[\\frac{d}{d\\psi}u(\\beta, \\psi)(\\psi_n - \\psi_0) = \\sum_{\\delta} h(\\delta) \\frac{d}{d\\beta} m_{\\beta}(\\delta) (\\psi_n - \\psi_0)(\\delta),\\] which we may write in terms of the efficient influence function (EIF) of \\(\\psi\\) by using the first order approximation \\((\\psi_n - \\psi_0)(\\delta) = \\frac{1}{n}\\sum_{i = 1}^n \\text{EIF}_{\\psi_{\\delta}}(O_i)\\), where \\(\\text{EIF}_{\\psi_{\\delta}}\\) is the efficient influence function (EIF) of \\(\\vec{\\psi}\\). Now, say, \\(\\vec{\\psi} = (\\psi(\\delta): \\delta)\\) is d-dimensional, then we may write the efficient influence function of the MSM parameter \\(\\beta\\) (assuming a linear MSM) as follows \\[\\text{EIF}_{\\beta}(O) = \\left(\\sum_{\\delta} h(\\delta) \\frac{d}{d\\beta} m_{\\beta}(\\delta) \\frac{d}{d\\beta} m_{\\beta}(\\delta)^t \\right)^{-1} \\cdot \\sum_{\\delta} h(\\delta) \\frac{d}{d\\beta} m_{\\beta}(\\delta) \\text{EIF}_{\\psi_{\\delta}}(O),\\] where the first term is of dimension \\(d \\times d\\) and the second term is of dimension \\(d \\times 1\\). In an effort to generalize still further, consider the case where \\(\\psi_{\\delta}(P_0) \\in (0, 1)\\) – that is, \\(\\psi_{\\delta}(P_0)\\) corresponds to the probability of some event of interest. In such a case, it would be more natural to consider a logistic MSM \\[m_{\\beta}(\\delta) = \\frac{1}{1 + \\exp(-f_{\\beta}(\\delta))},\\] where \\(f_{\\beta}\\) is taken to be linear in \\(\\beta\\) (e.g., \\(f_{\\beta} = \\beta_0 + \\beta_1 \\delta + \\ldots\\)). In such a case, we have the parameter of interest \\[\\beta_0 = \\text{argmax}_{\\beta} \\sum_{\\delta} \\left(\\psi_{\\delta}(P_0) \\text{log} m_{\\beta}(\\delta) + (1 - \\psi_{\\delta}(P_0))\\log(1 - m_{\\beta}(\\delta))\\right)h(\\delta),\\] where \\(\\beta_0\\) solves the following \\[ \\sum_{\\delta} h(\\delta) \\frac{d}{d\\beta} f_{\\beta}(\\delta) (\\psi_{\\delta}(P_0) - m_{\\beta}(\\delta)) = 0.\\] Inference from a working MSM is rather straightforward. To wit, the limiting distribution for \\(m_{\\beta}(\\delta)\\) may be expressed \\[\\sqrt{n}(\\beta_n - \\beta_0) \\to N(0, \\Sigma),\\] where \\(\\Sigma\\) is the empirical covariance matrix of \\(\\text{EIF}_{\\beta}(O)\\). tmle_fit$summary[4:5, ] type param init_est tmle_est se lower 1: MSM_linear MSM(intercept) 0.7333938 0.7342298 0.012575015 0.7095832 2: MSM_linear MSM(slope) 0.1168980 0.1172290 0.004747348 0.1079244 upper psi_transformed lower_transformed upper_transformed 1: 0.7588763 0.7342298 0.7095832 0.7588763 2: 0.1265336 0.1172290 0.1079244 0.1265336 5.7.4.1 Directly Targeting the MSM Parameter \\(\\beta\\) Note that in the above, a working MSM is fit to the individual TML estimates of the mean counterfactual outcome under a given value of the shift \\(\\delta\\) in the supplied grid. The parameter of interest \\(\\beta\\) of the MSM is asymptotically linear (and, in fact, a TML estimator) as a consequence of its construction from individual TML estimators. In smaller samples, it may be prudent to perform a TML estimation procedure that targets the parameter \\(\\beta\\) directly, as opposed to constructing it from several independently targeted TML estimates. An approach for constructing such an estimator is proposed in the sequel. Suppose a simple working MSM \\(\\mathbb{E}Y_{g^0_{\\delta}} = \\beta_0 + \\beta_1 \\delta\\), then a TML estimator targeting \\(\\beta_0\\) and \\(\\beta_1\\) may be constructed as \\[\\overline{Q}_{n, \\epsilon}(A,W) = \\overline{Q}_n(A,W) + \\epsilon (H_1(g), H_2(g),\\] for all \\(\\delta\\), where \\(H_1(g)\\) is the auxiliary covariate for \\(\\beta_0\\) and \\(H_2(g)\\) is the auxiliary covariate for \\(\\beta_1\\). To construct a targeted maximum likelihood estimator that directly targets the parameters of the working marginal structural model, we may use the tmle_vimshift_msm Spec (instead of the tmle_vimshift_delta Spec that appears above): # initialize a tmle specification tmle_msm_spec &lt;- tmle_vimshift_msm(shift_grid = delta_grid, max_shifted_ratio = 2) # fit the TML estimator and examine the results tmle_msm_fit &lt;- tmle3(tmle_msm_spec, data, node_list, learner_list) Iter: 1 fn: 1838.4669 Pars: 0.96061554500 0.03938437967 0.00000007423 Iter: 2 fn: 1838.4668 Pars: 0.960615569450 0.039384428822 0.000000001728 solnp--&gt; Completed in 2 iterations tmle_msm_fit A tmle3_Fit that took 100 step(s) type param init_est tmle_est se lower 1: MSM_linear MSM(intercept) 0.7331698 0.7331698 0.012688524 0.7083008 2: MSM_linear MSM(slope) 0.1167444 0.1167444 0.004823533 0.1072904 upper psi_transformed lower_transformed upper_transformed 1: 0.7580389 0.7331698 0.7083008 0.7580389 2: 0.1261983 0.1167444 0.1072904 0.1261983 5.8 Exercises 5.8.1 Basics/Review TODO Set the sl3 library of algorithms for the Super Learner TODO Describe two (equivalent) ways in which the causal effects of stochastic interventions may be interpreted. 5.8.2 Using the Ideas Choose a different variable of interest (e.g., TBD) and repeat the initial analysis we performed. That is, estimate the counterfactual mean under a shift of the new variable, after standardizing the chosen variable to have zero mean and unit variance. TODO TODO What advantages, if any, are there to targeted directly the parameters of a marginal structural model? 5.8.3 Advanced How does the marginal structural model we used to summarize… TODO References "],
["references.html", "References", " References "]
]
