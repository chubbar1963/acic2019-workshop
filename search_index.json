[
["index.html", "The tlverse Software Ecosystem for Causal Inference 2019 Atlantic Causal Inference Conference Preface About this workshop Outline About the instructors 0.1 Important links 0.2 Setup instructions", " The tlverse Software Ecosystem for Causal Inference 2019 Atlantic Causal Inference Conference Mark van der Laan, Alan Hubbard, Jeremy Coyle, Nima Hejazi, Ivana Malenica, Rachael Phillips updated: May 06, 2019 Preface This is an open source and fully-reproducible electronic handbook accompanying a full-day short-course on applying the targeted learning methodology in practice using the tlverse software ecosystem, given at the 2019 Atlantic Causal Inference Conference in Montréal, Québec, Canada on 22 May 2019. About this workshop This full-day workshop will provide a comprehensive introduction to the field of targeted learning for causal inference and the corresponding tlverse software ecosystem. In particular, we will focus on targeted minimum loss-based estimators of causal effects, including those of static, dynamic, optimal dynamic, and stochastic interventions. These multiply robust, efficient plug-in estimators use state-of-the-art, ensemble machine learning tools to flexibly adjust for confounding while yielding valid tatistical inference. We will discuss the utility of this robust estimation strategy in comparison to conventional techniques, which often rely on restrictive statistical models and may therefore lead to severely biased inference. In addition to discussion, this workshop will incorporate both interactive activities and hands-on, guided R programming exercises, to allow participants the opportunity to familiarize themselves with methodology and tools that will translate to real-world causal inference analyses. It is highly recommended for participants to have an understanding of basic statistical concepts such as confounding, probability distributions, confidence intervals, hypothesis tests, and regression. Advanced knowledge of mathematical statistics may be useful but is not necessary. Familiarity with the R programming language will be essential. Outline This is a full-day (6-hour) workshop, featuring modules that introduce distinct causal questions, each motivated by a case study, alongside statistical methodology and software for assessing the causal claim of interest. A sample schedule may take the form: 09:30AM–09:45AM: Why we need a statistical revolution 09:45AM–10:15AM: The Roadmap, and the WASH Benefits data 10:15AM–10:30AM: Introduction to the tlverse software ecosystem 10:30AM–10:45AM: Morning break 10:45AM–11:45AM: Super (machine) learning with the sl3 package 11:45AM–12:30PM: Targeted learning for causal inference with the tmle3 package 12:30PM–1:30PM: Lunch break 01:30PM–02:45PM: Optimal treatment regimes and the tmle3mopttx package 02:45PM–03:00PM: Afternoon break 3:00PM–4:00PM: Stochastic treatment regimes and the tmle3shift package 04:00PM–4:30PM: Coda: Why we need a statistical revolution About the instructors Mark van der Laan Mark van der Laan, Ph.D., is Professor of Biostatistics and Statistics at UC Berkeley. His research interests include statistical methods in computational biology, survival analysis, censored data, adaptive designs, targeted maximum likelihood estimation, causal inference, data-adaptive loss-based learning, and multiple testing. His research group developed loss-based super learning in semiparametric models, based on cross-validation, as a generic optimal tool for the estimation of infinite-dimensional parameters, such as nonparametric density estimation and prediction with both censored and uncensored data. Building on this work, his research group developed targeted maximum likelihood estimation for a target parameter of the data-generating distribution in arbitrary semiparametric and nonparametric models, as a generic optimal methodology for statistical and causal inference. Most recently, Mark’s group has focused in part on the development of a centralized, principled set of software tools for targeted learning, the tlverse. For more information, see https://vanderlaan-lab.org. Alan Hubbard Alan Hubbard, Ph.D., is Professor of Biostatistics, former head of the Division of Biostatistics at UC Berkeley, and head of data analytics core at UC Berkeley’s SuperFund research program. His current research interests include causal inference, variable importance analysis, statistical machine learning, estimation of and inference for data-adaptive statistical target parameters, and targeted minimum loss-based estimation. Research in his group is generally motivated by applications to problems in computational biology, epidemiology, and precision medicine. Jeremy Coyle Jeremy Coyle, Ph.D., is a consulting data scientist and statistical programmer, currently leading the software development effort that has produced the tlverse ecosystem of R packages and related software tools. Jeremy earned his Ph.D. in Biostatistics from UC Berkeley in 2016, primarily under the supervision of Alan Hubbard. Nima Hejazi Nima is a Ph.D. candidate in biostatistics with a designated emphasis in computational and genomic biology, working jointly with Mark van der Laan and Alan Hubbard. Nima is affiliated with UC Berkeley’s Center for Computational Biology and NIH Biomedical Big Data training program. His research interests span causal inference, nonparametric inference and machine learning, targeted loss-based estimation, survival analysis, statistical computing, reproducible research, and high-dimensional biology. He is also passionate about software development for applied statistics, including software design, automated testing, and reproducible coding practices. For more information, see https://nimahejazi.org. Ivana Malenica Ivana is a Ph.D. student in biostatistics advised by Mark van der Laan. Ivana is currently a fellow at the Berkeley Institute for Data Science, after serving as a NIH Biomedical Big Data and Freeport-McMoRan Genomic Engine fellow. She earned her Master’s in Biostatistics and Bachelor’s in Mathematics, and spent some time at the Translational Genomics Research Institute. Very broadly, her research interests span non/semi-parametric theory, probability theory, machine learning, causal inference and high-dimensional statistics. Most of her current work involves complex dependent settings (dependence through time and network) and adaptive sequential designs. Rachael Phillips Rachael is a Ph.D. student in biostatistics, advised by Alan Hubbard and Mark van der Laan. She has an M.A. in Biostatistics, B.S. in Biology with a Chemistry minor and a B.A. in Mathematics with a Spanish minor. Rachael is motivated to solve real-world, high-dimensional problems in human health. Her research interests span causal inference, machine learning, nonparametric statistical estimation, and finite sample inference. She is also passionate about online mediated education. Rachael is affiliated with the UC Berkeley Center for Computational Biology, NIH Biomedical Big Data Training Program, and Superfund Research Program. 0.1 Important links Feedback forms These are generic Google Forms that we’ll use to get immediate feedback throughout the course. multiple choice question general feedback Workshop surveys These pre- and post-workshop surveys help us ensure the effectiveness of our teaching methodology. pre-workshop survey post-workshop survey 0.2 Setup instructions 0.2.1 R and RStudio R and RStudio are separate downloads and installations. R is the underlying statistical computing environment. RStudio is a graphical integrated development environment (IDE) that makes using R much easier and more interactive. You need to install R before you install RStudio. 0.2.1.1 Windows 0.2.1.1.1 If you already have R and RStudio installed Open RStudio, and click on “Help” &gt; “Check for updates”. If a new version is available, quit RStudio, and download the latest version for RStudio. To check which version of R you are using, start RStudio and the first thing that appears in the console indicates the version of R you are running. Alternatively, you can type sessionInfo(), which will also display which version of R you are running. Go on the CRAN website and check whether a more recent version is available. If so, please download and install it. You can check here for more information on how to remove old versions from your system if you wish to do so. 0.2.1.1.2 If you don’t have R and RStudio installed Download R from the CRAN website. Run the .exe file that was just downloaded Go to the RStudio download page Under Installers select RStudio x.yy.zzz - Windows XP/Vista/7/8 (where x, y, and z represent version numbers) Double click the file to install it Once it’s installed, open RStudio to make sure it works and you don’t get any error messages. 0.2.1.2 macOS 0.2.1.2.1 If you already have R and RStudio installed Open RStudio, and click on “Help” &gt; “Check for updates”. If a new version is available, quit RStudio, and download the latest version for RStudio. To check the version of R you are using, start RStudio and the first thing that appears on the terminal indicates the version of R you are running. Alternatively, you can type sessionInfo(), which will also display which version of R you are running. Go on the CRAN website and check whether a more recent version is available. If so, please download and install it. 0.2.1.2.2 If you don’t have R and RStudio installed Download R from the CRAN website. Select the .pkg file for the latest R version Double click on the downloaded file to install R It is also a good idea to install XQuartz (needed by some packages) Go to the RStudio download page Under Installers select RStudio x.yy.zzz - Mac OS X 10.6+ (64-bit) (where x, y, and z represent version numbers) Double click the file to install RStudio Once it’s installed, open RStudio to make sure it works and you don’t get any error messages. 0.2.1.3 Linux Follow the instructions for your distribution from CRAN, they provide information to get the most recent version of R for common distributions. For most distributions, you could use your package manager (e.g., for Debian/Ubuntu run sudo apt-get install r-base, and for Fedora sudo yum install R), but we don’t recommend this approach as the versions provided by this are usually out of date. In any case, make sure you have at least R 3.3.1. Go to the RStudio download page Under Installers select the version that matches your distribution, and install it with your preferred method (e.g., with Debian/Ubuntu sudo dpkg -i rstudio-x.yy.zzz-amd64.deb at the terminal). Once it’s installed, open RStudio to make sure it works and you don’t get any error messages. These setup instructions are adapted from those written for Data Carpentry: R for Data Analysis and Visualization of Ecological Data. "],
["motivation.html", "Motivation", " Motivation “One enemy of robust science is our humanity — our appetite for being right, and our tendency to find patterns in noise, to see supporting evidence for what we already believe is true, and to ignore the facts that do not fit.” — (“Let’s Think About Cognitive Bias” 2015). Scientific research is at a unique point in history. The need to improve rigor and reproducibility in our field is greater than ever; corroboration moves science forward, yet there is a growing alarm about results that cannot be reproduced and that report false discoveries Baker (2016). Consequences of not meeting this need will result in further decline in the rate of scientific progression, the reputation of the sciences, and the public’s trust in its findings Munafò et al. (2017) (“How Scientists Fool Themselves – and How They Can Stop” 2015). “The key question we want to answer when seeing the results of any scientific study is whether we can trust the data analysis.” — Peng (2015) Unfortunately, at its current state the culture of data analysis and statistics actually enables human bias through improper model selection. All hypothesis tests and estimators are derived from statistical models, so to obtain valid estimates and inference it is critical that statistical model contains the process that generated the data. Perhaps treatment was randomized or only depended on a small number of baseline covariates; this knowledge should and can be incorporated in the model. Alternatively, maybe the data is observational, and there is no knowledge about the data-generating process (DGP). If this is the case, then the statistical model should contain all data distributions. In practice; however, models are not selected based on knowledge of the DGP, instead models are often selected based on (1) the p-values they yield, (2) their convenience of implementation, and/or (3) an analysts loyalty to a particular model. This problem of ``cargo-cult statistics — the ritualistic miming of statistics rather than conscientious practice,’’ Stark and Saltelli (2018) allows one to make arbitrary modeling choices, even though these choices result in different answers to the same research question. This presents a fundamental drive behind the epidemic of false positives that scientific research is suffering from (???). “We suggest that the weak statistical understanding is probably due to inadequate “statistics lite” education. This approach does not build up appropriate mathematical fundamentals and does not provide scientifically rigorous introduction into statistics. Hence, students’ knowledge may remain imprecise, patchy, and prone to serious misunderstandings. What this approach achieves, however, is providing students with false confidence of being able to use inferential tools whereas they usually only interpret the p-value provided by black box statistical software. While this educational problem remains unaddressed, poor statistical practices will prevail regardless of what procedures and measures may be favored and/or banned by editorials.&quot; — Szucs and Ioannidis (2017) Our team at The University of California, Berkeley, is uniquely positioned to provide such an education. Spearheaded by Professor Mark van der Laan, and spreading rapidly by many of his students and colleagues who have greatly enriched the field, the aptly named “Targeted Learning” methodology targets the scientific question at hand and is counter to the current culture of “convenience statistics” which opens the door to biased estimation, misleading results, and false discoveries. Targeted Learning restores the fundamentals that formalized the field of statistics, such as the that facts that a statistical model represents real knowledge about the experiment that generated the data, and a target parameter represents what we are seeking to learn from the data as a feature of the distribution that generated it van der Laan and Starmans (2014). In this way, Targeted Learning defines a truth and establishes a principled standard for estimation, thereby inhibiting these all-too-human biases (e.g., hindsight bias, confirmation bias, and outcome bias) from infiltrating analysis. “The key for effective classical [statistical] inference is to have well-defined questions and an analysis plan that tests those questions.” — Nosek et al. (2018) The objective for this handbook is to provide training to students, researchers, industry professionals, faculty in science, public health, statistics, and other fields to empower them with the necessary knowledge and skills to utilize the sound methodology of Targeted Learning — a technique that provides tailored pre-specified machines for answering queries, so that each data analysis is completely reproducible, and estimators are efficient, minimally biased, and provide formal statistical inference. For a statistical methodology to be readily accessible in practice, it is crucial that it is accompanied by robust user-friendly software Pullenayegum et al. (2016) Stromberg and others (2004). The tlverse software ecosystem was developed to fulfill this need for the Targeted Learning methodology. Not only does this software facilitate computationally reproducible and efficient analyses, it is also a tool for Targeted Learning education since its workflow mirrors that of the methodology. In particular, the tlverse paradigm does not focus on implementing a specific estimator or a small set of related estimators. Instead, the focus is on exposing the statistical framework of Targeted Learning itself — all R packages in the tlverse ecosystem directly model the key objects defined in the mathematical and theoretical framework of Targeted Learning. What’s more, the tlverse R packages share a core set of design principles centered on extensibility, allowing for them to be used in conjunction with each other and built upon one other in a cohesive fashion. In this handbook, the reader will embark on a journey through the tlverse ecosystem. Guided by R programming exercises, case studies, and intuitive explanation readers will build a toolbox for applying the Targeted Learning statistical methodology, which will translate to real-world causal inference analyses. The reader need not be a fully trained statistician to begin understanding and applying these methods. However, it is highly recommended for the reader to have an understanding of basic statistical concepts such as confounding, probability distributions, confidence intervals, hypothesis tests, and regression. Advanced knowledge of mathematical statistics may be useful but is not necessary. Familiarity with the R programming language will be essential. We also recommend an understanding of introductory causal inference. Please see __ for introductory materials for learning the R programming language and __ for causal inference learning materials. References "],
["intro.html", "Chapter 1 Welcome to the tlverse 1.1 Learning Objectives 1.2 What is the tlverse? 1.3 tlverse components 1.4 Installation 1.5 The Targeted Learning Roadmap 1.6 The Parameter of Interest 1.7 The WASH Benefits Example Dataset", " Chapter 1 Welcome to the tlverse 1.1 Learning Objectives Understand the tlverse ecosystem conceptually Identify the core components of the tlverse Install tlverse R packages Understand the Targeted Learning roadmap Learn about the WASH Benefits example data 1.2 What is the tlverse? The tlverse is a new framework for doing Targeted Learning in R, inspired by the tidyverse ecosystem of R packages. By analogy to the tidyverse: The tidyverse is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures. So, the tlverse is an opinionated collection of R packages for Targeted Learning sharing an underlying philosophy, grammar, and set of data structures 1.3 tlverse components These are the main packages that represent the core of the tlverse: sl3: Modern Super Learning with Pipelines What? A modern object-oriented re-implementation of the Super Learner algorithm, employing recently developed paradigms for R programming. Why? A design that leverages modern tools for fast computation, is forward-looking, and can form one of the cornerstones of the tlverse. tmle3: An Engine for Targeted Learning What? A generalized framework that simplifies Targeted Learning by identifying and implementing a series of common statistical estimation procedures. Why? A common interface and engine that accommodates current algorithmic approaches to Targeted Learning and is still flexible enough to remain the engine even as new techniques are developed. In addition to the engines that drive development in the tlverse, there are some supporting packages – in particular, we have two… origami: A Generalized Framework for Cross-Validation What? A generalized framework for flexible cross-validation Why? Cross-validation is a key part of ensuring error estimates are honest and preventing overfitting. It is an essential part of the both the Super Learner algorithm and Targeted Learning. delayed: Parallelization Framework for Dependent Tasks What? A framework for delayed computations (futures) based on task dependencies. Why? Efficient allocation of compute resources is essential when deploying large-scale, computationally intensive algorithms. A key principle of the tlverse is extensibility. That is, we want to support new Targeted Learning estimators as they are developed. The model for this is new estimators are implemented in additional packages using the core packages above. There are currently two featured examples of this: tmle3mopttx: Optimal Treatments in tlverse What? Learn an optimal rule and estimate the mean outcome under the rule Why? Optimal Treatment is a powerful tool in precision healthcare and other settings where a one-size-fits-all treatment approach is not appropriate. tmle3shift: Shift Interventions in tlverse What? Shift interventions for continuous treatments Why? Not all treatment variables are discrete. Being able to estimate the effects of continuous treatment represents a powerful extension of the Targeted Learning approach. 1.4 Installation The tlverse ecosystem of packages are currently hosted at https://github.com/tlverse, not yet on CRAN. You can use the devtools package to install them: install.packages(&quot;devtools&quot;) devtools::install_github(&quot;tlverse/tlverse&quot;) The tlverse depends on a large number of other packages that are also hosted on GitHub. Because of this, you may see the following error: Error: HTTP error 403. API rate limit exceeded for 71.204.135.82. (But here&#39;s the good news: Authenticated requests get a higher rate limit. Check out the documentation for more details.) Rate limit remaining: 0/60 Rate limit reset at: 2019-03-04 19:39:05 UTC To increase your GitHub API rate limit - Use `usethis::browse_github_pat()` to create a Personal Access Token. - Use `usethis::edit_r_environ()` and add the token as `GITHUB_PAT`. This just means that R tried to install too many packages from GitHub in too short of a window. To fix this, you need to tell R how to use GitHub as your user (you’ll need a GitHub user account). Follow these two steps: Use usethis::browse_github_pat() to create a Personal Access Token. Use usethis::edit_r_environ() and add the token as GITHUB_PAT. 1.5 The Targeted Learning Roadmap A central goal of the Targeted Learning statistical paradigm is to estimate scientifically relevant parameters in realistic (usually nonparametric) models. 1.5.1 The Statistical Model For a given data set \\(O = (W, A, Y)\\), the distribution of the observed data may be written as follows: \\(P(O) = P(W, A, Y) = P(W)P (A \\mid W) P(Y \\mid A, W)\\). To estimate a parameter of interest, a researcher need not necessarily be able to specify these whole or conditional distributions. Rather, each estimator only requires that certain parts of the distribution be known; for example, some may require estimates of \\(\\mathbb{E}(Y \\mid A, W)\\), the mean of \\(Y\\) within subgroups \\((A, W)\\), or the regression of the outcome on the exposure and confounders. At this stage in the roadmap, the researcher must specify a choice of statistical model to be used in estimating \\(\\mathbb{E}(Y \\mid A, W)\\) or other elements of the probability distribution needed to estimate the parameter of interest. Here, statistical model means any constraints on the model form that may be imposed by knowledge about the data-generating process – that is, known aspects of how the data were generated. Typically, the true model is a very large model, placing few constraints, if any, on the data-generating distribution, or a semi-parametric model. With few constraints on the data-generating distribution, and a potentially large number of covariates, data-adaptive, machine-learning approaches remain the only practical option for estimating components of the likelihood. The remainder of this course concerns how to do this as efficiently and robustly as possible, depending on the goal of the analysis. 1.5.2 The Causal Model The next step in the roadmap is to use a causal framework to formalize the experiment and thereby define the parameter of interest. Causal graphs are one useful tool to express what we know about the causal relations among variables that are relevant to the question under study (Pearl 2009). While directed acyclic graphs (DAGs) provide a convenient means by which to visualize causal relations between variables, the same causal relations among variables can be represented via a set of structural equations: \\[\\begin{align*} W &amp;= f_W(U_W) \\\\ A &amp;= f_A(W, U_A) \\\\ Y &amp;= f_Y(W, A, U_Y), \\end{align*}\\] where \\(U_W\\), \\(U_A\\), and \\(U_Y\\) represent the unmeasured exogenous background characteristics that influence the value of each variable. In the NPSEM, \\(f_W\\), \\(f_A\\) and \\(f_Y\\) denote that each variable (for \\(W\\), \\(A\\) and \\(Y\\), respectively) is a function of its parents and unmeasured background characteristics, but note that there is no imposition of any particular functional constraints. For this reason, they are called non-parametric structural equation models (NPSEMs). The DAG and set of nonparametric structural equations represent exactly the same information and so may be used interchangeably. 1.6 The Parameter of Interest The first hypothetical experiment we will consider is assigning exposure to the whole population and observing the outcome, and then assigning no exposure to the whole population and observing the outcome. On the nonparametric structural equations, this corresponds to a comparison of the outcome distribution in the population under two interventions: \\(A\\) is set to \\(1\\) for all individuals, and \\(A\\) is set to \\(0\\) for all individuals. These interventions imply two new nonparametric structural equation models. For the case \\(A = 1\\), we have \\[\\begin{align*} W &amp;= f_W(U_W) \\\\ A &amp;= 1 \\\\ Y(1) &amp;= f_Y(W, 1, U_Y), \\end{align*}\\] and for the case \\(A=0\\), \\[\\begin{align*} W &amp;= f_W(U_W) \\\\ A &amp;= 0 \\\\ Y(1) &amp;= f_Y(W, 0, U_Y). \\end{align*}\\] In these equations, \\(A\\) is no longer a function of \\(W\\) because we have intervened on the system, setting \\(A\\) deterministically to either of the values \\(1\\) or \\(0\\). The new symbols \\(Y(1)\\) and \\(Y(0)\\) indicate the outcome variable in our population if it were generated by the respective NPSEMs above; these are often called counterfactuals. The difference between the means of the outcome under these two interventions defines a parameter that is often called the “average treatment effect” (ATE), denoted \\[\\begin{equation}\\label{eqn:ate} ATE = \\mathbb{E}_X(Y(1)-Y(0)), \\end{equation}\\] where \\(\\mathbb{E}_X\\) is the mean under the theoretical (unobserved) full data \\(X = (W, Y(1), Y(0))\\). 1.6.1 Identifiability Because we can never observe both \\(Y(0)\\) (the counterfactual outcome when \\(A=0\\)) and \\(Y(1)\\), we cannot estimate directly. Instead, we have to make assumptions under which this quantity may be estimated from the observed data \\(O \\sim P_0\\) under the data-generating distribution \\(P_0\\). Fortunately, given the causal model specified in the NPSEM above, we can, with a handful of untestable assumptions, estimate the ATE, even from observational data. These assumptions may be summarized as follows The causal graph implies \\(Y(a) \\perp A\\) for all \\(a \\in \\mathcal{A}\\), which is the randomization assumption. In the case of observational data, the analogous assumption is strong ignorability $\\(Y(a) \\perp A \\mid W\\) for all \\(a \\in \\mathcal{A}\\). Although not represented in the causal graph, also required is the assumption of no interference between units (that is, the \\(Y\\)’s are independent) It is also necessary that all observed units, across strata defined by \\(W\\), have a bounded (non-deterministic) probability of receiving treatment – that is, \\(0 &lt; P_0(A = a \\mid W) &lt; 1\\) for all \\(a\\) and \\(W\\)). This assumption is referred to as positivity. Given these assumptions, the ATE may be re-written as a function of \\(P_0\\), specifically \\[\\begin{equation}\\label{eqn:estimand} ATE = \\mathbb{E}_0(Y(1) - Y(0)) = \\mathbb{E}_0 \\left(\\mathbb{E}_0[Y \\mid A = 1, W] - \\mathbb{E}_0[Y \\mid A = 0, W]\\right), \\end{equation}\\] or the difference in the predicted outcome values for each subject, under the contrast of treatment conditions (\\(A = 0\\) vs. \\(A = 1\\)), in the population, averaged over all observations. Thus, a parameter of a theoretical “full” data distribution can be represented as an estimand of the observed data distribution. Significantly, there is nothing about the representation in that requires parameteric assumptions; thus, the regressions on the right hand side may be estimated freely with machine learning. With different parameters, there will be potentially different identifiability assumptions and the resulting estimands can be functions of different components of \\(P_0\\). We discuss several more complex estimands in later sections of this workshop. 1.6.2 Estimator Although we will discuss more in later sections, the goals of the estimators we desire should be that, among sensible (asymptotically consistent, regular) estimators, the estimator be asymptotically efficient in the statistical model of interest, and the estimator can be constructed for finite-sample performance improvements, relative to other estimators in the same class. 1.6.3 Inference The estimators we discuss are asymptotically linear, meaning that the difference in the estimate \\(\\Psi(P_n)\\) and the true parameter (\\(\\Psi(P_0)\\)) can be represented in first order by a i.i.d. sum: \\[\\begin{equation}\\label{eqn:IC} \\Psi(P_n) - \\Psi(P_0) = \\frac{1}{n} IC(O_i; \\nu) + op(1/\\sqrt{n}) \\end{equation}\\] where \\(IC(O_i; \\nu)\\) is a function of the data and possibly other parameters \\(\\nu\\). Importantly, such estimators have mean-zero Gaussian limiting distributions; thus, in the univariate case, one has that \\[\\begin{equation}\\label{eqn:limit_dist} \\sqrt{n}(\\Psi(P_n) - \\Psi(P_0)) = N(0, (IC(O_i; \\nu))^2), \\end{equation}\\] so that inference for the estimator of interest may be obtained in terms of the influence function. For this simple case, a 95% confidence interval may be derived as: \\[\\begin{equation}\\label{eqn:CI} \\Psi(P^{\\star}_n) \\pm 1.96 \\sqrt{\\frac{\\hat{\\sigma}^2}{n}}, \\end{equation}\\] where \\(SE=\\sqrt{\\frac{\\hat{\\sigma}^2}{n}}\\) and \\(\\hat{\\sigma}^2\\) is the sample variance of the estimated IC’s: \\(IC(O; \\hat{\\nu})\\). One can use the functional delta method to derive the influence curve if a parameter of interest may be written as a function of other asymptotically linear estimators. 1.7 The WASH Benefits Example Dataset The data come from a study of the effect of water quality, sanitation, hand washing, and nutritional interventions on child development in rural Bangladesh (WASH Benefits Bangladesh): a cluster-randomised controlled trial (“Temporary,” n.d.). The study enrolled pregnant women in their first or second trimester from the rural villages of Gazipur, Kishoreganj, Mymensingh, and Tangail districts of central Bangladesh, with an average of eight women per cluster. Groups of eight geographically adjacent clusters were block-randomised, using a random number generator, into six intervention groups (all of which received weekly visits from a community health promoter for the first 6 months and every 2 weeks for the next 18 months) and a double-sized control group (no intervention or health promoter visit). The six intervention groups were: chlorinated drinking water; improved sanitation; handwashing with soap; combined water, sanitation, and hand washing; improved nutrition through counseling and provision of lipid-based nutrient supplements; and combined water, sanitation, handwashing, and nutrition. In the workshop, we concentrate on child growth (size for age) as the outcome of interest. For referene, this trial was registered with ClinicalTrials.gov as NCT01590095. library(here) library(tidyverse) # read in data dat &lt;- read_csv(here(&quot;data&quot;, &quot;washb_data.csv&quot;)) dat # A tibble: 4,695 x 28 whz tr fracode month aged sex momage momedu momheight hfiacat Nlt18 &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; 1 0 Cont… N05265 9 268 male 30 Prima… 146. Food S… 3 2 -1.16 Cont… N05265 9 286 male 25 Prima… 149. Modera… 2 3 -1.05 Cont… N08002 9 264 male 25 Prima… 152. Food S… 1 4 -1.26 Cont… N08002 9 252 fema… 28 Prima… 140. Food S… 3 5 -0.59 Cont… N06531 9 336 fema… 19 Secon… 151. Food S… 2 6 -0.51 Cont… N06531 9 304 male 20 Secon… 154. Severe… 0 7 -2.46 Cont… N08002 9 336 fema… 19 Prima… 151. Food S… 2 8 -0.6 Cont… N06528 9 312 fema… 25 No ed… 142. Food S… 2 9 -0.23 Cont… N06528 9 322 male 30 Secon… 153. Food S… 1 10 -0.14 Cont… N06453 9 376 male 30 No ed… 156. Modera… 2 # … with 4,685 more rows, and 17 more variables: Ncomp &lt;dbl&gt;, watmin &lt;dbl&gt;, # elec &lt;dbl&gt;, floor &lt;dbl&gt;, walls &lt;dbl&gt;, roof &lt;dbl&gt;, asset_wardrobe &lt;dbl&gt;, # asset_table &lt;dbl&gt;, asset_chair &lt;dbl&gt;, asset_khat &lt;dbl&gt;, asset_chouki &lt;dbl&gt;, # asset_tv &lt;dbl&gt;, asset_refrig &lt;dbl&gt;, asset_bike &lt;dbl&gt;, asset_moto &lt;dbl&gt;, # asset_sewmach &lt;dbl&gt;, asset_mobile &lt;dbl&gt; For the purposes of this workshop, we we start by treating the data as independent and identically distributed (i.i.d.) random draws from a very large target population. We could, with available options, account for the clustering of the data (within sampled geographic units), but, for simplification, we avoid these details in these workshop presentations, although modifications of our methodology for biased samples, repeated measures, etc., are available. We have 28 variables measured, of which 1 variable is set to be the outcome of interest. This outcome, \\(Y\\), is the weight-for-height Z-score (whz in dat); the treatment of interest, \\(A\\), is the randomized treatment group (tr in dat); and the adjustment set, \\(W\\), consists simply of everything else. This results in our observed data structure being \\(n\\) i.i.d. copies of \\(O_i = (W_i, A_i, Y_i)\\), for \\(i = 1, \\ldots, n\\). 1.7.1 The variables Using the skimr package, we can quickly summarize the variables measured in the WASH Benefits data set: library(skimr) skim(dat) Skim summary statistics n obs: 4695 n variables: 28 ── Variable type:character ───────────────────────────────────────────────────── variable missing complete n min max empty n_unique fracode 0 4695 4695 2 6 0 20 hfiacat 0 4695 4695 11 24 0 4 momedu 0 4695 4695 12 15 0 3 sex 0 4695 4695 4 6 0 2 tr 0 4695 4695 3 15 0 7 ── Variable type:numeric ─────────────────────────────────────────────────────── variable missing complete n mean sd p0 p25 p50 p75 aged 0 4695 4695 266.32 52.17 42 230 266 303 asset_bike 0 4695 4695 0.32 0.47 0 0 0 1 asset_chair 0 4695 4695 0.73 0.44 0 0 1 1 asset_chouki 0 4695 4695 0.78 0.41 0 1 1 1 asset_khat 0 4695 4695 0.61 0.49 0 0 1 1 asset_mobile 0 4695 4695 0.86 0.35 0 1 1 1 asset_moto 0 4695 4695 0.066 0.25 0 0 0 0 asset_refrig 0 4695 4695 0.079 0.27 0 0 0 0 asset_sewmach 0 4695 4695 0.065 0.25 0 0 0 0 asset_table 0 4695 4695 0.73 0.44 0 0 1 1 asset_tv 0 4695 4695 0.3 0.46 0 0 0 1 asset_wardrobe 0 4695 4695 0.17 0.37 0 0 0 0 elec 0 4695 4695 0.6 0.49 0 0 1 1 floor 0 4695 4695 0.11 0.31 0 0 0 0 momage 18 4677 4695 23.91 5.24 14 20 23 27 momheight 31 4664 4695 150.5 5.23 120.65 147.05 150.6 154.06 month 0 4695 4695 6.45 3.33 1 4 6 9 Ncomp 0 4695 4695 11.04 6.35 2 6 10 14 Nlt18 0 4695 4695 1.6 1.25 0 1 1 2 roof 0 4695 4695 0.99 0.12 0 1 1 1 walls 0 4695 4695 0.72 0.45 0 0 1 1 watmin 0 4695 4695 0.95 9.48 0 0 0 1 whz 0 4695 4695 -0.59 1.03 -4.67 -1.28 -0.6 0.08 p100 hist 460 ▁▁▂▇▇▅▁▁ 1 ▇▁▁▁▁▁▁▃ 1 ▃▁▁▁▁▁▁▇ 1 ▂▁▁▁▁▁▁▇ 1 ▅▁▁▁▁▁▁▇ 1 ▁▁▁▁▁▁▁▇ 1 ▇▁▁▁▁▁▁▁ 1 ▇▁▁▁▁▁▁▁ 1 ▇▁▁▁▁▁▁▁ 1 ▃▁▁▁▁▁▁▇ 1 ▇▁▁▁▁▁▁▃ 1 ▇▁▁▁▁▁▁▂ 1 ▆▁▁▁▁▁▁▇ 1 ▇▁▁▁▁▁▁▁ 60 ▅▇▅▂▁▁▁▁ 168 ▁▁▁▂▇▇▂▁ 12 ▅▃▇▃▂▇▃▅ 52 ▇▇▃▁▁▁▁▁ 10 ▇▃▂▁▁▁▁▁ 1 ▁▁▁▁▁▁▁▇ 1 ▃▁▁▁▁▁▁▇ 600 ▇▁▁▁▁▁▁▁ 4.97 ▁▁▅▇▃▁▁▁ A convenient summary of the relevant variables is given just above, complete with a small visualization describing the marginal characteristics of each covariate. Note that the asset variables reflect socio-economic status of the study participants. Notice also the uniform distribution of the treatment groups (with twice as many controls); this is, of course, by design. References "],
["modern-super-machine-learning-with-sl3.html", "Chapter 2 Modern Super (Machine) Learning with sl3 2.1 Learning Objectives 2.2 Introduction 2.3 Basic Implementation 2.4 Extensions 2.5 Exercise 2.6 Concluding Remarks", " Chapter 2 Modern Super (Machine) Learning with sl3 Rachael V. Phillips, Jeremy Coyle, Mark van der Laan Updated: 2019-05-06 2.1 Learning Objectives By the end of this lesson you will be able to: Assemble an ensemble of learners based on the properties that identify what features they support. Customize learner hyperparameters to incorporate a diversity of different settings. Select a subset of available covariates and pass only those variables to the modeling algorithm. Fit an ensemble with nested cross-validation to obtain an estimate of the performance of the ensemble itself. Calculate sl3 variable importance metrics. Interpret the discrete and continuous super learner fits. Rationalize the need to remove bias from the super learner to make an optimal bias-variance tradeoff for the parameter of interest. 2.2 Introduction Now that we have defined the statistical estimation problem, we are ready construct the TMLE; an asymptotically efficient substitution estimator of this target quantity. The first step in this estimation procedure is an initial estimate of the data-generating distribution, or the relevant part of this distribution that is needed to evaluate the target parameter. For this initial estimation, we use the super learner (???), an important step in creating a robust estimator. 2.2.0.1 Super learner Loss-function-based tool that uses V-fold cross-validation to obtain the best prediction of the relevant part of the likelihood that’s needed to evaluate target parameter. Requires expressing the estimand as the minimizer of an expected loss, and proposing a library of algorithms (“learners” in sl3 nomenclature) that we think might be consistent with the true data-generating distribution. Proven to be asymptotically as accurate as the best possible prediction algorithm that is tested (van der Laan and Dudoit 2003; Van der Vaart, Dudoit, and Laan 2006). The discrete super learner, or cross-validated selector, is the algorithm in the library that minimizes the V-fold cross-validated empirical risk. The continuous super learner is a weighted average of the library of algorithms, where the weights are chosen to minimize the V-fold cross-validated empirical risk of the library. Restricting the weights (“metalearner” in sl3 nomenclature) to be positive and sum to one (convex combination) has been shown to improve upon the discrete super learner (Polley and Van Der Laan 2010; ???). 2.3 Basic Implementation We begin by illustrating the basic functionality of the super learner algorithm as implemented in sl3. The sl3 implementation consists of the following steps: Load the necessary libraries and data Define the machine learning task Make a super learner by creating library of base learners and a metalearner Train the super learner on the machine learning task Obtain predicted values 2.3.1 WASH Benefits Study Example Using the WASH data, we are interested in predicting weight-for-height z-score whz using the available covariate data. Let’s begin! 0. Load the necessary libraries and data library(here) library(tidyverse) library(data.table) library(sl3) library(SuperLearner) library(origami) library(knitr) set.seed(7194) # load data set and take a peek washb_data &lt;- fread(here(&quot;data&quot;, &quot;washb_data.csv&quot;), stringsAsFactors = TRUE) head(washb_data, 3) %&gt;% kable(format = &quot;markdown&quot;, digits = 3) whz tr fracode month aged sex momage momedu momheight hfiacat Nlt18 Ncomp watmin elec floor walls roof asset_wardrobe asset_table asset_chair asset_khat asset_chouki asset_tv asset_refrig asset_bike asset_moto asset_sewmach asset_mobile 0.00 Control N05265 9 268 male 30 Primary (1-5y) 146.40 Food Secure 3 11 0 1 0 1 1 0 1 1 1 0 1 0 0 0 0 1 -1.16 Control N05265 9 286 male 25 Primary (1-5y) 148.75 Moderately Food Insecure 2 4 0 1 0 1 1 0 1 0 1 1 0 0 0 0 0 1 -1.05 Control N08002 9 264 male 25 Primary (1-5y) 152.15 Food Secure 1 10 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 1 1. Define the machine learning task To define the machine learning “task” (predict weight-for-height z-score whz using the available covariate data), we need to create an sl3_Task object. The sl3_Task keeps track of the roles the variables play in the machine learning problem, the data, and any metadata (e.g., observational-level weights, IDs, offset). # specify the outcome and covariates outcome &lt;- &quot;whz&quot; covars &lt;- colnames(washb_data)[-which(names(washb_data) == outcome)] # create the sl3 task washb_task &lt;- make_sl3_Task( data = washb_data, covariates = covars, outcome = outcome ) Warning in .subset2(public_bind_env, &quot;initialize&quot;)(...): Missing Covariate Data Found. Imputing covariates using sl3_process_missing # examine it washb_task A sl3 Task with 4695 obs and these nodes: $covariates [1] &quot;tr&quot; &quot;fracode&quot; &quot;month&quot; &quot;aged&quot; [5] &quot;sex&quot; &quot;momage&quot; &quot;momedu&quot; &quot;momheight&quot; [9] &quot;hfiacat&quot; &quot;Nlt18&quot; &quot;Ncomp&quot; &quot;watmin&quot; [13] &quot;elec&quot; &quot;floor&quot; &quot;walls&quot; &quot;roof&quot; [17] &quot;asset_wardrobe&quot; &quot;asset_table&quot; &quot;asset_chair&quot; &quot;asset_khat&quot; [21] &quot;asset_chouki&quot; &quot;asset_tv&quot; &quot;asset_refrig&quot; &quot;asset_bike&quot; [25] &quot;asset_moto&quot; &quot;asset_sewmach&quot; &quot;asset_mobile&quot; &quot;delta_momage&quot; [29] &quot;delta_momheight&quot; $outcome [1] &quot;whz&quot; $id NULL $weights NULL $offset NULL 2. Make a super learner Now that we have defined our machine learning problem with the task, we are ready to “make” the machine learning algorithms. Learners have properties that indicate what features they support. We may use sl3_list_properties() toget a list of all properties supported by at least one learner. sl3_list_properties() [1] &quot;binomial&quot; &quot;categorical&quot; &quot;continuous&quot; [4] &quot;cv&quot; &quot;density&quot; &quot;ids&quot; [7] &quot;multivariate_outcome&quot; &quot;offset&quot; &quot;preprocessing&quot; [10] &quot;timeseries&quot; &quot;weights&quot; &quot;wrapper&quot; Since we have a continuous outcome, we may identify the learners that support this outcome type with sl3_list_learners(). sl3_list_learners(c(&quot;continuous&quot;)) [1] &quot;Lrnr_arima&quot; &quot;Lrnr_bartMachine&quot; [3] &quot;Lrnr_bilstm&quot; &quot;Lrnr_condensier&quot; [5] &quot;Lrnr_dbarts&quot; &quot;Lrnr_expSmooth&quot; [7] &quot;Lrnr_glm&quot; &quot;Lrnr_glm_fast&quot; [9] &quot;Lrnr_glmnet&quot; &quot;Lrnr_grf&quot; [11] &quot;Lrnr_h2o_glm&quot; &quot;Lrnr_h2o_grid&quot; [13] &quot;Lrnr_hal9001&quot; &quot;Lrnr_HarmonicReg&quot; [15] &quot;Lrnr_lstm&quot; &quot;Lrnr_mean&quot; [17] &quot;Lrnr_nnls&quot; &quot;Lrnr_optim&quot; [19] &quot;Lrnr_pkg_SuperLearner&quot; &quot;Lrnr_pkg_SuperLearner_method&quot; [21] &quot;Lrnr_pkg_SuperLearner_screener&quot; &quot;Lrnr_randomForest&quot; [23] &quot;Lrnr_ranger&quot; &quot;Lrnr_rpart&quot; [25] &quot;Lrnr_rugarch&quot; &quot;Lrnr_solnp&quot; [27] &quot;Lrnr_stratified&quot; &quot;Lrnr_svm&quot; [29] &quot;Lrnr_tsDyn&quot; &quot;Lrnr_xgboost&quot; Now that we have an idea of some learners, we can construct them using the make_learner function. # choose base learners lrnr_glm &lt;- make_learner(Lrnr_glm) lrnr_mean &lt;- make_learner(Lrnr_mean) lrnr_ranger &lt;- make_learner(Lrnr_ranger) lrnr_glmnet &lt;- make_learner(Lrnr_glmnet) In order to assemble the library of learners, we need to “stack” them together. A Stack is a special learner and it has the same interface as all other learners. What makes a stack special is that it combines multiple learners by training them simultaneously, so that their predictions can be either combined or compared. stack &lt;- make_learner( Stack, lrnr_glm, lrnr_mean, lrnr_ranger, lrnr_glmnet ) We’re almost ready to super learn! Just a couple more necessary specifications. We will fit a non-negative least squares metalearner using Lrnr_nnls. Note that any learner can be used as a metalearner. metalearner &lt;- make_learner(Lrnr_nnls) Now that we have made a library/stack of base learners and a metalearner, we are ready to make the super learner. sl &lt;- make_learner(Lrnr_sl, learners = stack, metalearner = metalearner ) 3. Train the super learner on the machine learning task The super learner algorithm fits a metalearner on the validation-set predictions. This procedure is referred to as the continuous super learner. The cross-validation selector, or discrete super learner, is the base learner with the lowest cross-validated risk. Now we are ready to “train” our super learner on our sl3_task object. sl_fit &lt;- sl$train(washb_task) 4. Obtain predicted values Now that we have fit the super learner, we are ready to obtain our predicted values, and we can also obtain a summary of the results. sl_preds &lt;- sl_fit$predict() head(sl_preds) [1] -0.5127495 -0.9152300 -0.7752874 -0.8053409 -0.6387997 -0.7073217 sl_fit$print() %&gt;% kable(format = &quot;markdown&quot;, digits = 3) [1] &quot;SuperLearner:&quot; List of 4 $ : chr &quot;Lrnr_glm_TRUE&quot; $ : chr &quot;Lrnr_mean&quot; $ : chr &quot;Lrnr_ranger_500_TRUE&quot; $ : chr &quot;Lrnr_glmnet_NULL_deviance_10_1_100_TRUE&quot; [1] &quot;Lrnr_nnls&quot; lrnrs weights 1: Lrnr_glm_TRUE 0.1199472 2: Lrnr_mean 0.0000000 3: Lrnr_ranger_500_TRUE 0.4763250 4: Lrnr_glmnet_NULL_deviance_10_1_100_TRUE 0.4111953 [1] &quot;Cross-validated risk (MSE, squared error loss):&quot; learner coefficients mean_risk SE_risk 1: Lrnr_glm_TRUE NA 1.018612 0.02380402 2: Lrnr_mean NA 1.065282 0.02502664 3: Lrnr_ranger_500_TRUE NA 1.012847 0.02346574 4: Lrnr_glmnet_NULL_deviance_10_1_100_TRUE NA 1.012105 0.02357576 5: SuperLearner NA 1.006726 0.02341488 fold_SD fold_min_risk fold_max_risk 1: 0.07799191 0.8956048 1.134940 2: 0.09191791 0.9264292 1.196647 3: 0.08092142 0.8777004 1.145596 4: 0.07938736 0.8826677 1.130114 5: 0.07993542 0.8742290 1.132479 learner coefficients mean_risk SE_risk fold_SD fold_min_risk fold_max_risk Lrnr_glm_TRUE NA 1.019 0.024 0.078 0.896 1.135 Lrnr_mean NA 1.065 0.025 0.092 0.926 1.197 Lrnr_ranger_500_TRUE NA 1.013 0.023 0.081 0.878 1.146 Lrnr_glmnet_NULL_deviance_10_1_100_TRUE NA 1.012 0.024 0.079 0.883 1.130 SuperLearner NA 1.007 0.023 0.080 0.874 1.132 2.4 Extensions 2.4.1 Customize Learner Hyperparameters We can customize learner hyperparameters to incorporate a diversity of different settings. We can also include learners from the SuperLearner R package. Documentation for the learners and their hyperparameters can be found in the sl3 Learners Reference. lrnr_ranger100 &lt;- make_learner(Lrnr_ranger, num.trees = 100) lrnr_ranger1k &lt;- make_learner(Lrnr_ranger, num.trees = 1000) lrnr_gam &lt;- Lrnr_pkg_SuperLearner$new(&quot;SL.gam&quot;) lrnr_bayesglm &lt;- Lrnr_pkg_SuperLearner$new(&quot;SL.bayesglm&quot;) Let’s create a new stack with these new learners, so we may incorporate them in a new super learner. new_stack &lt;- make_learner( Stack, lrnr_glm, lrnr_mean, lrnr_ranger, lrnr_glmnet, lrnr_ranger1k, lrnr_ranger100, lrnr_gam, lrnr_bayesglm ) 2.4.2 Screening covariates We can also select a subset of available covariates and pass only those variables to the modeling algorithm. Let’s see how this works. Consider screening covariates based on their correlation with the outcome of interest (cor.test p-value &lt; 0.1), and randomForest variable importance (top 10 most important variables). screen_cor &lt;- Lrnr_pkg_SuperLearner_screener$new(&quot;screen.corP&quot;) screen_rf &lt;- Lrnr_pkg_SuperLearner_screener$new(&quot;screen.randomForest&quot;) Now we need to “pipe” only those selected covariates to the modeling algorithm. To accomplish this, we need to make a Pipeline, which is a just set of learners to be fit sequentially, where the fit from one learner is used to define the task for the next learner. cor_pipeline &lt;- make_learner(Pipeline, screen_cor, new_stack) rf_pipeline &lt;- make_learner(Pipeline, screen_rf, new_stack) Lastly, we just have to stack all of these pipelines together, so we may use them as base learners in our super learner. fancy_stack &lt;- make_learner(Stack, cor_pipeline, rf_pipeline, new_stack) dt &lt;- delayed_learner_train(fancy_stack, washb_task) plot(dt, color=FALSE, height=&quot;300px&quot;) Now we can Super Learn with this fancy base learner stack. sl_fancy &lt;- Lrnr_sl$new(learners = fancy_stack, metalearner = metalearner) sl_fancy_fit &lt;- sl_fancy$train(washb_task) sl_preds &lt;- sl_fancy_fit$predict() sl_fancy_fit$print() %&gt;% kable(format = &quot;markdown&quot;, digits = 3) 2.4.3 Cross-validated super learner We can cross-validate the super learner to see how well the super learner performs on unseen data. This requires an “external” layer of cross-validation, also called nested cross-validation, which involves setting aside a separate holdout sample that we don’t use to fit the super learner. This external cross validation procedure may also incorporate 10 folds, which is the default in sl3. CVsl &lt;- CV_lrnr_sl(sl_fit, washb_task, loss_squared_error) CVsl %&gt;% kable(format = &quot;markdown&quot;, digits = 3) 2.4.4 Variable importance Variable importance can be interesting and informative. Let’s explore how it works in sl3. washb_varimp &lt;- varimp(sl_fit, loss_squared_error) washb_varimp %&gt;% kable(format = &#39;html&#39;, digits = 3) X risk_diff aged 0.464 momedu 0.431 tr 0.430 month 0.430 asset_refrig 0.428 elec 0.427 asset_chair 0.427 floor 0.427 momheight 0.426 Nlt18 0.426 asset_chouki 0.426 asset_moto 0.425 hfiacat 0.425 momage 0.425 sex 0.425 walls 0.425 asset_table 0.425 asset_wardrobe 0.425 asset_bike 0.425 watmin 0.425 delta_momage 0.424 asset_tv 0.424 roof 0.424 delta_momheight 0.424 asset_sewmach 0.424 fracode 0.424 asset_mobile 0.424 asset_khat 0.423 Ncomp 0.422 This function calculates the risk difference between the learner fit with a scrambled covariate and the learner fit with the true covariate, across all covariates. In this manner, the larger the risk difference the more important the variable is in the prediction. 2.5 Exercise 2.5.1 Predicting myocardial infarction with sl3 Using the chspred data, loaded below, use sl3 to predict myocardial infarction (mi) using the available covariate data. Work with a buddy. You have 20 minutes. In the etherpad, submit your group’s answers to the following questions. Which learner was the discrete super learner? What was the cross validated risk of the discrete super learner? What was the cross validated risk of the continuous super learner? Did your group face any challenges? # load the data set db_data &lt;- url(&quot;https://raw.githubusercontent.com/benkeser/sllecture/master/chspred.csv&quot;) chspred &lt;- read_csv(file = db_data, col_names = TRUE) Parsed with column specification: cols( .default = col_double() ) See spec(...) for full column specifications. # take a quick peek head(chspred, 3) # A tibble: 3 x 28 waist alcoh hdl beta smoke ace ldl bmi aspirin gend age estrgn &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 110. 0 66.5 0 0 1 114. 28.0 0 0 73.5 0 2 90.0 0 50.1 0 0 0 104. 20.9 0 0 61.8 0 3 106. 8.42 40.5 0 0 0 166. 28.5 1 1 72.9 0 # … with 16 more variables: glu &lt;dbl&gt;, ins &lt;dbl&gt;, cysgfr &lt;dbl&gt;, dm &lt;dbl&gt;, # fetuina &lt;dbl&gt;, whr &lt;dbl&gt;, hsed &lt;dbl&gt;, race &lt;dbl&gt;, logcystat &lt;dbl&gt;, # logtrig &lt;dbl&gt;, logcrp &lt;dbl&gt;, logcre &lt;dbl&gt;, health &lt;dbl&gt;, logkcal &lt;dbl&gt;, # sysbp &lt;dbl&gt;, mi &lt;dbl&gt; 2.6 Concluding Remarks The general ensemble learning approach of super learner can be applied to a diversity of estimation and prediction problems that can be defined by a loss function. Plug-in estimators of the estimand are desirable because a plug-in estimator respects both the local and global constraints of the statistical model. Asymptotically linear estimators are also advantageous, since they converge to the estimand at \\(1/\\sqrt{n}\\) rate, and thereby permit formal statistical inference. If we plug in the estimator returned by super learner into the target parameter mapping, then we would end up with an estimator that has the same bias as what we plugged in. This estimator would not be asymptotically linear. Targeted maximum likelihood estimation (TMLE) is a general strategy that succeeds in constructing asymptotically linear plug-in estimators. References "],
["tmle3-the-targeted-learning-framework.html", "Chapter 3 tmle3 – The Targeted Learning Framework 3.1 Learning Objectives 3.2 Example: tmle3 for ATE 3.3 tmle3 Components 3.4 Fitting tmle3 with multiple parameters 3.5 Summary", " Chapter 3 tmle3 – The Targeted Learning Framework Jeremy Coyle, based on the tmle3 package Updated: 2019-05-06 3.1 Learning Objectives Use tmle3 to estimate an Average Treatment Effect (ATE) Understand tmle3 “Specs” Fit tmle3 for a custom set of parameters Use the delta method to estimate transformations of parameters 3.2 Example: tmle3 for ATE We’ll illustrate the most basic use of TMLE using the WASH Benefits data introduced earlier and estimating an Average Treatment Effect (ATE) As a reminder, the ATE is identified with the following statistical parameter (under assumptions): \\(ATE = E_0(Y(1)=Y(0)) = E_0\\left( E_0[Y \\mid A=1,W]-E_0[Y \\mid A=0,W] \\right),\\) 3.2.1 Load the Data We’ll use the same WASH Benefits data as the earlier chapters: library(here) library(data.table) library(tmle3) library(sl3) washb_data &lt;- fread(here(&quot;data&quot;, &quot;washb_data.csv&quot;), stringsAsFactors = TRUE) 3.2.2 Define the variable roles We’ll use the common W (covariates), A (treatment/intervention), Y (outcome) data structure. tmle3 needs to know what variables in the dataset correspond to each of these roles. We use a list of character vectors to tell it. We call this a “Node List” as it corresponds to the nodes in a Directed Acyclic Graph (DAG), a way of displaying causal relationships between variables. node_list &lt;- list( W = c( &quot;month&quot;, &quot;aged&quot;, &quot;sex&quot;, &quot;momage&quot;, &quot;momedu&quot;, &quot;momheight&quot;, &quot;hfiacat&quot;, &quot;Nlt18&quot;, &quot;Ncomp&quot;, &quot;watmin&quot;, &quot;elec&quot;, &quot;floor&quot;, &quot;walls&quot;, &quot;roof&quot;, &quot;asset_wardrobe&quot;, &quot;asset_table&quot;, &quot;asset_chair&quot;, &quot;asset_khat&quot;, &quot;asset_chouki&quot;, &quot;asset_tv&quot;, &quot;asset_refrig&quot;, &quot;asset_bike&quot;, &quot;asset_moto&quot;, &quot;asset_sewmach&quot;, &quot;asset_mobile&quot; ), A = &quot;tr&quot;, Y = &quot;whz&quot; ) 3.2.3 Handle Missingness Currently, missingness in tmle3 is handled in a fairly simple way: Missing covariates are median (for continuous) or mode (for discrete) imputed, and additional covariates indicating imputation are generated Observations missing either treatment or outcome variables are excluded. We plan to implement IPCW-TMLE to more efficiently handle missingness in the treatment and outcome variables. These steps are implemented in the process_missing function in tmle3: processed &lt;- process_missing(washb_data, node_list) washb_data &lt;- processed$data node_list &lt;- processed$node_list 3.2.4 Create a “Spec” Object tmle3 is general, and allows most components of the TMLE procedure to be specified in a modular way. However, most end-users will not be interested in manually specifying all of these components. Therefore, tmle3 implements a tmle3_Spec object that bundles a set ofcomponents into a specification that, with minimal additional detail, can be run by an end-user. We’ll start with using one of the specs, and then work our way down into the internals of tmle3. ate_spec &lt;- tmle_ATE( treatment_level = &quot;Nutrition + WSH&quot;, control_level = &quot;Control&quot; ) 3.2.5 Define the learners Currently, the only other thing a user must define are the sl3 learners used to estimate the relevant factors of the likelihood: Q and g. This takes the form of a list of sl3 learners, one for each likelihood factor to be estimated with sl3: # choose base learners lrnr_mean &lt;- make_learner(Lrnr_mean) lrnr_xgboost &lt;- make_learner(Lrnr_xgboost) # define metalearners appropriate to data types ls_metalearner &lt;- make_learner(Lrnr_nnls) mn_metalearner &lt;- make_learner(Lrnr_solnp, metalearner_linear_multinomial, loss_loglik_multinomial) sl_Y &lt;- Lrnr_sl$new(learners = list(lrnr_mean, lrnr_xgboost), metalearner = ls_metalearner) sl_A &lt;- Lrnr_sl$new(learners = list(lrnr_mean, lrnr_xgboost), metalearner = mn_metalearner) learner_list &lt;- list(A = sl_A, Y = sl_Y) Here, we use a SuperLearner as defined in the previous chapter. In the future, we plan to include reasonable defaults learners. 3.2.6 Fit the TMLE We now have everything we need to fit the tmle using tmle3: tmle_fit &lt;- tmle3(ate_spec, washb_data, node_list, learner_list) 3.2.7 Evaluate the Estimates We can see the summary results by printing the fit object. Alternatively, we can extra results from the summary by indexing into it: print(tmle_fit) A tmle3_Fit that took 1 step(s) type param init_est tmle_est 1: ATE ATE[Y_{A=Nutrition + WSH}-Y_{A=Control}] 0.002374285 0.004919129 se lower upper psi_transformed lower_transformed 1: 0.05093973 -0.09492091 0.1047592 0.004919129 -0.09492091 upper_transformed 1: 0.1047592 estimates &lt;- tmle_fit$summary$psi_transformed print(estimates) [1] 0.004919129 3.3 tmle3 Components Now that we’ve successfully used a spec to obtain a TML estimate, let’s look under the hood at the components. The spec has a number of functions that generate the objects necessary to define and fit a TMLE. 3.3.1 tmle3_task First is, a tmle3_Task, analogous to an sl3_Task, containing the data we’re fitting the TMLE to, as well as an NP-SEM generated from the node_list defined above, describing the variables and their relationships. tmle_task &lt;- ate_spec$make_tmle_task(washb_data, node_list) tmle_task$npsem $W tmle3_Node: W Variables: month, aged, sex, momedu, hfiacat, Nlt18, Ncomp, watmin, elec, floor, walls, roof, asset_wardrobe, asset_table, asset_chair, asset_khat, asset_chouki, asset_tv, asset_refrig, asset_bike, asset_moto, asset_sewmach, asset_mobile, momage, momheight, delta_momage, delta_momheight Parents: $A tmle3_Node: A Variables: tr Parents: W $Y tmle3_Node: Y Variables: whz Parents: A, W 3.3.2 Initial Likelihood Next, is an object representing the likelihood, factorized according to the NPSEM described above: initial_likelihood &lt;- ate_spec$make_initial_likelihood( tmle_task, learner_list ) print(initial_likelihood) W: Lf_emp A: LF_fit Y: LF_fit These components of the likelihood indicate how the factors were estimated: the marginal distribution of \\(W\\) was estimated using NP-MLE, and the conditional distributions of \\(A\\) and \\(Y\\) were estimated using sl3 fits (as defined with the learner_list) above. We can use this in tandem with the tmle_task object to obtain likelihood estimates for each observation: initial_likelihood$get_likelihoods(tmle_task) W A Y 1: 0.0002129925 0.2478116 -0.6636675 2: 0.0002129925 0.2546811 -0.6366056 3: 0.0002129925 0.2591630 -0.6243758 4: 0.0002129925 0.2802803 -0.6040870 5: 0.0002129925 0.2536342 -0.5474464 --- 4691: 0.0002129925 0.1349251 -0.4674441 4692: 0.0002129925 0.1261758 -0.4862865 4693: 0.0002129925 0.1264204 -0.5709195 4694: 0.0002129925 0.1753331 -0.8200469 4695: 0.0002129925 0.1299314 -0.5445321 3.3.3 Targeted Likelihood (updater) We also need to define a “Targeted Likelihood” object. This is a special type of likelihood that is able to be updated using an tmle3_Update object. This object defines the update strategy (e.g. submodel, loss function, CV-TMLE or not, etc). targeted_likelihood &lt;- Targeted_Likelihood$new(initial_likelihood) When constructing the targeted likelihood, you can specify different update options. See the documentation for tmle3_Update for details of the different options. For example, you can disable CV-TMLE (the default in tmle3) as follows: targeted_likelihood_no_cv &lt;- Targeted_Likelihood$new(initial_likelihood, updater = list(cvtmle = FALSE) ) 3.3.4 Parameter Mapping Finally, we need to define the parameters of interest. Here, the spec defines a single parameter, the ATE. In the next section, we’ll see how to add additional parameters. tmle_params &lt;- ate_spec$make_params(tmle_task, targeted_likelihood) print(tmle_params) [[1]] Param_ATE: ATE[Y_{A=Nutrition + WSH}-Y_{A=Control}] 3.3.5 Putting it all together Having used the spec to manually generate all these components, we can now manually fit a tmle3: tmle_fit_manual &lt;- fit_tmle3( tmle_task, targeted_likelihood, tmle_params, targeted_likelihood$updater ) print(tmle_fit_manual) A tmle3_Fit that took 1 step(s) type param init_est tmle_est 1: ATE ATE[Y_{A=Nutrition + WSH}-Y_{A=Control}] 0.002420953 0.005688114 se lower upper psi_transformed lower_transformed 1: 0.05066608 -0.09361558 0.1049918 0.005688114 -0.09361558 upper_transformed 1: 0.1049918 The result is equivalent to fitting using the tmle3 function as above. 3.4 Fitting tmle3 with multiple parameters Above, we fit a tmle3 with just one parameter. tmle3 also supports fitting multiple parameters simultaneously. To illustrate this, we’ll use the tmle_TSM_all spec: tsm_spec &lt;- tmle_TSM_all() targeted_likelihood &lt;- Targeted_Likelihood$new(initial_likelihood) all_tsm_params &lt;- tsm_spec$make_params(tmle_task, targeted_likelihood) print(all_tsm_params) [[1]] Param_TSM: E[Y_{A=Control}] [[2]] Param_TSM: E[Y_{A=Handwashing}] [[3]] Param_TSM: E[Y_{A=Nutrition}] [[4]] Param_TSM: E[Y_{A=Nutrition + WSH}] [[5]] Param_TSM: E[Y_{A=Sanitation}] [[6]] Param_TSM: E[Y_{A=WSH}] [[7]] Param_TSM: E[Y_{A=Water}] This spec generates a Treatment Specific Mean (TSM) for each level of the exposure variable. Note that we must first generate a new targeted likelihood, as the old one was targeted to the ATE. However, we can recycle the initial likelihood we fit above, saving us a super learner step. 3.4.1 Delta Method We can also define parameters based on Delta Method Transformations of other parameters. For instance, we can estimate a ATE using the delta method and two of the above TSM parameters: ate_param &lt;- define_param( Param_delta, targeted_likelihood, delta_param_ATE, list(all_tsm_params[[1]], all_tsm_params[[4]]) ) print(ate_param) Param_delta: E[Y_{A=Nutrition + WSH}] - E[Y_{A=Control}] This can similarly be used to estimate other derived parameters like Relative Risks, and Population Attributable Risks 3.4.2 Fit We can now fit a TMLE simultaneously for all TSM parameters, as well as the above defined ATE parameter all_params &lt;- c(all_tsm_params, ate_param) tmle_fit_multiparam &lt;- fit_tmle3( tmle_task, targeted_likelihood, all_params, targeted_likelihood$updater ) print(tmle_fit_multiparam) A tmle3_Fit that took 1 step(s) type param init_est tmle_est 1: TSM E[Y_{A=Control}] -0.598097569 -0.620355839 2: TSM E[Y_{A=Handwashing}] -0.610547103 -0.641610265 3: TSM E[Y_{A=Nutrition}] -0.606100696 -0.622523827 4: TSM E[Y_{A=Nutrition + WSH}] -0.595676615 -0.614469201 5: TSM E[Y_{A=Sanitation}] -0.591533375 -0.590238665 6: TSM E[Y_{A=WSH}] -0.533175373 -0.444067807 7: TSM E[Y_{A=Water}] -0.579947617 -0.536383461 8: ATE E[Y_{A=Nutrition + WSH}] - E[Y_{A=Control}] 0.002420953 0.005886638 se lower upper psi_transformed lower_transformed 1: 0.02980701 -0.6787765 -0.5619352 -0.620355839 -0.6787765 2: 0.04204793 -0.7240227 -0.5591978 -0.641610265 -0.7240227 3: 0.04253932 -0.7058994 -0.5391483 -0.622523827 -0.7058994 4: 0.04110326 -0.6950301 -0.5339083 -0.614469201 -0.6950301 5: 0.04209751 -0.6727483 -0.5077291 -0.590238665 -0.6727483 6: 0.04483865 -0.5319499 -0.3561857 -0.444067807 -0.5319499 7: 0.03928547 -0.6133816 -0.4593853 -0.536383461 -0.6133816 8: 0.05066116 -0.0934074 0.1051807 0.005886638 -0.0934074 upper_transformed 1: -0.5619352 2: -0.5591978 3: -0.5391483 4: -0.5339083 5: -0.5077291 6: -0.3561857 7: -0.4593853 8: 0.1051807 3.5 Summary tmle3 is a general purpose framework for generating TML estimates. The easiest way to use it is to use a predefined spec, allowing you to just fill in the blanks for the data, variable roles, and sl3 learners. However, digging under the hood allows users to specify a wide range of TMLEs. In the next sections, we’ll see how this framework can be used to estimate advanced parameters such as optimal treatments and shift interventions. "],
["optimal-individualized-treatment-regimes.html", "Chapter 4 Optimal Individualized Treatment Regimes 4.1 Learning Objectives 4.2 Introduction to Optimal Individualized Interventions 4.3 Data Structure and Notation 4.4 Defining the Causal Effect of an Optimal Individualized Intervention 4.5 Binary treatment 4.6 Extensions to Causal Effect of an Optimal Individualized Intervention 4.7 Categorical treatment 4.8 Exercise: Optimal Individualized Intervention with Categorical Treatment 4.9 Exercise: WASH Benefits Data", " Chapter 4 Optimal Individualized Treatment Regimes Ivana Malenica, based on the tmle3mopttx package by Ivana Malenica, Jeremy Coyle, and Mark van der Laan Updated: 2019-05-06 4.1 Learning Objectives By the end of this lesson you will be able to: Differentiate between dynamic and optimal dynamic treatment regimes from static interventions. Understand the benefits, and challenges, associated with using optimal individualized treatment regimes in practice. Contrast the impact of implementing an optimal individualized treatment in the population with static and dynamic regimes. Estimate causal effects under optimal individualized treatment regimes with the tmle3mopttx R package. Contrast the population impact of implementing optimal individualized treatment based on sub-optimal rules. Construct realistic optimal individualized treatments that respect real data and subject-matter knowledge limitations on interventions. Understand and implement variable importance analysis defined in terms of optimal individualized treatment interventions. 4.2 Introduction to Optimal Individualized Interventions Identifying which intervention will be effective for which patient based on lifestyle, genetic and environmental factors is a common goal in precision medicine. One opts to administer the intervention to individuals who will profit from it, instead of assigning treatment on a population level. This aim motivates a different type of intervention, as opposed to the static exposures we might be used to. In this chapter, we learn about dynamic (individualized) interventions that tailor the treatment decision based on the collected covariates. In the statistics community, such a treatment strategy is termed individualized treatment regime (ITR), and the (counterfactual) population mean outcome under an ITR is the value of the ITR. Even more, suppose one wishes to maximize the population mean of an outcome, where for each individual we have access to some set of measured covariates. An ITR with the maximal value is referred to as an optimal ITR or the optimal individualized treatment. Consequently, the value of an optimal ITR is termed the optimal value, or the mean under the optimal individualized treatment. In this chapter, we examine a simple example of optimal individualized treatment regimes and estimate the mean outcome under the optimal individualized treatment where the candidate rules are restricted to depend only on user-supplied subset of the baseline covariates. In order to accomplish this, we present the tmle3mopttx R package, which features an implementation of a recently developed algorithm for computing targeted minimum loss-based estimates of a causal effect based on optimal individualized regime for categorical treatment. In particular, we will use tmle3mopttx to estimate optimal individualized treatments and the corresponding population value, construct realistic optimal ITRs, and perform variable importance in terms of the mean under the optimal individualized treatment. 4.3 Data Structure and Notation Suppose we observe \\(n\\) independent and identically distributed observations of the form \\(O=(W,A,Y) \\sim P_0\\). \\(P_0 \\in \\mathcal{M}\\), where \\(\\mathcal{M}\\) is the fully nonparametric model. Denote \\(A \\in \\mathcal{A}\\) as categorical treatment, where \\(\\mathcal{A} \\equiv \\{a_1, \\cdots, a_{n_A} \\}\\) and \\(n_A = |\\mathcal{A}|\\), with \\(n_A\\) denoting the number of categories. Denote \\(Y\\) as the final outcome, and \\(W\\) a vector-valued collection of baseline covariates. The likelihood of the data admits a factorization, implied by the time ordering of \\(O\\). \\[\\begin{equation*}\\label{eqn:likelihood_factorization} p_0(O) = p_{Y,0}(Y \\mid A,W) p_{A,0}(A \\mid W) p_{W,0}(W) = q_{Y,0}(Y \\mid A,W) q_{A,0}(A \\mid W) q_{W,0}(W), \\end{equation*}\\] Consequently, we define \\(P_{Y,0}(Y \\mid A,W) = Q_{Y,0}(Y \\mid A,W)\\), \\(P_{A,0}(A \\mid W)=g_0(A \\mid W)\\) and \\(P_{W,0}(W)=Q_{W,0}(W)\\) as the corresponding conditional distributions of \\(Y\\), \\(A\\) and \\(W\\). We also define \\(\\bar{Q}_{Y,0}(A,W) \\equiv E_0[Y \\mid A,W]\\). Finally, denote \\(V\\) as \\(V \\in W\\), defining a subset of the baseline covariates the optimal individualized rule depends on. 4.4 Defining the Causal Effect of an Optimal Individualized Intervention Consider dynamic treatment rules \\(V \\rightarrow d(V) \\in \\{a_1, \\cdots, a_{n_A} \\} \\times \\{1\\}\\), for assigning treatment \\(A\\) based on \\(V \\in W\\). Dynamic treatment regime may be viewed as an intervention in which \\(A\\) is set equal to a value based on a hypothetical regime \\(d(V)\\), and \\(Y_{d(V)}\\) is the corresponding counterfactual outcome under \\(d(V)\\). The goal of any causal analysis motivated by an optimal individualized intervention, is to estimate a parameter defined as the counterfactual mean of the outcome with respect to the modified intervention distribution. Recall causal assumptions: Consistency: \\(Y^{d(v_i)}_i = Y_i\\) in the event \\(A_i = d(v_i)\\), for \\(i = 1, \\ldots, n\\). Stable unit value treatment assumption (SUTVA): \\(Y^{d(v_i)}_i\\) does not depend on \\(d(v_j)\\) for \\(i = 1, \\ldots, n\\) and \\(j \\neq i\\), or lack of interference. Strong ignorability: \\(A \\indep Y^{d(v)} \\mid W\\), for all \\(a \\in \\mathcal{A}\\). Positivity (or overlap): \\(P_0(\\min_{a \\in \\mathcal{A}} g_0(a|W) &gt; 0)=1\\) Here, we also assume non-exceptional law is in effect. We are primarily interested in the value of an individualized rule, \\[E_0[Y_{d(V)}] = E_{0,W}[\\bar{Q}_{Y,0}(A=d(V),W)].\\] The optimal rule is the rule with the maximal value: \\[d_{opt}(V) \\equiv \\text{argmax}_{d(V) \\in \\mathcal{D}} E_0[Y_{d(V)}]\\] where \\(\\mathcal{D}\\) represents the set of possible rules, \\(d\\), implied by \\(V\\). The target causal estimand of our analysis is \\[\\psi_0 := E_0[Y_{d_{opt}(V)}] = E_{0,W}[\\bar{Q}_{Y,0}(A=d_{opt}(V),W)].\\] General, high-level idea: Learn the optimal ITR using Super Learner. Estimate its value with the cross-validated Targeted Minimum Loss-based Estimator (CV-TMLE). 4.5 Binary treatment How do we estimate the optimal individualized treatment regime? In the case of a binary treatment, a key quantity for optimal ITR is the blip function. Optimal ITR ideally assigns treatment to individuals falling in strata in which the stratum-specific average treatment effect, the blip function, is positive and does not assign treatment to individuals for which this quantity is negative. We define the blip function as: \\[\\bar{Q}_0(V) \\equiv E_0[Y_1-Y_0 \\mid V] \\equiv E_0[\\bar{Q}_{Y,0}(1,W) - \\bar{Q}_{Y,0}(0,W) \\mid V],\\] or the average treatment effect within a stratum of \\(V\\). Optimal individualized rule can now be derived as \\(d_{opt}(V) = I(\\bar{Q}_{0}(V) &gt; 0)\\). Relying on the Targeted Maximum Likelihood (TML) estimator and the Super Learner estimate of the blip function, we follow the below steps in order to obtain value of the ITR: Estimate \\(\\bar{Q}_{Y,0}(A,W)\\) and \\(g_0(A|W)\\) using sl3. We denote such estimates as \\(\\bar{Q}_{Y,n}(A,W)\\) and \\(g_n(A|W)\\). Apply the doubly robust Augmented-Inverse Probability Weighted (A-IPW) transform to our outcome, where we define: \\[D_{\\bar{Q}_Y,g,a}(O) \\equiv \\frac{I(A=a)}{g(A|W)} (Y-\\bar{Q}_Y(A,W)) + \\bar{Q}_Y(A=a,W)\\] Note that under the randomization and positivity assumptions we have that \\(E[D_{\\bar{Q}_Y,g,a}(O) | V] = E[Y_a |V]\\). We emphasize the double robust nature of the A-IPW transform- consistency of \\(E[Y_a |V]\\) will depend on correct estimation of either \\(\\bar{Q}_{Y,0}(A,W)\\) or \\(g_0(A|W)\\). As such, in a randomized trial, we are guaranteed a consistent estimate of \\(E[Y_a \\mid V]\\) even if we get \\(\\bar{Q}_{Y,0}(A,W)\\) wrong! Using this transform, we can define the following contrast: \\(D_{\\bar{Q}_Y,g}(O) = D_{\\bar{Q}_Y,g,a=1}(O) - D_{\\bar{Q}_Y,g,a=0}(O)\\) We estimate the blip function, \\(\\bar{Q}_{0,a}(V)\\), by regressing \\(D_{\\bar{Q}_Y,g}(O)\\) on \\(V\\) using the specified sl3 library of learners and an appropriate loss function. Our estimated rule is \\(d(V) = \\text{argmax}_{a \\in \\mathcal{A}} \\bar{Q}_{0,a}(V)\\). We obtain inference for the mean outcome under the estimated optimal rule using CV-TMLE. 4.5.0.1 Why CV-TMLE? CV-TMLE is necessary as the non-cross-validated TMLE is biased upward for the mean outcome under the rule, and therefore overly optimistic. More generally however, using CV-TMLE allows us more freedom in estimation and therefore greater data adaptivity, without sacrificing inference! To start, let us load the packages we will use and set a seed for simulation: library(here) library(data.table) library(sl3) library(tmle3) library(tmle3mopttx) library(devtools) set.seed(111) 4.5.0.2 Simulate Data Our data generating distribution is of the following form: data(&quot;data_bin&quot;) The above composes our observed data structure \\(O = (W, A, Y)\\). Note that the mean under the true optimal rule is \\(\\psi=0.578\\) for this data generating distribution. Next, we specify the role that each variable in the data set plays as the nodes in a DAG. # organize data and nodes for tmle3 data &lt;- data_bin node_list &lt;- list( W = c(&quot;W1&quot;, &quot;W2&quot;, &quot;W3&quot;), A = &quot;A&quot;, Y = &quot;Y&quot; ) 4.5.0.3 Constructing Optimal Stacked Regressions with sl3 We generate three different ensemble learners that must be fit, corresponding to the learners for the outcome regression, propensity score, and the blip function. # Define sl3 library and metalearners: xgboost_50 &lt;- Lrnr_xgboost$new(nrounds = 50) xgboost_100 &lt;- Lrnr_xgboost$new(nrounds = 100) xgboost_500 &lt;- Lrnr_xgboost$new(nrounds = 500) lrn1 &lt;- Lrnr_mean$new() lrn2 &lt;- Lrnr_glm_fast$new() lrn3 &lt;- Lrnr_hal9001$new() Q_learner &lt;- Lrnr_sl$new( learners = list(xgboost_50, xgboost_100, xgboost_500, lrn1, lrn2), metalearner = Lrnr_nnls$new() ) g_learner &lt;- Lrnr_sl$new( learners = list(xgboost_100, lrn2), metalearner = Lrnr_nnls$new() ) b_learner &lt;- Lrnr_sl$new( learners = list(xgboost_50, xgboost_100, xgboost_500, lrn1, lrn2), metalearner = Lrnr_nnls$new() ) We make the above explicit with respect to standard notation by bundling the ensemble learners into a list object below: # specify outcome and treatment regressions and create learner list learner_list &lt;- list(Y = Q_learner, A = g_learner, B = b_learner) 4.5.0.4 Targeted Estimation of the Mean under the Optimal Individualized Interventions Effects To start, we will initialize a specification for the TMLE of our parameter of interest simply by calling tmle3_mopttx_blip_revere. We specify the argument V = c(&quot;W1&quot;, &quot;W2&quot;, &quot;W3&quot;) when initializing the tmle3_Spec object in order to communicate that we’re interested in learning a rule dependent on V covariates. We also need to specify the type of blip we will use in this estimation problem, and the list of learners used to estimate the blip function. In addition, we need to specify whether we want to maximize the mean outcome under the rule (maximize=TRUE). If complex=FALSE, tmle3mopttx will consider all the possible rules under a smaller set of covariates including the static rules, and optimize the mean outcome over all the suboptimal rules dependent on \\(V\\). # initialize a tmle specification tmle_spec &lt;- tmle3_mopttx_blip_revere( V = c(&quot;W1&quot;, &quot;W2&quot;, &quot;W3&quot;), type = &quot;blip1&quot;, b_learner = learner_list$B, maximize = TRUE, complex = TRUE ) # fit the TML estimator fit &lt;- tmle3(tmle_spec, data, node_list, learner_list) fit A tmle3_Fit that took 1 step(s) type param init_est tmle_est se lower upper 1: TSM E[Y_{A=NULL}] 0.4289592 0.5701264 0.02749039 0.5162462 0.6240065 psi_transformed lower_transformed upper_transformed 1: 0.5701264 0.5162462 0.6240065 We can see that the estimate of \\(psi_0\\) is \\(0.56\\), and that the confidence interval covers our true mean under the true optimal individualized treatment. 4.6 Extensions to Causal Effect of an Optimal Individualized Intervention We consider two extensions to the procedure described for estimating the value of the ITR. The first one considers a setting where the user might be interested in a grid of possible suboptimal rules, corresponding to potentially limited knowledge of potential effect modifiers (Simpler Rules). The second extension concerns implementation of realistic optimal individual interventions where certain regimes might be preferred, but due to practical or global positivity restraints are not realistic to implement (Realistic Interventions). 4.6.1 Simpler Rules In order to not only consider the most ambitious fully \\(V\\)-optimal rule, we define \\(S\\)-optimal rules as the optimal rule that considers all possible subsets of \\(V\\) covariates, with card(\\(S\\)) \\(\\leq\\) card(\\(V\\)) and \\(\\emptyset \\in S\\). This allows us to consider sub-optimal rules that are easier to estimate and potentially provide more realistic rules- as such, we allow for statistical inference for the counterfactual mean outcome under the sub-optimal rule. # initialize a tmle specification tmle_spec &lt;- tmle3_mopttx_blip_revere( V = c(&quot;W1&quot;, &quot;W2&quot;, &quot;W3&quot;), type = &quot;blip1&quot;, b_learner = learner_list$B, maximize = TRUE, complex = FALSE ) # fit the TML estimator fit &lt;- tmle3(tmle_spec, data, node_list, learner_list) fit A tmle3_Fit that took 1 step(s) type param init_est tmle_est se lower upper 1: TSM E[Y_{A=W3}] 0.4345327 0.5675065 0.02675428 0.515069 0.6199439 psi_transformed lower_transformed upper_transformed 1: 0.5675065 0.515069 0.6199439 Even though the user specified all baseline covariates as the basis for rule estimation, a simpler rule based on only \\(W_3\\) is sufficient to maximize the mean under the optimal individualized treatment! 4.6.2 Realistic Optimal Individual Regimes TO DO 4.6.3 Variable Importance Analysis In the previous sections we have seen how to obtain a contrast between the mean under the optimal individualized rule and the mean under the observed outcome for a single covariate. We are now ready to run the variable importance analysis for all of our observed covariates. We will initialize a specification for the TMLE of our parameter of interest (called a tmle3_Spec in the tlverse nomenclature) simply by calling tmle3_mopttx_vim. # initialize a tmle specification tmle_spec &lt;- tmle3_mopttx_vim( V = c(&quot;W1&quot;, &quot;W2&quot;, &quot;W3&quot;), type = &quot;blip1&quot;, b_learner = learner_list$B, contrast = &quot;multiplicative&quot;, maximize = FALSE, method = &quot;SL&quot; ) # fit the TML estimator vim_results &lt;- tmle3_vim(tmle_spec, data, node_list, learner_list, adjust_for_other_A = FALSE ) vim_results Comment… 4.7 Categorical treatment What if the treatment is categorical? Can we still use the blip function? We define pseudo-blips as vector valued entities where the output for a given \\(V\\) is a vector of length equal to the number of treatment categories, \\(n_A\\). As such, we define it as: \\[\\bar{Q}_0^{pblip}(V) = \\{\\bar{Q}_{0,a}^{pblip}(V): a \\in \\mathcal{A} \\}\\] We implement three different pseudo-blips in tmle3mopttx. Blip1 corresponds to choosing a reference category of treatment, and defining the blip for all other categories relative to the specified reference: \\[\\bar{Q}_{0,a}^{pblip-ref}(V) \\equiv E_0(Y_a-Y_0|V)\\] Blip2 approach corresponds to defining the blip relative to the average of all categories: \\[\\bar{Q}_{0,a}^{pblip-avg}(V) \\equiv E_0(Y_a- \\frac{1}{n_A} \\sum_{a \\in \\mathcal{A}} Y_a|V)\\] Blip3 reflects an extension of Blip2, where the average is now a weighted average: \\[\\bar{Q}_{0,a}^{pblip-wavg}(V) \\equiv E_0(Y_a- \\frac{1}{n_A} \\sum_{a \\in \\mathcal{A}} Y_{a} P(A=a \\mid V) \\mid V)\\] 4.8 Exercise: Optimal Individualized Intervention with Categorical Treatment Our data generating distribution is of the following form: We can just load the data available as part of the package as follows: data(&quot;data_cat&quot;) The mean under the true optimal rule is \\(\\psi=0.625\\), which is the quantity we aim to estimate. 4.8.0.1 Specify the NPSEM # organize data and nodes for tmle3 data &lt;- data_cat node_list &lt;- list( W = c(&quot;W1&quot;, &quot;W2&quot;, &quot;W3&quot;, &quot;W4&quot;), A = &quot;A&quot;, Y = &quot;Y&quot; ) 4.8.0.2 Create the Super Learner library Note that we need to estimate \\(g_0(A|W)\\) for a categorical \\(A\\)- therefore we will need to use the multinomial Super Learner option available within the sl3 package with learners that can address multi-class classification problems. In order to see which learners can be used to estimate \\(g_0(A \\mid W)\\) in sl3, we run the following: # See which learners support multi-class classification: sl3_list_learners(c(&quot;categorical&quot;)) [1] &quot;Lrnr_bartMachine&quot; &quot;Lrnr_dbarts&quot; [3] &quot;Lrnr_glmnet&quot; &quot;Lrnr_grf&quot; [5] &quot;Lrnr_h2o_glm&quot; &quot;Lrnr_h2o_grid&quot; [7] &quot;Lrnr_independent_binomial&quot; &quot;Lrnr_mean&quot; [9] &quot;Lrnr_multivariate&quot; &quot;Lrnr_optim&quot; [11] &quot;Lrnr_randomForest&quot; &quot;Lrnr_ranger&quot; [13] &quot;Lrnr_rpart&quot; &quot;Lrnr_solnp&quot; [15] &quot;Lrnr_svm&quot; &quot;Lrnr_xgboost&quot; In addition, since the corresponding blip will be vector valued, we will have a column for each additional level of treatment. As such, we need to create multivariate learners with the helper function create_mv_learners that takes a list of initialized learners as input. # Initialize some of the learners. # Here we use xgboost with various parameters, glm, HAL and the mean. xgboost_50 &lt;- Lrnr_xgboost$new(nrounds = 50) xgboost_100 &lt;- Lrnr_xgboost$new(nrounds = 100) xgboost_500 &lt;- Lrnr_xgboost$new(nrounds = 500) lrn1 &lt;- Lrnr_mean$new() lrn2 &lt;- Lrnr_glm_fast$new() lrn3 &lt;- Lrnr_hal9001$new() # Define the Q learner, which is just a regular learner: Q_learner &lt;- Lrnr_sl$new( learners = list(xgboost_50, xgboost_100, xgboost_500, lrn1, lrn2), metalearner = Lrnr_nnls$new() ) # Define the g learner, which is a multinomial learner: glib &lt;- list( rf &lt;- make_learner(Lrnr_randomForest), xgb &lt;- make_learner(Lrnr_xgboost), glmnet &lt;- make_learner(Lrnr_glmnet), multinom_gf &lt;- make_learner(Lrnr_independent_binomial, make_learner(Lrnr_glm_fast)), mean &lt;- make_learner(Lrnr_mean) ) # Specify the appropriate loss of the multinomial learner: mn_metalearner &lt;- make_learner(Lrnr_solnp, loss_function = loss_loglik_multinomial, learner_function = metalearner_linear_multinomial ) g_learner &lt;- make_learner(Lrnr_sl, glib, mn_metalearner) # Define the Blip learner, which is a multivariate learner: learners &lt;- list(xgboost_50, xgboost_100, xgboost_500, lrn1, lrn2) b_learner &lt;- create_mv_learners(learners = learners) # specify outcome and treatment regressions and create learner list learner_list &lt;- list(Y = Q_learner, A = g_learner, B = b_learner) 4.8.0.3 Targeted Estimation of the Mean under the Optimal Individualized Interventions Effects Does it matter which blip type we use? # initialize a tmle specification tmle_spec &lt;- tmle3_mopttx_blip_revere( V = c(&quot;W1&quot;, &quot;W2&quot;, &quot;W3&quot;, &quot;W4&quot;), type = &quot;blip2&quot;, b_learner = learner_list$B, maximize = TRUE, complex = TRUE ) # fit the TML estimator fit &lt;- tmle3(tmle_spec, data, node_list, learner_list) fit A tmle3_Fit that took 1 step(s) type param init_est tmle_est se lower upper 1: TSM E[Y_{A=NULL}] 0.4987662 0.5986982 0.02503101 0.5496383 0.6477581 psi_transformed lower_transformed upper_transformed 1: 0.5986982 0.5496383 0.6477581 We can see that the estimate of \\(psi_0\\) is \\(0.58\\), and that the confidence interval covers our true mean under the true optimal individualized treatment. 4.9 Exercise: WASH Benefits Data We cement everything we learned so far with a real data application! We will be using the WASH Benefits data, corresponding to the Effect of water quality, sanitation, hand washing, and nutritional interventions on child development in rural Bangladesh trial. The main aim of the cluster-randomised controlled trial was to assess the impact of six intervention groups, including: chlorinated drinking water improved sanitation handwashing with soap combined water, sanitation, and handwashing improved nutrition through counselling and provision of lipid-based nutrient supplements combined water, sanitation, handwashing, and nutrition. We aim to estimate the optimal ITR and the corresponding value under the optimal ITR for the main intervention in WASH Benefits data. To start, let’s load the data, convert all columns to be of class numeric, and take a quick look at it: washb_data &lt;- fread(here(&quot;data&quot;, &quot;washb_data.csv&quot;), stringsAsFactors = TRUE) washb_data &lt;- washb_data[!is.na(momage), lapply(.SD, as.numeric)] head(washb_data, 3) whz tr fracode month aged sex momage momedu momheight hfiacat Nlt18 Ncomp 1: 0.00 1 4 9 268 2 30 2 146.40 1 3 11 2: -1.16 1 4 9 286 2 25 2 148.75 3 2 4 3: -1.05 1 20 9 264 2 25 2 152.15 1 1 10 watmin elec floor walls roof asset_wardrobe asset_table asset_chair 1: 0 1 0 1 1 0 1 1 2: 0 1 0 1 1 0 1 0 3: 0 0 0 1 1 0 0 1 asset_khat asset_chouki asset_tv asset_refrig asset_bike asset_moto 1: 1 0 1 0 0 0 2: 1 1 0 0 0 0 3: 0 1 0 0 0 0 asset_sewmach asset_mobile 1: 0 1 2: 0 1 3: 0 1 Our outcome of interest is the weight-for-height Z-score which we seek to maximize, whereas our treatment is the six intervention groups aimed at improving living conditions. All the other collected baseline covariates correspond to \\(W\\). node_list &lt;- list( W = names(washb_data)[!(names(washb_data) %in% c(&quot;whz&quot;, &quot;tr&quot;))], A = &quot;tr&quot;, Y = &quot;whz&quot; ) xgboost_100 &lt;- Lrnr_xgboost$new(nrounds = 100) xgboost_500 &lt;- Lrnr_xgboost$new(nrounds = 500) glm_fast &lt;- Lrnr_glm_fast$new() lrn_mean &lt;- Lrnr_mean$new() # Define the Q learner, which is just a regular learner: Q_learner &lt;- Lrnr_sl$new( learners = list(xgboost_100, xgboost_500, lrn_mean), metalearner = Lrnr_nnls$new() ) # Define the g learner, which is a multinomial learner: glib &lt;- list( xgb &lt;- make_learner(Lrnr_xgboost), mean &lt;- make_learner(Lrnr_mean) ) # Specify the appropriate loss of the multinomial learner: mn_metalearner &lt;- make_learner(Lrnr_solnp, loss_function = loss_loglik_multinomial, learner_function = metalearner_linear_multinomial ) g_learner &lt;- make_learner(Lrnr_sl, glib, mn_metalearner) # Define the Blip learner, which is a multivariate learner: learners &lt;- list(xgboost_100, xgboost_500, lrn_mean) b_learner &lt;- create_mv_learners(learners = learners) # specify outcome and treatment regressions and create learner list learner_list &lt;- list(Y = Q_learner, A = g_learner, B = b_learner) We pick a few potential effect modifiers, including mother’s education, current living conditions (floor), and possession of material items including the refrigerator. concentrate of these covariates as they might be indicative of the socio-economic status of individuals involved in the trial. table(washb_data$momedu) 1 2 3 733 1441 2503 table(washb_data$floor) 0 1 4177 500 table(washb_data$asset_refrig) 0 1 4305 372 # initialize a tmle specification tmle_spec &lt;- tmle3_mopttx_blip_revere( V = c(&quot;momedu&quot;, &quot;floor&quot;, &quot;asset_refrig&quot;), type = &quot;blip2&quot;, b_learner = learner_list$B, maximize = TRUE, complex = TRUE ) # fit the TML estimator fit &lt;- tmle3(tmle_spec, data = washb_data, node_list, learner_list) fit A tmle3_Fit that took 1 step(s) type param init_est tmle_est se lower upper 1: TSM E[Y_{A=NULL}] -0.5581545 -0.4882481 0.04424441 -0.5749655 -0.4015306 psi_transformed lower_transformed upper_transformed 1: -0.4882481 -0.5749655 -0.4015306 "],
["stochastic-treatment-regimes.html", "Chapter 5 Stochastic Treatment Regimes 5.1 Learning Objectives 5.2 Introduction 5.3 Stochastic Interventions 5.4 Estimating the Causal Effect of a Stochastic Intervention with tmle3shift 5.5 Stochastic Interventions over a Grid of Counterfactual Shifts 5.6 Exercises", " Chapter 5 Stochastic Treatment Regimes Nima Hejazi, based on the tmle3shift package by Nima Hejazi, Jeremy Coyle, and Mark van der Laan Updated: 2019-05-06 5.1 Learning Objectives Differentiate stochastic treatment regimes from static, dynamic, and optimal treatment regimes. Describe how estimating causal effects of stochastic interventions informs a real-world data analysis. Contrast a population level stochastic intervention policy from a modified treatment policy. Estimate causal effects under stochastic treatment regimes with the tmle3shift R package. Construct marginal structural models to measure variable importance in terms of stochastic interventions, using the grid of shift interventions. Specify a grid of counterfactual shift interventions to be used for defining a set of stochastic intervention policies. Interpret a set of effect estimates from a grid of counterfactual shift interventions. Implement a shift intervention at the individual level, to facilitate shifting each individual to a value that’s supported by the data. Define novel shift intervention functions to extend the tmle3shift R package. 5.2 Introduction In this chapter, we examine a simple example of stochastic treatment regimes in the context of a continuous treatment variable of interest, defining an intuitive causal effect through which to examine stochastic interventions more generally. As a first step to using stochastic treatment regimes in practice, we present the tmle3shift R package, which features an implementation of a recently developed algorithm for computing targeted minimum loss-based estimates of a causal effect based on a stochastic treatment regime that shifts the natural value of the treatment based on a shifting function \\(d(A,W)\\). We will also use tmle3shift to construct marginal structural models for variable importance measures, implement shift interventions at the individual level, and define novel shift intervention functions. 5.3 Stochastic Interventions Present a relatively simple yet extremely flexible manner by which realistic causal effects (and contrasts thereof) may be defined. May be applied to nearly any manner of treatment variable – continuous, ordinal, categorical, binary – allowing for a rich set of causal effects to be defined through this formalism. Arguably the most general of the classes of interventions through which causal effects may be defined, and are conceptually simple. We may consider stochastic interventions in two ways: The equation \\(f_A\\), which produces \\(A\\), is replaced by a probabilistic mechanism \\(g_{\\delta}(A \\mid W)\\) that differs from the original \\(g(A \\mid W)\\). The stochastically modified value of the treatment \\(A_{\\delta}\\) is drawn from a user-specified distribution \\(g_\\delta(A \\mid W)\\), which may depend on the original distribution \\(g(A \\mid W)\\) and is indexed by a user-specified parameter \\(\\delta\\). In this case, the stochastically modified value of the treatment \\(A_{\\delta} \\sim g_{\\delta}(\\cdot \\mid W)\\). The observed value \\(A\\) is replaced by a new value \\(A_{d(A,W)}\\) based on applying a user-defined function \\(d(A,W)\\) to \\(A\\). In this case, the stochastic treatment regime may be viewed as an intervention in which \\(A\\) is set equal to a value based on a hypothetical regime \\(d(A, W)\\), where regime \\(d\\) depends on the treatment level \\(A\\) that would be assigned in the absence of the regime as well as the covariates \\(W\\). Stochastic interventions of this variety may be referred to as depending on the natural value of treatment or as modified treatment policies Haneuse and Rotnitzky (2013) 5.3.1 Identifying the Causal Effect of a Stochastic Intervention The stochastic intervention generates a counterfactual random variable \\(Y_{d(A,W)} := f_Y(d(A,W), W, U_Y) \\equiv Y_{g_{\\delta}} := f_Y(A_{\\delta}, W, U_Y)\\), where the counterfactual outcome \\(Y_{d(A,W)} \\sim \\mathcal{P}_0^{\\delta}\\). The target causal estimand of our analysis is \\(\\psi_{0, \\delta} := \\mathbb{E}_{P_0^{\\delta}}\\{Y_{d(A,W)}\\}\\), the mean of the counterfactual outcome variable \\(Y_{d(A, W)}\\). The statistical target parameter may also be denoted \\(\\Psi(P_0) = \\mathbb{E}_{P_0}{\\overline{Q}(d(A, W), W)}\\), where \\(\\overline{Q}(d(A, W), W)\\) is the counterfactual outcome value of a given individual under the stochastic intervention distribution Díaz and van der Laan (2018). In prior work, Díaz and van der Laan (2012) showed that the causal quantity of interest \\(\\mathbb{E}_0 \\{Y_{d(A, W)}\\}\\) is identified by a functional of the distribution of \\(O\\): \\[\\begin{align*}\\label{eqn:identification2012} \\psi_{0,d} = \\int_{\\mathcal{W}} \\int_{\\mathcal{A}} &amp; \\mathbb{E}_{P_0} \\{Y \\mid A = d(a, w), W = w\\} \\cdot \\\\ &amp;q_{0, A}^O(a \\mid W = w) \\cdot q_{0, W}^O(w) d\\mu(a)d\\nu(w). \\end{align*}\\] The four standard assumptions presented in are necessary in order to establish identifiability of the causal parameter from the observed data via the statistical functional. With the identification assumptions satisfied, Díaz and van der Laan (2012) and Díaz and van der Laan (2018) provide an efficient influence function with respect to the nonparametric model \\(\\mathcal{M}\\) as \\[\\begin{equation*}\\label{eqn:eif} D(P_0)(x) = H(a, w)({y - \\overline{Q}(a, w)}) + \\overline{Q}(d(a, w), w) - \\Psi(P_0), \\end{equation*}\\] where the auxiliary covariate \\(H(a,w)\\) may be expressed \\[\\begin{equation*}\\label{eqn:aux_covar_full} H(a,w) = \\mathbb{I}(a + \\delta &lt; u(w)) \\frac{g_0(a - \\delta \\mid w)} {g_0(a \\mid w)} + \\mathbb{I}(a + \\delta \\geq u(w)), \\end{equation*}\\] which may be reduced to \\[\\begin{equation*}\\label{eqn:aux_covar_simple} H(a,w) = \\frac{g_0(a - \\delta \\mid w)}{g_0(a \\mid w)} + 1 \\end{equation*}\\] in the case that the treatment is in the limits that arise from conditioning on on \\(W\\), i.e., for \\(A_i \\in (u(w) - \\delta, u(w))\\). 5.3.2 Interpreting the Causal Effect of a Stochastic Intervention Figure 5.1: Animation of how a counterfactual outcome changes as the natural treatment distribution is subjected to a simple stochastic intervention 5.4 Estimating the Causal Effect of a Stochastic Intervention with tmle3shift We use tmle3shift to construct a targeted maximum likelihood (TML) estimator of of a causal effect of a stochastic treatment regime that shifts the natural value of the treatment based on a shifting function \\(d(A,W)\\). We will follow the recipe provided by Díaz and van der Laan (2018), tailored to the tmle3 framework: Construct initial estimators \\(g_n\\) of \\(g_0(A, W)\\) and \\(Q_n\\) of \\(\\overline{Q}_0(A, W)\\), perhaps using data-adaptive regression techniques. For each observation \\(i\\), compute an estimate \\(H_n(a_i, w_i)\\) of the auxiliary covariate \\(H(a_i,w_i)\\). Estimate the parameter \\(\\epsilon\\) in the logistic regression model \\[ \\text{logit}\\overline{Q}_{\\epsilon, n}(a, w) = \\text{logit}\\overline{Q}_n(a, w) + \\epsilon H_n(a, w),\\] or an alternative regression model incorporating weights. Compute TML estimator \\(\\Psi_n\\) of the target parameter, defining update \\(\\overline{Q}_n^{\\star}\\) of the initial estimate \\(\\overline{Q}_{n, \\epsilon_n}\\): \\[\\begin{equation*}\\label{eqn:tmle} \\Psi_n = \\Psi(P_n^{\\star}) = \\frac{1}{n} \\sum_{i = 1}^n \\overline{Q}_n^{\\star}(d(A_i, W_i), W_i). \\end{equation*}\\] To start, let’s load the packages we’ll use and set a seed for simulation: library(tidyverse) library(data.table) library(condensier) library(sl3) library(tmle3) library(tmle3shift) set.seed(429153) 1. Construct initial estimators \\(g_n\\) of \\(g_0(A, W)\\) and \\(Q_n\\) of \\(\\overline{Q}_0(A, W)\\). We need to estimate two components of the likelihood in order to construct a TML estimator. The outcome regression, \\(\\hat{Q}_n\\), which is a simple regression of the form \\(\\mathbb{E}[Y \\mid A,W]\\). # learners used for conditional expectation regression lrn_mean &lt;- Lrnr_mean$new() lrn_fglm &lt;- Lrnr_glm_fast$new() lrn_xgb &lt;- Lrnr_xgboost$new(nrounds = 200) sl_lrn &lt;- Lrnr_sl$new( learners = list(lrn_mean, lrn_fglm, lrn_xgb), metalearner = Lrnr_nnls$new() ) The treatment mechanism, \\(\\hat{g}_n\\), i.e., the propensity score. In the case of a continuous intervention, such a quantity is a conditional density. Generally speaking, conditional density estimation is a challenging problem that has received much attention in the literature. To estimate the treatment mechanism, we must make use of learning algorithms specifically suited to conditional density estimation; a list of such learners may be extracted from sl3 by using sl3_list_learners(): sl3_list_learners(&quot;density&quot;) [1] &quot;Lrnr_condensier&quot; &quot;Lrnr_haldensify&quot; &quot;Lrnr_rfcde&quot; [4] &quot;Lrnr_solnp_density&quot; To proceed, we’ll select two of the above learners, Lrnr_haldensify for using the highly adaptive lasso for conditional density estimation, based on an algorithm given by Díaz and van der Laan (2011) and implemented in Hejazi (2019), and Lrnr_rfcde, an approach for using random forests for conditional density estimation (Pospisil and Lee 2018). A Super Learner may be constructed by pooling estimates from each of these modified conditional density regression techniques. # learners used for conditional density regression (i.e., propensity score) lrn_haldensify &lt;- Lrnr_haldensify$new( n_bins = 5, grid_type = &quot;equal_mass&quot;, lambda_seq = exp(seq(-1, -13, length = 500)) ) lrn_rfcde &lt;- Lrnr_rfcde$new( n_trees = 1000, node_size = 5, n_basis = 31, output_type = &quot;observed&quot; ) sl_lrn_dens &lt;- Lrnr_sl$new( learners = list(lrn_haldensify, lrn_rfcde), metalearner = Lrnr_solnp_density$new() ) Finally, we construct a learner_list object for use in constructing a TML estimator of our target parameter of interest: Q_learner &lt;- sl_lrn g_learner &lt;- sl_lrn_dens learner_list &lt;- list(Y = Q_learner, A = g_learner) 5.4.1 Simulate Data # simulate simple data for tmle-shift sketch n_obs &lt;- 1000 # number of observations tx_mult &lt;- 2 # multiplier for the effect of W = 1 on the treatment ## baseline covariates -- simple, binary W &lt;- replicate(2, rbinom(n_obs, 1, 0.5)) ## create treatment based on baseline W A &lt;- rnorm(n_obs, mean = tx_mult * W, sd = 1) ## create outcome as a linear function of A, W + white noise Y &lt;- rbinom(n_obs, 1, prob = plogis(A + W)) # organize data and nodes for tmle3 data &lt;- data.table(W, A, Y) setnames(data, c(&quot;W1&quot;, &quot;W2&quot;, &quot;A&quot;, &quot;Y&quot;)) node_list &lt;- list(W = c(&quot;W1&quot;, &quot;W2&quot;), A = &quot;A&quot;, Y = &quot;Y&quot;) head(data) W1 W2 A Y 1: 1 1 3.5806529 1 2: 1 0 3.2071846 1 3: 1 1 1.0358382 1 4: 0 0 -0.6578495 1 5: 1 1 3.0199033 1 6: 1 1 2.7803127 1 We now have an observed data structure (data) and a specification of the role that each variable in the data set plays as the nodes in a directed acyclic graph (DAG) via nonparametric structural equation models (NPSEMs). To start, we will initialize a specification for the TMLE of our parameter of interest (a tmle3_Spec in the tlverse nomenclature) simply by calling tmle_shift. We specify the argument shift_val = 0.5 when initializing the tmle3_Spec object to communicate that we’re interested in a shift of \\(0.5\\) on the scale of the treatment \\(A\\) – that is, we specify \\(\\delta = 0.5\\). # initialize a tmle specification tmle_spec &lt;- tmle_shift( shift_val = 0.5, shift_fxn = shift_additive_bounded, shift_fxn_inv = shift_additive_bounded_inv ) As seen above, the tmle_shift specification object (like all tmle3_Spec objects) does not store the data for our specific analysis of interest. Later, we’ll see that passing a data object directly to the tmle3 wrapper function, alongside the instantiated tmle_spec, will serve to construct a tmle3_Task object internally (see the tmle3 documentation for details). Note that in the initialization of the tmle3_Spec, we specified a shifting function shift_additive_bounded (and its inverse). This shifting function corresponds to a stochastic regime slightly more complicated than that initially considered in Díaz and van der Laan (2018). In particular, shift_additive_bounded is encapsulates a procedure that determines an acceptable set of shifting values for the shift \\(\\delta\\), allowing for the observed treatment value of a given observation to be shifted if the auxiliary covariate \\(H_n\\) is bounded by a constant and not shifting the given observation if this criterion does not hold. We discuss this in greater detail in the sequel. 5.4.2 Targeted Estimation of Stochastic Interventions Effects tmle_fit &lt;- tmle3(tmle_spec, data, node_list, learner_list) Iter: 1 fn: 1374.0974 Pars: 0.80529 0.19471 Iter: 2 fn: 1374.0974 Pars: 0.80530 0.19470 solnp--&gt; Completed in 2 iterations tmle_fit A tmle3_Fit that took 1 step(s) type param init_est tmle_est se lower upper 1: TSM E[Y_{A=NULL}] 0.7949624 0.7962288 0.01209385 0.7725253 0.8199323 psi_transformed lower_transformed upper_transformed 1: 0.7962288 0.7725253 0.8199323 The print method of the resultant tmle_fit object conveniently displays the results from computing our TML estimator. 5.5 Stochastic Interventions over a Grid of Counterfactual Shifts Consider an arbitrary scalar \\(\\delta\\) that defines a counterfactual outcome \\(\\psi_n = Q_n(d(A, W), W)\\), where, for simplicity, let \\(d(A, W) = A + \\delta\\). A simplified expression of the auxiliary covariate for the TMLE of \\(\\psi\\) is \\(H_n = \\frac{g^{\\star}(a \\mid w)}{g(a \\mid w)}\\), where \\(g^{\\star}(a \\mid w)\\) defines the treatment mechanism with the stochastic intervention implemented. In this manner, we can specify a grid of shifts \\(\\delta\\) to define a set of stochastic intervention policies in an a priori manner. To ascertain whether a given choice of the shift \\(\\delta\\) is acceptable, let there be a bound \\(C(\\delta) = \\frac{g^{\\star}(a \\mid w)}{g(a \\mid w)} &lt; M\\), where \\(g^{\\star}(a \\mid w)\\) is a function of \\(\\delta\\) in part, and \\(M\\) is a user-specified upper bound of \\(C(\\delta)\\). Then, \\(C(\\delta)\\) is a measure of the influence of a given observation (under a bound of the ratio of the conditional densities), which provides a way to limit the maximum influence of a given observation through a choice of the shift \\(\\delta\\). For the purpose of using such a shift in practice, the present software provides the functions shift_additive_bounded and shift_additive_bounded_inv, which define a variation of this shift: \\[\\begin{equation} \\delta(a, w) = \\begin{cases} \\delta, &amp; C(\\delta) \\leq M \\\\ 0, \\text{otherwise} \\\\ \\end{cases}, \\end{equation}\\] which corresponds to an intervention in which the natural value of treatment of a given observational unit is shifted by a value \\(\\delta\\) in the case that the ratio of the intervened density \\(g^{\\star}(a \\mid w)\\) to the natural density \\(g(a \\mid w)\\) (that is, \\(C(\\delta)\\)) does not exceed a bound \\(M\\). In the case that the ratio \\(C(\\delta)\\) exceeds the bound \\(M\\), the stochastic intervention policy does not apply to the given unit and they remain at their natural value of treatment \\(a\\). 5.5.1 Initializing vimshift through its tmle3_Spec To start, we will initialize a specification for the TMLE of our parameter of interest (called a tmle3_Spec in the tlverse nomenclature) simply by calling tmle_shift. We specify the argument shift_grid = seq(-1, 1, by = 1) when initializing the tmle3_Spec object to communicate that we’re interested in assessing the mean counterfactual outcome over a grid of shifts -1, 0, 1 on the scale of the treatment \\(A\\). # what&#39;s the grid of shifts we wish to consider? delta_grid &lt;- seq(-1, 1, 1) # initialize a tmle specification tmle_spec &lt;- tmle_vimshift_delta( shift_grid = delta_grid, max_shifted_ratio = 2 ) 5.5.2 Targeted Estimation of Stochastic Intervention Effects One may walk through the step-by-step procedure for fitting the TML estimator of the mean counterfactual outcome under each shift in the grid, using the machinery exposed by the tmle3 R package, or simply invoke the tmle3 wrapper function to fit the series of TML estimators (one for each parameter defined by the grid delta) in a single function call. For convenience, we choose the latter: tmle_fit &lt;- tmle3(tmle_spec, data, node_list, learner_list) Iter: 1 fn: 1375.2014 Pars: 0.80068 0.19932 Iter: 2 fn: 1375.2014 Pars: 0.80068 0.19932 solnp--&gt; Completed in 2 iterations tmle_fit A tmle3_Fit that took 1 step(s) type param init_est tmle_est se lower upper 1: TSM E[Y_{A=NULL}] 0.6289292 0.6287832 0.01411715 0.6011141 0.6564523 2: TSM E[Y_{A=NULL}] 0.7386592 0.7390000 0.01389504 0.7117662 0.7662338 3: TSM E[Y_{A=NULL}] 0.8437334 0.8461638 0.01009108 0.8263856 0.8659419 4: MSM_linear MSM(intercept) 0.7369852 0.7379017 0.01203307 0.7143173 0.7614861 5: MSM_linear MSM(slope) 0.1071872 0.1085517 0.00444074 0.0998480 0.1172554 psi_transformed lower_transformed upper_transformed 1: 0.6287832 0.6011141 0.6564523 2: 0.7390000 0.7117662 0.7662338 3: 0.8461638 0.8263856 0.8659419 4: 0.7379017 0.7143173 0.7614861 5: 0.1085517 0.0998480 0.1172554 Remark: The print method of the resultant tmle_fit object conveniently displays the results from computing our TML estimator. 5.5.3 Inference with Marginal Structural Models Since we consider estimating the mean counterfactual outcome \\(\\psi_n\\) under several values of the intervention \\(\\delta\\), taken from the aforementioned \\(\\delta\\)-grid, one approach for obtaining inference on a single summary measure of these estimated quantities involves leveraging working marginal structural models (MSMs). Summarizing the estimates \\(\\psi_n\\) through a working MSM allows for inference on the trend imposed by a \\(\\delta\\)-grid to be evaluated via a simple hypothesis test on a parameter of this working MSM. Letting \\(\\psi_{\\delta}(P_0)\\) be the mean outcome under a shift \\(\\delta\\) of the treatment, we have \\(\\vec{\\psi}_{\\delta} = (\\psi_{\\delta}: \\delta)\\) with corresponding estimators \\(\\vec{\\psi}_{n, \\delta} = (\\psi_{n, \\delta}: \\delta)\\). Further, let \\(\\beta(\\vec{\\psi}_{\\delta}) = \\phi((\\psi_{\\delta}: \\delta))\\). By a straightforward application of the delta method (discussed previously), we may write the efficient influence function of the MSM parameter \\(\\beta\\) in terms of the EIFs of each of the corresponding point estimates. Based on this, inference from a working MSM is rather straightforward. To wit, the limiting distribution for \\(m_{\\beta}(\\delta)\\) may be expressed \\[\\sqrt{n}(\\beta_n - \\beta_0) \\to N(0, \\Sigma),\\] where \\(\\Sigma\\) is the empirical covariance matrix of \\(\\text{EIF}_{\\beta}(O)\\). tmle_fit$summary[4:5, ] type param init_est tmle_est se lower upper 1: MSM_linear MSM(intercept) 0.7369852 0.7379017 0.01203307 0.7143173 0.7614861 2: MSM_linear MSM(slope) 0.1071872 0.1085517 0.00444074 0.0998480 0.1172554 psi_transformed lower_transformed upper_transformed 1: 0.7379017 0.7143173 0.7614861 2: 0.1085517 0.0998480 0.1172554 5.5.4 Directly Targeting the MSM Parameter \\(\\beta\\) Note that in the above, a working MSM is fit to the individual TML estimates of the mean counterfactual outcome under a given value of the shift \\(\\delta\\) in the supplied grid. The parameter of interest \\(\\beta\\) of the MSM is asymptotically linear (and, in fact, a TML estimator) as a consequence of its construction from individual TML estimators. In smaller samples, it may be prudent to perform a TML estimation procedure that targets the parameter \\(\\beta\\) directly, as opposed to constructing it from several independently targeted TML estimates. An approach for constructing such an estimator is proposed in the sequel. Suppose a simple working MSM \\(\\mathbb{E}Y_{g^0_{\\delta}} = \\beta_0 + \\beta_1 \\delta\\), then a TML estimator targeting \\(\\beta_0\\) and \\(\\beta_1\\) may be constructed as \\[\\overline{Q}_{n, \\epsilon}(A,W) = \\overline{Q}_n(A,W) + \\epsilon (H_1(g), H_2(g),\\] for all \\(\\delta\\), where \\(H_1(g)\\) is the auxiliary covariate for \\(\\beta_0\\) and \\(H_2(g)\\) is the auxiliary covariate for \\(\\beta_1\\). To construct a targeted maximum likelihood estimator that directly targets the parameters of the working marginal structural model, we may use the tmle_vimshift_msm Spec (instead of the tmle_vimshift_delta Spec that appears above): # initialize a tmle specification tmle_msm_spec &lt;- tmle_vimshift_msm( shift_grid = delta_grid, max_shifted_ratio = 2 ) # fit the TML estimator and examine the results tmle_msm_fit &lt;- tmle3(tmle_msm_spec, data, node_list, learner_list) Iter: 1 fn: 1377.7427 Pars: 0.78219 0.21781 Iter: 2 fn: 1377.7427 Pars: 0.78219 0.21781 solnp--&gt; Completed in 2 iterations tmle_msm_fit A tmle3_Fit that took 100 step(s) type param init_est tmle_est se lower 1: MSM_linear MSM(intercept) 0.7368652 0.7368652 0.012047233 0.71325310 2: MSM_linear MSM(slope) 0.1072669 0.1072669 0.004416694 0.09861038 upper psi_transformed lower_transformed upper_transformed 1: 0.7604774 0.7368652 0.71325310 0.7604774 2: 0.1159235 0.1072669 0.09861038 0.1159235 5.5.5 Example with the WASH Benefits Data To complete our walk through, let’s turn to using stochastic interventions to investigate the data from the WASH Benefits trial. To start, let’s load the data, convert all columns to be of class numeric, and take a quick look at it washb_data &lt;- fread(here(&quot;data&quot;, &quot;washb_data.csv&quot;), stringsAsFactors = TRUE) washb_data &lt;- washb_data[!is.na(momage), lapply(.SD, as.numeric)] head(washb_data, 3) whz tr fracode month aged sex momage momedu momheight hfiacat Nlt18 Ncomp 1: 0.00 1 4 9 268 2 30 2 146.40 1 3 11 2: -1.16 1 4 9 286 2 25 2 148.75 3 2 4 3: -1.05 1 20 9 264 2 25 2 152.15 1 1 10 watmin elec floor walls roof asset_wardrobe asset_table asset_chair 1: 0 1 0 1 1 0 1 1 2: 0 1 0 1 1 0 1 0 3: 0 0 0 1 1 0 0 1 asset_khat asset_chouki asset_tv asset_refrig asset_bike asset_moto 1: 1 0 1 0 0 0 2: 1 1 0 0 0 0 3: 0 1 0 0 0 0 asset_sewmach asset_mobile 1: 0 1 2: 0 1 3: 0 1 Next, we specify our NPSEM via the node_list object. For our example analysis, we’ll consider the outcome to be the weight-for-height Z-score (as in previous chapters), the intervention of interest to be the mother’s age at time of child’s birth, and take all other covariates to be potential confounders. node_list &lt;- list( W = names(washb_data)[!(names(washb_data) %in% c(&quot;whz&quot;, &quot;momage&quot;))], A = &quot;momage&quot;, Y = &quot;whz&quot; ) Were we to consider the counterfactual weight-for-height Z-score under shifts in the age of the mother at child’s birth, how would we interpret estimates of our parameter? To simplify our interpretation, consider a shift of just a year in the mother’s age (i.e., \\(\\delta = 1\\)); in this setting, a stochastic intervention would correspond to a policy advocating that potential mothers defer having a child for a single calendar year, possibly implemented through an encouragement design deployed in a clinical setting. For this example, we’ll use the variable importance strategy of considering a grid of stochastic interventions to evaluate the weight-for-height Z-score under a shift in the mother’s age down by two years (\\(\\delta = -2\\)), up by two years (\\(\\delta = 2\\)), and under no shift at all (\\(\\delta = 0\\)). To do this, we simply initialize a Spec tmle_vimshift_delta just as we did in a previous example # initialize a tmle specification for the variable importance parameter washb_vim_spec &lt;- tmle_vimshift_delta( shift_grid = c(-2, 2), max_shifted_ratio = 2 ) Prior to running our analysis, we’ll modify the learner_list object we had created such that the density estimation procedure we rely on will be only the random forest conditional density estimation procedure of Pospisil and Lee (2018), as the nonparametric conditional density approach based on the highly adaptive lasso (Díaz and van der Laan 2011; Benkeser and van der Laan 2016; Coyle and Hejazi 2018; Hejazi 2019) is currently unable to accommodate large datasets. # learners used for conditional density regression (i.e., propensity score) lrn_rfcde &lt;- Lrnr_rfcde$new( n_trees = 500, node_size = 3, n_basis = 20, output_type = &quot;observed&quot; ) # modify learner list, using existing SL for Q fit learner_list &lt;- list(Y = sl_lrn, A = lrn_rfcde) Having made the above preparations, we’re now ready to estimate the counterfactual mean of the weight-for-height Z-score under a small grid of shifts in the mother’s age at child’s birth. Just as before, we do this through a simple call to our tmle3 wrapper function: washb_tmle_fit &lt;- tmle3(washb_vim_spec, washb_data, node_list, learner_list) washb_tmle_fit 5.6 Exercises 5.6.1 Review of Key Concepts TODO Set the sl3 library of algorithms for the Super Learner to a simple, interpretable library and use this new library to estimate the counterfactual mean of mother’s age at child’s birth (momage) under a shift \\(\\delta = 0\\). What does this counterfactual mean equate to in terms of the observed data? Describe two (equivalent) ways in which the causal effects of stochastic interventions may be interpreted. TODO 5.6.2 The Ideas in Action Choose a different variable of interest (e.g., TBD) and repeat the initial analysis we performed. That is, estimate the counterfactual mean under a shift of the new variable, after standardizing the chosen variable to have zero mean and unit variance. Interpret your findings. Using a grid of values of the shift parameter \\(\\delta\\) (e.g., \\(\\{-1, 0, +1\\}\\)), repeat the analysis on the variable chosen in the preceding question, summarizing the trend for this sequence of shifts using a marginal structural model. Repeat the preceding analysis, using the same grid of shifts, but instead directly targeting the parameters of the marginal structural model. Interpret the results – that is, what does the slope of the marginal structural model tell us about the trend across the chosen sequence of shifts? 5.6.3 Advanced Topics How does the marginal structural model we used to summarize the trend along the sequence of shifts previously help to contextualize the estimated effect for a single shift? That is, how does access to estimates across several shifts and the marginal structural model parameters allow us to more richly interpret our findings? What advantages, if any, are there to targeting directly the parameters of a marginal structural model? References "],
["references.html", "References", " References "]
]
