# Stochastic Treatment Regimes

_Nima Hejazi_, based on the [`tmle3shift`
package](https://github.com/tlverse/tmle3shift) by _Nima Hejazi, Jeremy Coyle,
and Mark van der Laan_

Updated: `r Sys.Date()`

## Learning Objectives

1. Differentiate stochastic treatment regimes from static, dynamic, and optimal treatment regimes.
2. Describe how estimating causal effects of stochastic interventions informs a real-world data analysis.
3. Contrast a population level stochastic intervention policy from a modified treatment policy.
4. Estimate causal effects under stochastic treatment regimes with the `tmle3shift` `R` package.
5. Construct marginal structural models to measure variable importance in terms of stochastic interventions, using the grid of shift interventions.
6. Specify a grid of counterfactual shift interventions to be used for defining a set of stochastic intervention policies.
7. Interpret a set of effect estimates from a grid of counterfactual shift interventions.
8. Implement a shift intervention at the individual level, to facilitate shifting each individual to a value that's supported by the data.
9. Define novel shift intervention functions to extend the `tmle3shift` `R` package.

## Introduction

In this chapter, we examine a simple example of stochastic treatment regimes in
the context of a continuous treatment variable of interest, defining an
intuitive causal effect through which to examine stochastic interventions more
generally. As a first step to using stochastic
treatment regimes in practice, we present the [`tmle3shift` R
package](https://github.com/tlverse/tmle3shift), which features an
implementation of a recently developed algorithm for computing targeted minimum
loss-based estimates of a causal effect based on a stochastic treatment regime
that shifts the natural value of the treatment based on a shifting function
$d(A,W)$. We will also use `tmle3shift` to construct marginal structural models
for variable importance measures, implement shift interventions at the
individual level, and define novel shift intervention functions.

## Stochastic Interventions

* Present a relatively simple yet extremely flexible manner by which _realistic_ causal effects (and contrasts thereof) may be defined.
* May be applied to nearly any manner of treatment variable -- continuous,
ordinal, categorical, binary -- allowing for a rich set of causal effects to be defined through this formalism.
* Arguably the most general of the classes of interventions through which causal effects may be defined, and are conceptually simple.

* We may consider stochastic interventions in two ways:

1. The equation $f_A$, which produces $A$, is replaced by a probabilistic
   mechanism $g_{\delta}(A \mid W)$ that differs from the original $g(A \mid
   W)$. The _stochastically modified_ value of the treatment $A_{\delta}$ is
   drawn from a user-specified distribution $g_\delta(A \mid W)$, which may
   depend on the original distribution $g(A \mid W)$ and is indexed by a user-specified parameter $\delta$. In this case, the stochastically modified
   value of the treatment $A_{\delta} \sim g_{\delta}(\cdot \mid W)$.

2. The observed value $A$ is replaced by a new value $A_{d(A,W)}$ based
   on applying a user-defined function $d(A,W)$ to $A$. In this case, the
   stochastic treatment regime may be viewed as an intervention in which $A$ is
   set equal to a value based on a hypothetical regime $d(A, W)$, where regime
   $d$ depends on the treatment level $A$ that would be assigned in the absence
   of the regime as well as the covariates $W$. Stochastic interventions of
   this variety may be referred to as depending on the _natural value of
   treatment_ or as _modified treatment policies_ @haneuse2013estimation
   @young2014identification.

### Identifying the Causal Effect of a Stochastic Interventions

* The stochastic intervention generates a counterfactual random variable
$Y_{d(A,W)} := f_Y(d(A,W), W, U_Y) \equiv Y_{g_{\delta}} := f_Y(A_{\delta}, W,
  U_Y)$, where the counterfactual outcome $Y_{d(A,W)} \sim
  \mathcal{P}_0^{\delta}$.

* The target causal estimand of our analysis is $\psi_{0, \delta} :=
  \mathbb{E}_{P_0^{\delta}}\{Y_{d(A,W)}\}$, the mean of the counterfactual
  outcome variable $Y_{d(A, W)}$. The statistical target parameter may also be denoted $\Psi(P_0) = \mathbb{E}_{P_0}{\overline{Q}(d(A, W), W)}$, where
  $\overline{Q}(d(A, W), W)$ is the counterfactual outcome value of a given
  individual under the stochastic intervention distribution @diaz2018stochastic.

* In prior work, @diaz2012population showed that
the causal quantity of interest $\mathbb{E}_0 \{Y_{d(A, W)}\}$ is identified
by a functional of the distribution of $O$:
  \begin{align*}\label{eqn:identification2012}
    \psi_{0,d} = \int_{\mathcal{W}} \int_{\mathcal{A}} & \mathbb{E}_{P_0}
     \{Y \mid A = d(a, w), W = w\} \cdot \\ &q_{0, A}^O(a \mid W = w) \cdot
     q_{0, W}^O(w) d\mu(a)d\nu(w).
  \end{align*}

* The four standard assumptions presented in \ref{intro} are
necessary in order to establish identifiability of the causal parameter from the observed data via the statistical functional.

* With the identification assumptions satisfied, @diaz2012population and
@diaz2018stochastic provide an efficient influence function with respect to
the nonparametric model $\mathcal{M}$ as
\begin{equation*}\label{eqn:eif}
  D(P_0)(x) = H(a, w)({y - \overline{Q}(a, w)}) +
  \overline{Q}(d(a, w), w) - \Psi(P_0),
\end{equation*}
where the auxiliary covariate $H(a,w)$ may be expressed
\begin{equation*}\label{eqn:aux_covar_full}
  H(a,w) = \mathbb{I}(a + \delta < u(w)) \frac{g_0(a - \delta \mid w)}
  {g_0(a \mid w)} + \mathbb{I}(a + \delta \geq u(w)),
\end{equation*}
which may be reduced to
\begin{equation*}\label{eqn:aux_covar_simple}
  H(a,w) = \frac{g_0(a - \delta \mid w)}{g_0(a \mid w)} + 1
\end{equation*}
in the case that the treatment is in the limits that arise from conditioning on
$W$, i.e., for $A_i \in (u(w) - \delta, u(w))$.

### Interpreting the Causal Effect of a Stochastic Intervention

```{r, fig.cap="Animation of how a counterfactual outcome changes as the natural treatment distribution is subjected to a simple stochastic intervention", echo=FALSE, eval=TRUE, out.width='60%'}
knitr::include_graphics(path = "img/gif/shift_animation.gif")
```

## Estimating the Causal Effect of a Stochastic Intervention with `tmle3shift`

We use `tmle3shift` to construct a targeted maximum likelihood (TML) estimator
of a causal effect of a stochastic treatment regime that shifts the natural
value of the treatment based on a shifting function $d(A,W)$. We will follow the recipe provided by @diaz2018stochastic, tailored to the `tmle3` framework:

1. Construct initial estimators $g_n$ of $g_0(A, W)$ and $Q_n$ of
   $\overline{Q}_0(A, W)$, perhaps using data-adaptive regression techniques.
2. For each observation $i$, compute an estimate $H_n(a_i, w_i)$ of the
   auxiliary covariate $H(a_i,w_i)$.
3. Estimate the parameter $\epsilon$ in the logistic regression model
   $$ \text{logit}\overline{Q}_{\epsilon, n}(a, w) =
   \text{logit}\overline{Q}_n(a, w) + \epsilon H_n(a, w),$$
   or an alternative regression model incorporating weights.
4. Compute TML estimator $\Psi_n$ of the target parameter, defining update
   $\overline{Q}_n^{\star}$ of the initial estimate
   $\overline{Q}_{n, \epsilon_n}$:
   \begin{equation*}\label{eqn:tmle}
     \Psi_n = \Psi(P_n^{\star}) = \frac{1}{n} \sum_{i = 1}^n
     \overline{Q}_n^{\star}(d(A_i, W_i), W_i).
   \end{equation*}

To start, let us load the packages we will use and set a seed for simulation:

```{r setup-shift, message=FALSE, warning=FALSE}
library(tidyverse)
library(data.table)
library(condensier)
library(sl3)
library(tmle3)
library(tmle3shift)
set.seed(429153)
```

**1. Construct initial estimators $g_n$ of $g_0(A, W)$ and $Q_n$ of
   $\overline{Q}_0(A, W)$.**

We need to estimate two components of the likelihood in order to construct a
TML estimator.

1. The outcome regression, $\hat{Q}_n$, which is a simple regression of the form $\mathbb{E}[Y \mid A,W]$.

```{r sl3_lrnrs-Qfit-shift, message=FALSE, warning=FALSE}
# learners used for conditional expectation regression
lrn_mean <- Lrnr_mean$new()
lrn_fglm <- Lrnr_glm_fast$new()
lrn_xgb <- Lrnr_xgboost$new(nrounds = 200)
lrn_hal <- Lrnr_hal9001$new()
sl_lrn <- Lrnr_sl$new(
  learners = list(lrn_mean, lrn_fglm), # , lrn_xgb, lrn_hal),
  metalearner = Lrnr_nnls$new()
)
```

2. The treatment mechanism, $\hat{g}_n$, i.e., the _propensity score_. In the
case of a continuous intervention, such a quantity is a conditional density. For
this, we use arbitrary regression functions to generate conditional density
estimates, a hazard-based approach @diaz2011super.

```{r l3_lrnrs-gfit-shift, message=FALSE, warning=FALSE}
# learners used for conditional density regression
lrn_mean_dens <- Lrnr_condensier$new(
  nbins = 20, bin_estimator = lrn_mean,
  bin_method = "dhist"
)
lrn_fglm_dens <- Lrnr_condensier$new(
  nbins = 10, bin_estimator = lrn_fglm,
  bin_method = "dhist"
)
lrn_xgb_dens <- Lrnr_condensier$new(
  nbins = 5, bin_estimator = lrn_xgb,
  bin_method = "dhist"
)
sl_lrn_dens <- Lrnr_sl$new(
  learners = list(lrn_mean_dens, lrn_fglm_dens, lrn_xgb_dens),
  metalearner = Lrnr_solnp_density$new()
)

# specify outcome and treatment regressions and create learner list
Q_learner <- sl_lrn
g_learner <- sl_lrn_dens
learner_list <- list(Y = Q_learner, A = g_learner)
```

### Simulate Data

```{r sim_data, message=FALSE, warning=FALSE}
# simulate simple data for tmle-shift sketch
n_obs <- 1000 # number of observations
tx_mult <- 2 # multiplier for the effect of W = 1 on the treatment

## baseline covariates -- simple, binary
W <- replicate(2, rbinom(n_obs, 1, 0.5))

## create treatment based on baseline W
A <- rnorm(n_obs, mean = tx_mult * W, sd = 1)

## create outcome as a linear function of A, W + white noise
Y <- rbinom(n_obs, 1, prob = plogis(A + W))

# organize data and nodes for tmle3
data <- data.table(W, A, Y)
setnames(data, c("W1", "W2", "A", "Y"))
node_list <- list(W = c("W1", "W2"), A = "A", Y = "Y")
head(data)
```

We now have an observed data structure (`data`) and a specification of the role
that each variable in the data set plays as the nodes in a _directed acyclic graph_ (DAG) via _nonparametric structural equation models_ (NPSEMs).

To start, we will initialize a specification for the TMLE of our parameter of
interest (called a `tmle3_Spec` in the `tlverse` nomenclature) simply by calling
`tmle_shift`. We specify the argument `shift_val = 0.5` when initializing the
`tmle3_Spec` object to communicate that we're interested in a shift of $0.5$ on
the scale of the treatment $A$ -- that is, we specify $\delta = 0.5$ (note that
this is an arbitrarily chosen value for this example).

```{r spec_init-shift, message=FALSE, warning=FALSE}
# initialize a tmle specification
tmle_spec <- tmle_shift(
  shift_val = 0.5,
  shift_fxn = shift_additive_bounded,
  shift_fxn_inv = shift_additive_bounded_inv
)
```

As seen above, the `tmle_shift` specification object (like all `tmle3_Spec`
objects) does _not_ store the data for our specific analysis of interest. Later,
we'll see that passing a data object directly to the `tmle3` wrapper function,
alongside the instantiated `tmle_spec`, will serve to construct a `tmle3_Task`
object internally (see the `tmle3` documentation for details).

### Targeted Estimation of Stochastic Interventions Effects

```{r fit_tmle-shift, message=FALSE, warning=FALSE, cache=FALSE}
tmle_fit <- tmle3(tmle_spec, data, node_list, learner_list)
tmle_fit
```

The `print` method of the resultant `tmle_fit` object conveniently displays the
results from computing our TML estimator.

## Variable Importance Analysis with Stochastic Interventions

### Defining a grid of possible counterfactual shift interventions

* Consider an arbitrary scalar $\delta$ that defines a counterfactual outcome
$\psi_n = Q_n(d(A, W), W)$, where, for simplicity, let $d(A, W) = A + \delta$. A
simplified expression of the auxiliary covariate for the TMLE of $\psi$ is
$H_n = \frac{g^*(a \mid w)}{g(a \mid w)}$, where $g^*(a \mid w)$ defines the
treatment mechanism with the stochastic intervention implemented. In this manner,
we can specify a _grid_ of shifts $\delta$ to define a set of stochastic
intervention policies in an _a priori_ manner.

* To ascertain whether a given choice of the shift $\delta$ is admissable (in the
sense of avoiding violations of the positivity assumption), let there be a bound
$C(\delta) = \frac{g^\*(a \mid w)}{g(a \mid w)} < M$, where $g^\*(a \mid w)$ is
a function of $\delta$ in part, and $M$ is a potentially user-specified upper
bound of $C(\delta)$. Then, $C(\delta)$ is a measure of the influence of a given
observation (under a bound of the conditional densities), which provides a way
to limit the maximum influence of a given observation through a choice of the
shift $\delta$.

* We formalize and extend the procedure to determine an acceptable set of values
for the shift $\delta$, which provides a strategy for implementing a shift at the level of a given observation $(a_i, w_i)$, thereby allowing for all observations
to be shifted to an appropriate value -- whether $\delta_{\text{min}}$,
$\delta$, or $\delta_{\text{max}}$. For a shift $d(A,
W) = A + \delta(A, W)$, define the shift $\delta(A, W)$ as
\begin{equation}
  \delta(a, w) =
    \begin{cases}
      \delta, & \delta_{\text{min}}(a,w) \leq \delta \leq
        \delta_{\text{max}}(a,w) \\
      \delta_{\text{max}}(a,w), & \delta \geq \delta_{\text{max}}(a,w) \\
      \delta_{\text{min}}(a,w), & \delta \leq \delta_{\text{min}}(a,w) \\
    \end{cases},
\end{equation}
where $$\delta_{\text{max}}(a, w) = \text{argmax}_{\left\{\delta \geq 0,
\frac{g(a - \delta \mid w)}{g(a \mid w)} \leq M \right\}} \frac{g(a - \delta
\mid w)}{g(a \mid w)}$$ and
$$\delta_{\text{min}}(a, w) = \text{argmin}_{\left\{\delta \leq 0,
\frac{g(a - \delta \mid w)}{g(a \mid w)} \leq M \right\}} \frac{g(a - \delta
\mid w)}{g(a \mid w)}.$$

### Initializing `vimshift` through its `tmle3_Spec`

To start, we will initialize a specification for the TMLE of our parameter of
interest (called a `tmle3_Spec` in the `tlverse` nomenclature) simply by calling
`tmle_shift`. We specify the argument `shift_grid = seq(-1, 1, by = 1)`
when initializing the `tmle3_Spec` object to communicate that we're interested
in assessing the mean counterfactual outcome over a grid of shifts `r seq(-1,
1, by = 1)` on the scale of the treatment $A$.

```{r vim_spec_init, message=FALSE, warning=FALSE}
# what's the grid of shifts we wish to consider?
delta_grid <- seq(-1, 1, 1)

# initialize a tmle specification
tmle_spec <- tmle_vimshift_delta(
  shift_grid = delta_grid,
  max_shifted_ratio = 2
)
```

### Targeted Estimation of Stochastic Interventions Effects

One may walk through the step-by-step procedure for fitting the TML estimator
of the mean counterfactual outcome under each shift in the grid, using the
machinery exposed by the [`tmle3` R package](https://tlverse.org/tmle3).

One may invoke the `tmle3` wrapper function (a user-facing convenience utility)
to fit the series of TML estimators (one for each parameter defined by the grid
delta) in a single function call:

```{r fit_tmle_wrapper, message=FALSE, warning=FALSE, cache=FALSE}
tmle_fit <- tmle3(tmle_spec, data, node_list, learner_list)
tmle_fit
```

_Remark_: The `print` method of the resultant `tmle_fit` object conveniently
displays the results from computing our TML estimator.

### Inference with Marginal Structural Models

Appendix?

In the directly preceding section, we consider estimating the mean
counterfactual outcome $\psi_n$ under several values of the intervention
$\delta$, taken from the aforementioned $\delta$-grid. We now turn our attention
to an approach for obtaining inference on a single summary measure of these
estimated quantities. In particular, we propose summarizing the estimates
$\psi_n$ through a marginal structural model (MSM), obtaining inference by way
of a hypothesis test on a parameter of this working MSM. For a data structure
$O = (W, A, Y)$, let $\psi_{\delta}(P_0)$ be the mean outcome under a shift
$\delta$ of the treatment, so that we have $\vec{\psi}_{\delta} =
(\psi_{\delta}: \delta)$ with corresponding estimators $\vec{\psi}_{n, \delta}
= (\psi_{n, \delta}: \delta)$. Further, let $\beta(\vec{\psi}_{\delta}) =
\phi((\psi_{\delta}: \delta))$.

For a given MSM $m_{\beta}(\delta)$, we have that
$$\beta_0 = \text{argmin}_{\beta} \sum_{\delta}(\psi_{\delta}(P_0) -
m_{\beta}(\delta))^2 h(\delta),$$
which is the solution to
$$u(\beta, (\psi_{\delta}: \delta)) = \sum_{\delta}h(\delta)
\left(\psi_{\delta}(P_0) - m_{\beta}(\delta) \right) \frac{d}{d\beta}
m_{\beta}(\delta) = 0.$$
This then leads to the following expansion
$$\beta(\vec{\psi}_n) - \beta(\vec{\psi}_0) \approx -\frac{d}{d\beta} u(\beta_0,
\vec{\psi}_0)^{-1} \frac{d}{d\psi} u(\beta_0, \psi_0)(\vec{\psi}_n -
\vec{\psi}_0),$$
where we have
$$\frac{d}{d\beta} u(\beta, \psi) = -\sum_{\delta} h(\delta) \frac{d}{d\beta}
m_{\beta}(\delta)^t \frac{d}{d\beta} m_{\beta}(\delta)
-\sum_{\delta} h(\delta) m_{\beta}(\delta) \frac{d^2}{d\beta^2}
m_{\beta}(\delta),$$
which, in the case of an MSM that is a linear model (since
$\frac{d^2}{d\beta^2} m_{\beta}(\delta) = 0$), reduces simply to
$$\frac{d}{d\beta} u(\beta, \psi) = -\sum_{\delta} h(\delta) \frac{d}{d\beta}
m_{\beta}(\delta)^t \frac{d}{d\beta} m_{\beta}(\delta),$$
and
$$\frac{d}{d\psi}u(\beta, \psi)(\psi_n - \psi_0) = \sum_{\delta} h(\delta)
\frac{d}{d\beta} m_{\beta}(\delta) (\psi_n - \psi_0)(\delta),$$
which we may write in terms of the efficient influence function (EIF) of $\psi$
by using the first order approximation $(\psi_n - \psi_0)(\delta) =
\frac{1}{n}\sum_{i = 1}^n \text{EIF}_{\psi_{\delta}}(O_i)$,
where $\text{EIF}_{\psi_{\delta}}$ is the efficient influence function (EIF) of
$\vec{\psi}$.

Now, say, $\vec{\psi} = (\psi(\delta): \delta)$ is d-dimensional, then we may
write the efficient influence function of the MSM parameter $\beta$ (assuming a
linear MSM) as follows
$$\text{EIF}_{\beta}(O) = \left(\sum_{\delta} h(\delta) \frac{d}{d\beta}
m_{\beta}(\delta) \frac{d}{d\beta} m_{\beta}(\delta)^t \right)^{-1} \cdot
\sum_{\delta} h(\delta) \frac{d}{d\beta} m_{\beta}(\delta)
\text{EIF}_{\psi_{\delta}}(O),$$ where the first term is of dimension
$d \times d$ and the second term is of dimension $d \times 1$.

Inference from a working MSM is rather straightforward. To wit, the limiting
distribution for $m_{\beta}(\delta)$ may be expressed
$$\sqrt{n}(\beta_n - \beta_0) \to N(0, \Sigma),$$
where $\Sigma$ is the empirical covariance matrix of $\text{EIF}_{\beta}(O)$.

```{r msm_fit, message=FALSE, warning=FALSE}
tmle_fit$summary[4:5, ]
```

#### Directly Targeting the MSM Parameter $\beta$

Note that in the above, a working MSM is fit to the individual TML estimates of
the mean counterfactual outcome under a given value of the shift $\delta$ in
the supplied grid. The parameter of interest $\beta$ of the MSM is
asymptotically linear (and, in fact, a TML estimator) as a consequence of its
construction from individual TML estimators. In smaller samples, it may be
prudent to perform a TML estimation procedure that targets the parameter
$\beta$ directly, as opposed to constructing it from several independently
targeted TML estimates. An approach for constructing such an estimator is
proposed in the sequel.

Suppose a simple working MSM $\mathbb{E}Y_{g^0_{\delta}} = \beta_0 + \beta_1
\delta$, then a TML estimator targeting $\beta_0$ and $\beta_1$ may be
constructed as
$$\overline{Q}_{n, \epsilon}(A,W) = \overline{Q}_n(A,W) + \epsilon (H_1(g),
H_2(g),$$ for all $\delta$, where $H_1(g)$ is the auxiliary covariate for
$\beta_0$ and $H_2(g)$ is the auxiliary covariate for $\beta_1$.

To construct a targeted maximum likelihood estimator that directly targets the
parameters of the working marginal structural model, we may use the
`tmle_vimshift_msm` Spec (instead of the `tmle_vimshift_delta` Spec that
appears above):

```{r vim_targeted_msm_fit, message=FALSE, warning=FALSE, cache=FALSE}
# initialize a tmle specification
tmle_msm_spec <- tmle_vimshift_msm(
  shift_grid = delta_grid,
  max_shifted_ratio = 2
)

# fit the TML estimator and examine the results
tmle_msm_fit <- tmle3(tmle_msm_spec, data, node_list, learner_list)
tmle_msm_fit
```

---

## Exercises

### Basics/Review

1. TODO

2. Set the `sl3` library of algorithms for the Super Learner to a simple,
   interpretable library and use this new library to estimate the counterfactual
   mean of [VARIABLE WE'VE BEEN WORKING WITH] under a shift $\delta = 0$. What
   does this counterfactual mean equate to?

3. Describe two (equivalent) ways in which the causal effects of stochastic
   interventions may be interpreted.

4. TODO

### Using the Ideas

1. Choose a different variable of interest (e.g., TBD) and repeat the initial
   analysis we performed. That is, estimate the counterfactual mean under a
   shift of the new variable, after standardizing the chosen variable to have
   zero mean and unit variance. Interpret your findings.

2. Using a grid of values of the shift parameter $\delta$ (e.g., $\{-1, 0,
   +1\}$), repeat the analysis on the variable chosen in the preceding question,
   summarizing the trend for this sequence of shifts using a marginal structural
   model.

3. Repeat the preceding analysis, using the same grid of shifts, but instead
   directly targeting the parameters of the marginal structural model. Interpret
   the results -- that is, what does the slope of the marginal structural model
   tell us about the trend across the chosen sequence of shifts?

### Advanced

1. How does the marginal structural model we used to summarize the trend along
   the sequence of shifts previously help to contextualize the estimated effect
   for a single shift? That is, how does access to estimates across several
   shifts and the marginal structural model parameters allow us to more richly
   interpret our findings?

2. What advantages, if any, are there to targeted directly the parameters of a
   marginal structural model?

<!--
### Statistical Inference for Targeted Maximum Likelihood Estimates

Recall that the asymptotic distribution of TML estimators has been studied
thoroughly:
$$\psi_n - \psi_0 = (P_n - P_0) \cdot D(\bar{Q}_n^*, g_n) + R(\hat{P}^*, P_0),$$
which, provided the following two conditions:

1. If $D(\bar{Q}_n^*, g_n)$ converges to $D(P_0)$ in $L_2(P_0)$ norm, and
2. the size of the class of functions considered for estimation of $\bar{Q}_n^*$
   and $g_n$ is bounded (technically, $\exists \mathcal{F}$ st
   $D(\bar{Q}_n^*, g_n) \in \mathcal{F}$ *__whp__*, where $\mathcal{F}$ is a
   Donsker class),
readily admits the conclusion that
$\psi_n - \psi_0 = (P_n - P_0) \cdot D(P_0) + R(\hat{P}^*, P_0)$.

Under the additional condition that the remainder term $R(\hat{P}^*, P_0)$
decays as $o_P \left( \frac{1}{\sqrt{n}} \right),$ we have that
$$\psi_n - \psi_0 = (P_n - P_0) \cdot D(P_0) + o_P \left( \frac{1}{\sqrt{n}}
 \right),$$
which, by a central limit theorem, establishes a Gaussian limiting distribution
for the estimator:

$$\sqrt{n}(\psi_n - \psi) \to N(0, V(D(P_0))),$$
where $V(D(P_0))$ is the variance of the efficient influence curve (canonical
gradient) when $\psi$ admits an asymptotically linear representation.

The above implies that $\psi_n$ is a $\sqrt{n}$-consistent estimator of $\psi$,
that it is asymptotically normal (as given above), and that it is locally
efficient. This allows us to build Wald-type confidence intervals in a
straightforward manner:

$$\psi_n \pm z_{\alpha} \cdot \frac{\sigma_n}{\sqrt{n}},$$
where $\sigma_n^2$ is an estimator of $V(D(P_0))$. The estimator $\sigma_n^2$
may be obtained using the bootstrap or computed directly via the following

$$\sigma_n^2 = \frac{1}{n} \sum_{i = 1}^{n} D^2(\bar{Q}_n^*, g_n)(O_i)$$


- @haneuse2013estimation characterization of stochastic interventions as
  \textit{modified treatment policies} (MTPs).
- Assumption of \textit{piecewise smooth invertibility} allows for the
  intervention distribution of any MTP to be recovered:
  \begin{equation*}
    g_{0, \delta}(a \mid w) = \sum_{j = 1}^{J(w)} I_{\delta, j} \{h_j(a, w),
    w\} g_0\{h_j(a, w) \mid w\} h^{\prime}_j(a,w)
  \end{equation*}
- Such intervention policies account for the natural value of the
  intervention $A$ directly yet are interpretable as the imposition of an
  altered intervention mechanism.
- Piecewise smooth invertibility: This assumption ensures that we can
  use the change of variable formula when computing integrals over $A$ and
  it is useful to study the estimators that we propose in this paper.

- __Asymptotic linearity:__
  \begin{equation*}
    \Psi(P_n^{\star}) - \Psi(P_0) = \frac{1}{n} \sum_{i = 1}^{n} D(P_0)(X_i) +
    o_P\left(\frac{1}{\sqrt{n}}\right)
  \end{equation*}
- Gaussian limiting distribution:
  \begin{equation*}
    \sqrt{n}(\Psi(P_n^{\star}) - \Psi(P_0)) \to N(0, Var(D(P_0)(O)))
  \end{equation*}
- Statistical inference:
  \begin{equation*}
    \text{Wald-type CI}: \Psi(P_n^{\star}) \pm z_{\alpha} \cdot
    \frac{\sigma_n}{\sqrt{n}},
  \end{equation*}
  where $\sigma_n^2$ is computed directly via
  $\sigma_n^2 = \frac{1}{n} \sum_{i = 1}^{n} D^2(\cdot)(O_i)$.

Under the additional condition that the remainder term $R(\hat{P}^*, P_0)$
decays as $o_P \left( \frac{1}{\sqrt{n}} \right),$ we have that
$\Psi_n - \Psi_0 = (P_n - P_0) \cdot D(P_0) + o_P
\left( \frac{1}{\sqrt{n}} \right),$ which, by a central limit theorem,
establishes a Gaussian limiting distribution for the estimator, with variance
$V(D(P_0))$, the variance of the efficient influence function
when $\Psi$ admits an asymptotically linear representation.

The above implies that $\Psi_n$ is a $\sqrt{n}$-consistent estimator of $\Psi$,
that it is asymptotically normal (as given above), and that it is locally
efficient. This allows us to build Wald-type confidence intervals, where
$\sigma_n^2$ is an estimator of $V(D(P_0))$. The estimator $\sigma_n^2$
may be obtained using the bootstrap or computed directly via
$\sigma_n^2 = \frac{1}{n} \sum_{i = 1}^{n} D^2(\bar{Q}_n^*, g_n)(O_i)$

We obtain semiparametric-efficient estimation and robust inference in the
nonparametric model $\M$ by solving the efficient influence function.

1. If $D(\bar{Q}_n^*, g_n)$ converges to $D(P_0)$ in $L_2(P_0)$ norm.
2. The size of the class of functions $\bar{Q}_n^*$ and $g_n$ is bounded
   (technically, $\exists \mathcal{F}$ st
   $D(\bar{Q}_n^*, g_n) \in \mathcal{F}$ whp, where $\mathcal{F}$ is a
   Donsker class)
-->
